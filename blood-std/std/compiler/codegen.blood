// Blood Self-Hosted Compiler - Code Generator
//
// This module provides the main entry point for generating LLVM IR from MIR.
// It coordinates the generation of function bodies, declarations, and
// produces complete LLVM modules as text.

mod common;
mod hir_def;
mod hir_ty;
mod hir_item;
mod hir_lower_ctx;
mod mir_def;
mod mir_types;
mod mir_stmt;
mod mir_term;
mod mir_body;
mod codegen_types;
mod codegen_ctx;
mod codegen_expr;
mod codegen_stmt;
mod codegen_term;
mod mir_escape;
mod hashmap;
mod type_intern;
mod codegen_size;

// ============================================================
// Module Generation
// ============================================================

/// Result of code generation for a complete module.
pub struct CodegenResult {
    /// The generated LLVM IR as a string.
    pub llvm_ir: String,
    /// Any warnings generated during codegen.
    pub warnings: Vec<String>,
    /// Whether codegen was successful.
    pub success: bool,
}

impl CodegenResult {
    /// Creates a successful result.
    pub fn ok(llvm_ir: String) -> CodegenResult {
        CodegenResult {
            llvm_ir: llvm_ir,
            warnings: Vec::new(),
            success: true,
        }
    }

    /// Creates a failed result.
    pub fn error(msg: String) -> CodegenResult {
        let mut warnings = Vec::new();
        warnings.push(msg);
        CodegenResult {
            llvm_ir: String::new(),
            warnings: warnings,
            success: false,
        }
    }
}

/// Generates LLVM IR for a module with multiple functions.
pub fn generate_module(
    module_name: &str,
    functions: &Vec<(String, mir_body::MirBody)>,
) -> CodegenResult {
    // Empty items list and no remaps for backward compatibility
    let empty_items: Vec<hir_lower_ctx::ItemEntry> = Vec::new();
    let empty_remaps: Vec<common::DefaultMethodRemap> = Vec::new();
    generate_module_with_items(module_name, functions, &empty_items, &empty_remaps)
}

/// Finds call remapping entries for a given default method DefId.
fn find_call_remaps(
    remaps: &Vec<common::DefaultMethodRemap>,
    def_id: u32,
) -> Vec<common::CallRemapEntry> {
    let mut result: Vec<common::CallRemapEntry> = Vec::new();
    let mut i: usize = 0;
    while i < remaps.len() {
        if remaps[i].body_def_id == def_id {
            let mut j: usize = 0;
            while j < remaps[i].call_remaps.len() {
                result.push(common::CallRemapEntry::new(
                    remaps[i].call_remaps[j].from_def_id,
                    remaps[i].call_remaps[j].to_def_id,
                ));
                j = j + 1;
            }
            return result;
        }
        i = i + 1;
    }
    result
}

/// Generates LLVM IR for a module with multiple functions and ADT item info.
pub fn generate_module_with_items(
    module_name: &str,
    functions: &Vec<(String, mir_body::MirBody)>,
    items: &Vec<hir_lower_ctx::ItemEntry>,
    default_method_remaps: &Vec<common::DefaultMethodRemap>,
) -> CodegenResult {
    let mut output = String::new();

    // Build the DefId to name mapping for all functions
    let mut def_names: Vec<codegen_ctx::DefNameEntry> = Vec::new();
    let mut idx: usize = 0;
    while idx < functions.len() {
        let (ref name, ref body) = functions[idx];
        def_names.push(codegen_ctx::DefNameEntry::new(
            body.def_id.index,
            clone_string(name),
        ));
        idx = idx + 1;
    }

    // Create the shared codegen context with def names
    let mut ctx = codegen_ctx::CodegenCtx::new();
    let mut di: usize = 0;
    while di < def_names.len() {
        ctx.register_def_name(def_names[di].def_id, clone_string(&def_names[di].name));
        di = di + 1;
    }

    // Populate ADT registry from HIR items
    populate_adt_registry(&mut ctx, items);

    // Module header
    output.push_str("; ModuleID = '");
    output.push_str(module_name);
    output.push_str("'\n");
    output.push_str("source_filename = \"");
    output.push_str(module_name);
    output.push_str(".blood\"\n");
    output.push_str("target datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128\"\n");
    output.push_str("target triple = \"x86_64-unknown-linux-gnu\"\n");
    output.push_str("\n");

    // Generate each function using the shared context
    // Skip duplicate function definitions (keep only the first one with each name)
    // This is a workaround for missing proper monomorphization
    let mut generated_set = hashmap::HashMapU64U32::with_capacity(functions.len());
    let mut skip_count: usize = 0;
    let mut i: usize = 0;
    while i < functions.len() {
        let (ref name, ref body) = functions[i];
        // Check if this function name has already been generated (O(1) hash lookup)
        let name_hash = hashmap::hash_str(name.as_str());
        let already_generated = match generated_set.get(name_hash) {
            Option::Some(_) => true,
            Option::None => false,
        };
        if !already_generated {
            // Set up call remapping for trait default methods
            ctx.call_remaps = find_call_remaps(default_method_remaps, body.def_id.index);
            let fn_ir = generate_function_with_ctx(&mut ctx, body, name.as_str());
            output.push_str(fn_ir.as_str());
            ctx.call_remaps = Vec::new();
            generated_set.insert(name_hash, 1);
        } else {
            skip_count = skip_count + 1;
            // Emit a comment noting the skipped duplicate
            output.push_str("; DUPLICATE SKIPPED: @");
            output.push_str(name.as_str());
            output.push_str("\n");
        }
        i = i + 1;
    }
    // Debug: emit total skip count as comment
    if skip_count > 0 {
        output.push_str("; TOTAL DUPLICATES SKIPPED: ");
        let skip_str = codegen_types::format_u64(skip_count as u64);
        output.push_str(skip_str.as_str());
        output.push_str("\n");
    }

    // Append string constants from the context
    ctx.emit_string_constants();
    output.push_str(ctx.output.as_str());

    // Intrinsic and runtime declarations (consolidated in intrinsic_declarations())
    let decls = intrinsic_declarations();
    output.push_str(decls.as_str());

    CodegenResult::ok(output)
}

/// Generates LLVM IR for a function with access to def names table.
/// Legacy function for backward compatibility.
pub fn generate_function_with_defs(
    body: &mir_body::MirBody,
    fn_name: &str,
    def_names: &Vec<codegen_ctx::DefNameEntry>,
) -> String {
    let mut ctx = codegen_ctx::CodegenCtx::new();

    // Register all def names in the context
    let mut i: usize = 0;
    while i < def_names.len() {
        ctx.register_def_name(def_names[i].def_id, clone_string(&def_names[i].name));
        i = i + 1;
    }

    generate_function_with_ctx(&mut ctx, body, fn_name)
}

/// Generates LLVM IR for a single function using a shared codegen context.
pub fn generate_function_with_ctx(
    ctx: &mut codegen_ctx::CodegenCtx,
    body: &mir_body::MirBody,
    fn_name: &str,
) -> String {
    // Reset per-function state but keep global state (def_names, adt_registry, string_table)
    ctx.clear_locals();
    ctx.output = String::new();
    ctx.begin_function(common::make_string(fn_name));

    // Build parameter list (skip first local which is return place)
    let mut params: Vec<(String, String)> = Vec::new();
    let mut p: usize = 1; // Start at 1 to skip return place
    let param_end: usize = 1usize + (body.param_count as usize);
    while p < param_end && p < body.locals.len() {
        let local = &body.locals[p];
        let local_id = mir_def::MirLocalId::new(p as u32);
        // Handler op state local: arg type is ptr (state pointer from wrapper)
        let ty = if ctx.is_handler_state_ptr(local_id) {
            common::make_string("ptr")
        } else {
            codegen_size::type_to_llvm_with_ctx_id(ctx, local.ty)
        };
        let mut arg_name = common::make_string("%arg");
        let idx_str = codegen_types::format_u64((p - 1) as u64);
        arg_name.push_str(idx_str.as_str());
        params.push((ty, arg_name));
        p = p + 1;
    }

    // Get return type (local _0)
    // Normalize {} (empty struct / unit) to void for LLVM function signatures
    let ret_ty_raw = if body.locals.len() > 0 {
        codegen_size::type_to_llvm_with_ctx_id(ctx, body.locals[0].ty)
    } else {
        common::make_string("void")
    };
    let ret_ty = if is_empty_struct_type(ret_ty_raw.as_str()) {
        common::make_string("void")
    } else {
        ret_ty_raw
    };

    // Store function signature for generic call fixup at call sites
    let mut sig_param_types: Vec<String> = Vec::new();
    let mut sp: usize = 0;
    while sp < params.len() {
        sig_param_types.push(clone_string(&params[sp].0));
        sp = sp + 1;
    }
    ctx.register_fn_signature(body.def_id.index, sig_param_types, clone_string(&ret_ty));

    // Emit function header
    ctx.emit_fn_header(fn_name, &params, ret_ty.as_str());

    // Emit entry label
    ctx.write("entry:\n");

    // Run escape analysis to determine allocation tiers
    let escape_result = mir_escape::analyze_escapes(body);

    // Emit allocas with escape-aware allocation decisions
    codegen_stmt::emit_allocas_with_escapes(ctx, body, &escape_result);

    // Store arguments into allocas
    codegen_stmt::emit_arg_stores(ctx, body);

    // Jump to first basic block if there are any
    if body.basic_blocks.len() > 0 {
        let first_label = ctx.block_label_cg(mir_def::BasicBlockId::new(0));
        ctx.indent();
        ctx.emit_br_cg(&first_label);
        ctx.dedent();
    } else {
        ctx.indent();
        ctx.emit_unreachable();
        ctx.dedent();
    }

    // Emit all basic blocks
    let mut block_idx: usize = 0;
    while block_idx < body.basic_blocks.len() {
        let block_id = mir_def::BasicBlockId::new(block_idx as u32);
        codegen_term::emit_basic_block(ctx, block_id, &body.basic_blocks[block_idx]);
        block_idx = block_idx + 1;
    }

    ctx.emit_fn_footer();
    ctx.end_function();

    // Extract and return the function IR
    let result = clone_string(&ctx.output);
    ctx.output = String::new();
    result
}

// ============================================================
// ADT Registry Population
// ============================================================

/// Populates the ADT registry from HIR items.
/// Uses a two-pass approach: first register all ADTs with placeholder field types,
/// then rebuild layouts using the now-populated registry for correct nested ADT types.
pub fn populate_adt_registry(
    ctx: &mut codegen_ctx::CodegenCtx,
    items: &Vec<hir_lower_ctx::ItemEntry>,
) {
    // Pass 1: Register all ADTs with basic (possibly ptr) field types.
    // This ensures all ADT def_ids are known before resolving nested types.
    let mut i: usize = 0;
    while i < items.len() {
        let entry = &items[i];
        match &entry.item.kind {
            &hir_item::ItemKind::Struct(ref struct_def) => {
                let layout = build_struct_layout_basic(entry.def_id.index, struct_def);
                ctx.register_struct(layout);
            }
            &hir_item::ItemKind::Enum(ref enum_def) => {
                let layout = build_enum_layout_with_ctx(ctx, entry.def_id.index, enum_def);
                ctx.register_enum(layout);
            }
            &hir_item::ItemKind::Fn(_) => {}
            &hir_item::ItemKind::TypeAlias(_) => {}
            &hir_item::ItemKind::Const(_) => {}
            &hir_item::ItemKind::Static(_) => {}
            &hir_item::ItemKind::Trait(_) => {}
            &hir_item::ItemKind::Effect(_) => {}
            &hir_item::ItemKind::Handler(_) => {}
            &hir_item::ItemKind::Module(_) => {}
            &hir_item::ItemKind::Impl(_) => {}
            &hir_item::ItemKind::Macro(_) => {}
            &hir_item::ItemKind::Foreign(_) => {}
        }
        i = i + 1;
    }

    // Pass 2+: Rebuild struct and enum layouts using context-aware type resolution.
    // Each pass resolves one more level of nesting. Since lookup_struct/lookup_enum and
    // adt_llvm_type scan from the end, new entries override old ones.
    // Repeat until all types stabilize (typically 2-3 iterations).
    let mut pass: u32 = 0;
    while pass < 4 {
        let mut j: usize = 0;
        while j < items.len() {
            let entry = &items[j];
            match &entry.item.kind {
                &hir_item::ItemKind::Struct(ref struct_def) => {
                    let layout = build_struct_layout_with_ctx(ctx, entry.def_id.index, struct_def);
                    ctx.register_struct(layout);
                }
                &hir_item::ItemKind::Enum(ref enum_def) => {
                    let layout = build_enum_layout_with_ctx(ctx, entry.def_id.index, enum_def);
                    ctx.register_enum(layout);
                }
                _ => {}
            }
            j = j + 1;
        }
        pass = pass + 1;
    }
}

/// Registers synthetic StructLayouts for builtin ADT types (Vec, String, HashMap, Box).
/// These types are not in the HIR items list but need to be in the ADT registry so that
/// user-defined structs containing these types resolve to the correct LLVM layout
/// (e.g., `{ ptr, i64, i64 }` instead of `ptr`).
pub fn register_builtin_adts(
    ctx: &mut codegen_ctx::CodegenCtx,
    builtin_vec_def: &Option<hir_def::DefId>,
    builtin_string_def: &Option<hir_def::DefId>,
    builtin_hashmap_def: &Option<hir_def::DefId>,
    builtin_box_def: &Option<hir_def::DefId>,
) {
    // Vec<T> = { ptr, i64, i64 } (data pointer, length, capacity)
    match builtin_vec_def {
        &Option::Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "{ ptr, i64, i64 }");
            ctx.register_struct(layout);
        }
        &Option::None => {}
    }
    // String = { ptr, i64, i64 } (same as Vec<u8>)
    match builtin_string_def {
        &Option::Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "{ ptr, i64, i64 }");
            ctx.register_struct(layout);
        }
        &Option::None => {}
    }
    // HashMap<K,V> = { ptr, i64, i64 } (runtime representation)
    match builtin_hashmap_def {
        &Option::Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "{ ptr, i64, i64 }");
            ctx.register_struct(layout);
        }
        &Option::None => {}
    }
    // Box<T> = ptr (single heap pointer)
    match builtin_box_def {
        &Option::Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "ptr");
            ctx.register_struct(layout);
        }
        &Option::None => {}
    }
}

/// Creates a synthetic StructLayout for a builtin type with the given LLVM type string.
fn make_builtin_struct_layout(def_id: u32, llvm_type_str: &str) -> codegen_ctx::StructLayout {
    codegen_ctx::StructLayout {
        def_id: def_id,
        fields: Vec::new(),
        llvm_type: common::make_string(llvm_type_str),
    }
}

/// Rebuilds ADT layouts using context-aware type resolution.
/// Call this after registering builtin ADTs and before code generation
/// to ensure all struct fields containing Vec/String/HashMap resolve to correct sizes.
pub fn rebuild_adt_layouts(
    ctx: &mut codegen_ctx::CodegenCtx,
    items: &Vec<hir_lower_ctx::ItemEntry>,
) {
    let mut pass: u32 = 0;
    while pass < 4 {
        let mut j: usize = 0;
        while j < items.len() {
            let entry = &items[j];
            match &entry.item.kind {
                &hir_item::ItemKind::Struct(ref struct_def) => {
                    let layout = build_struct_layout_with_ctx(ctx, entry.def_id.index, struct_def);
                    ctx.register_struct(layout);
                }
                &hir_item::ItemKind::Enum(ref enum_def) => {
                    let layout = build_enum_layout_with_ctx(ctx, entry.def_id.index, enum_def);
                    ctx.register_enum(layout);
                }
                _ => {}
            }
            j = j + 1;
        }
        pass = pass + 1;
    }
}

/// Builds a StructLayout using basic type resolution (no ADT registry lookups).
/// Used in pass 1 to get all ADTs registered before resolving nested types.
fn build_struct_layout_basic(def_id: u32, struct_def: &hir_item::StructDef) -> codegen_ctx::StructLayout {
    let mut fields: Vec<codegen_ctx::AdtFieldInfo> = Vec::new();
    let mut llvm_type = common::make_string("{ ");

    match &struct_def.body {
        &hir_item::StructBody::Record(ref struct_fields) => {
            let mut fi: usize = 0;
            while fi < struct_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let field_ty_hir = type_intern::ty_id_to_type(struct_fields[fi].ty);
                let field_ty = codegen_types::type_to_llvm(&field_ty_hir);
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx::AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option::Some(struct_fields[fi].ty),
                });
                fi = fi + 1;
            }
        }
        &hir_item::StructBody::Tuple(ref tuple_fields) => {
            let mut fi: usize = 0;
            while fi < tuple_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let tuple_field_hir = type_intern::ty_id_to_type(type_intern::TyId::new(tuple_fields[fi].index));
                let field_ty = codegen_types::type_to_llvm(&tuple_field_hir);
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx::AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option::Some(type_intern::TyId::new(tuple_fields[fi].index)),
                });
                fi = fi + 1;
            }
        }
        &hir_item::StructBody::Unit => {
            // Unit struct: empty
        }
    }

    llvm_type.push_str(" }");

    // Handle edge case: empty struct
    if fields.len() == 0 {
        llvm_type = common::make_string("{}");
    }

    codegen_ctx::StructLayout {
        def_id: def_id,
        fields: fields,
        llvm_type: llvm_type,
    }
}

/// Builds a StructLayout using context-aware type resolution.
/// ADT fields resolve to their actual struct/enum types from the registry.
fn build_struct_layout_with_ctx(
    ctx: &mut codegen_ctx::CodegenCtx,
    def_id: u32,
    struct_def: &hir_item::StructDef,
) -> codegen_ctx::StructLayout {
    let mut fields: Vec<codegen_ctx::AdtFieldInfo> = Vec::new();
    let mut llvm_type = common::make_string("{ ");

    match &struct_def.body {
        &hir_item::StructBody::Record(ref struct_fields) => {
            let mut fi: usize = 0;
            while fi < struct_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, struct_fields[fi].ty);
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx::AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option::Some(struct_fields[fi].ty),
                });
                fi = fi + 1;
            }
        }
        &hir_item::StructBody::Tuple(ref tuple_fields) => {
            let mut fi: usize = 0;
            while fi < tuple_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, type_intern::TyId::new(tuple_fields[fi].index));
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx::AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option::Some(type_intern::TyId::new(tuple_fields[fi].index)),
                });
                fi = fi + 1;
            }
        }
        &hir_item::StructBody::Unit => {
            // Unit struct: empty
        }
    }

    llvm_type.push_str(" }");

    if fields.len() == 0 {
        llvm_type = common::make_string("{}");
    }

    codegen_ctx::StructLayout {
        def_id: def_id,
        fields: fields,
        llvm_type: llvm_type,
    }
}

/// Builds an EnumLayout using context-aware type resolution.
/// ADT fields in enum payloads resolve to their actual struct/enum types from the registry.
fn build_enum_layout_with_ctx(
    ctx: &mut codegen_ctx::CodegenCtx,
    def_id: u32,
    enum_def: &hir_item::EnumDef,
) -> codegen_ctx::EnumLayout {
    let mut variants: Vec<codegen_ctx::VariantLayout> = Vec::new();
    let mut max_payload_size: u64 = 0;
    let mut max_alignment: u64 = 1;
    let mut has_payload: bool = false;

    let mut vi: usize = 0;
    while vi < enum_def.variants.len() {
        let variant = &enum_def.variants[vi];
        let mut fields: Vec<codegen_ctx::AdtFieldInfo> = Vec::new();
        let mut payload_type = common::make_string("{}");

        match &variant.kind {
            &hir_item::VariantKind::Unit => {
                // No payload
            }
            &hir_item::VariantKind::Tuple(ref tuple_fields) => {
                let mut pt = common::make_string("{ ");
                let mut fi: usize = 0;
                while fi < tuple_fields.len() {
                    if fi > 0 {
                        pt.push_str(", ");
                    }
                    let tuple_ty_id = type_intern::TyId::new(tuple_fields[fi].index);
                    let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, tuple_ty_id);
                    pt.push_str(field_ty.as_str());
                    fields.push(codegen_ctx::AdtFieldInfo {
                        llvm_type: field_ty,
                        hir_type: Option::Some(type_intern::TyId::new(tuple_fields[fi].index)),
                    });
                    fi = fi + 1;
                }
                pt.push_str(" }");
                if tuple_fields.len() > 0 {
                    has_payload = true;
                    payload_type = pt;
                }
            }
            &hir_item::VariantKind::Record(ref record_fields) => {
                let mut pt = common::make_string("{ ");
                let mut fi: usize = 0;
                while fi < record_fields.len() {
                    if fi > 0 {
                        pt.push_str(", ");
                    }
                    let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, record_fields[fi].ty);
                    pt.push_str(field_ty.as_str());
                    fields.push(codegen_ctx::AdtFieldInfo {
                        llvm_type: field_ty,
                        hir_type: Option::Some(record_fields[fi].ty),
                    });
                    fi = fi + 1;
                }
                pt.push_str(" }");
                if record_fields.len() > 0 {
                    has_payload = true;
                    payload_type = pt;
                }
            }
        }

        // Use proper struct size with padding (not naive sum of field sizes)
        let variant_size = codegen_size::llvm_type_size(payload_type.as_str());
        let variant_align = codegen_size::llvm_type_alignment(payload_type.as_str());
        if variant_size > max_payload_size {
            max_payload_size = variant_size;
        }
        if variant_align > max_alignment {
            max_alignment = variant_align;
        }

        variants.push(codegen_ctx::VariantLayout {
            variant_idx: variant.discriminant,
            fields: fields,
            payload_llvm_type: payload_type,
        });

        vi = vi + 1;
    }

    // Always use i32 for discriminant (matching reference compiler)
    let discriminant_type = common::make_string("i32");

    // Build enum LLVM type with alignment-aware payload array.
    // The payload array element type is chosen to satisfy the maximum alignment
    // requirement across all variant payloads (matching reference compiler behavior).
    let mut llvm_type = common::make_string("{ i32");
    if has_payload && max_payload_size > 0 {
        if max_alignment >= 8 {
            let num_elements = (max_payload_size + 7) / 8;
            llvm_type.push_str(", [");
            let count_str = codegen_types::format_u64(num_elements);
            llvm_type.push_str(count_str.as_str());
            llvm_type.push_str(" x i64]");
            max_payload_size = num_elements * 8;
        } else if max_alignment >= 4 {
            let num_elements = (max_payload_size + 3) / 4;
            llvm_type.push_str(", [");
            let count_str = codegen_types::format_u64(num_elements);
            llvm_type.push_str(count_str.as_str());
            llvm_type.push_str(" x i32]");
            max_payload_size = num_elements * 4;
        } else if max_alignment >= 2 {
            let num_elements = (max_payload_size + 1) / 2;
            llvm_type.push_str(", [");
            let count_str = codegen_types::format_u64(num_elements);
            llvm_type.push_str(count_str.as_str());
            llvm_type.push_str(" x i16]");
            max_payload_size = num_elements * 2;
        } else {
            llvm_type.push_str(", [");
            let size_str = codegen_types::format_u64(max_payload_size);
            llvm_type.push_str(size_str.as_str());
            llvm_type.push_str(" x i8]");
        }
    }
    llvm_type.push_str(" }");

    codegen_ctx::EnumLayout {
        def_id: def_id,
        discriminant_type: discriminant_type,
        variants: variants,
        llvm_type: llvm_type,
        max_payload_size: max_payload_size,
    }
}

// ============================================================
// Simple Function Generator
// ============================================================

/// Generates a simple function that returns a constant.
pub fn generate_constant_function(name: &str, value: i64) -> String {
    let mut output = String::new();
    output.push_str("define i64 @");
    output.push_str(name);
    output.push_str("() {\n");
    output.push_str("entry:\n");
    output.push_str("    ret i64 ");
    let val_str = codegen_types::format_i64(value);
    output.push_str(val_str.as_str());
    output.push_str("\n}\n");
    output
}

// ============================================================
// Module Preamble
// ============================================================

/// Generates the standard module preamble.
pub fn module_preamble(module_name: &str) -> String {
    let mut output = String::new();
    output.push_str("; ModuleID = '");
    output.push_str(module_name);
    output.push_str("'\n");
    output.push_str("source_filename = \"");
    output.push_str(module_name);
    output.push_str(".blood\"\n");
    output.push_str("target datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128\"\n");
    output.push_str("target triple = \"x86_64-unknown-linux-gnu\"\n\n");
    output
}

/// Generates standard intrinsic declarations.
pub fn intrinsic_declarations() -> String {
    let mut output = String::new();
    output.push_str("\n; Intrinsic declarations\n");
    output.push_str("declare void @llvm.memcpy.p0.p0.i64(ptr, ptr, i64, i1)\n");
    output.push_str("declare void @llvm.memset.p0.i64(ptr, i8, i64, i1)\n");
    output.push_str("declare void @llvm.trap()\n");
    output.push_str("declare void @llvm.debugtrap()\n");

    // C library declarations
    output.push_str("\n; C library declarations\n");
    output.push_str("declare i32 @puts(ptr)\n");

    // Box runtime declarations
    output.push_str("\n; Box runtime declarations\n");
    output.push_str("declare ptr @box_new(ptr, i64)\n");
    output.push_str("declare ptr @box_as_ref(ptr)\n");

    // Effect handler evidence API declarations (from libblood_runtime.a)
    output.push_str("\n; Effect handler evidence API declarations\n");
    output.push_str("declare ptr @blood_evidence_create()\n");
    output.push_str("declare ptr @blood_evidence_current()\n");
    output.push_str("declare void @blood_evidence_set_current(ptr)\n");
    output.push_str("declare void @blood_evidence_push_with_state(ptr, i64, ptr)\n");
    output.push_str("declare void @blood_evidence_set_inline(i64)\n");
    output.push_str("declare void @blood_evidence_clear_inline()\n");
    output.push_str("declare i64 @blood_evidence_pop(ptr)\n");
    output.push_str("declare void @blood_evidence_register(ptr, i64, ptr, i64)\n");
    output.push_str("declare i64 @blood_perform(i64, i32, ptr, i64, i64)\n");
    output.push_str("declare i64 @blood_continuation_create_multishot(ptr, ptr)\n");
    output.push_str("declare i64 @blood_continuation_resume(i64, i64)\n");
    output.push_str("\n; Identity continuation for tail-resumptive performs\n");
    output.push_str("define internal i64 @__blood_identity_continuation(i64 %0, ptr %1) {\n");
    output.push_str("entry:\n");
    output.push_str("  ret i64 %0\n");
    output.push_str("}\n");

    // Builtin constructor stubs (used as function pointers for match dispatch, not called directly)
    output.push_str("\n; Builtin constructor stubs\n");
    output.push_str("define internal void @option_none_ctor() { ret void }\n");
    output.push_str("define internal void @option_some_ctor(ptr %0) { ret void }\n");
    output.push_str("declare void @string_new(ptr)\n");
    output.push_str("declare void @vec_new(i64, ptr)\n");

    // Format string conversion runtime declarations
    // These return { ptr, i64 } fat pointers (&str).
    output.push_str("\n; Format string conversion runtime declarations\n");
    output.push_str("declare { ptr, i64 } @int_to_string(i32)\n");
    output.push_str("declare { ptr, i64 } @bool_to_string(i1)\n");
    output.push_str("declare { ptr, i64 } @float_to_string(double)\n");
    output.push_str("declare { ptr, i64 } @char_to_string(i32)\n");

    // Builtin method runtime declarations
    // These are runtime functions called by builtin method resolution.
    // Signatures match blood-rust's codegen/context/mod.rs.
    output.push_str("\n; String method runtime declarations\n");
    output.push_str("declare i64 @string_len(ptr)\n");
    output.push_str("declare void @string_push(ptr, i32)\n");
    output.push_str("declare void @string_push_str(ptr, ptr)\n");
    output.push_str("declare { ptr, i64 } @string_as_str(ptr)\n");
    output.push_str("declare { ptr, i64 } @string_as_bytes(ptr)\n");

    output.push_str("\n; str method runtime declarations\n");
    output.push_str("declare { ptr, i64 } @str_as_bytes(ptr)\n");

    output.push_str("\n; Vec method runtime declarations\n");
    output.push_str("declare i64 @vec_len(ptr)\n");
    output.push_str("declare void @vec_push(ptr, ptr, i64)\n");
    output.push_str("declare i32 @vec_pop(ptr, i64, ptr)\n");
    output.push_str("declare void @vec_clear(ptr)\n");
    output.push_str("declare void @vec_with_capacity(i64, i64, ptr)\n");
    output.push_str("declare i32 @vec_is_empty(ptr)\n");
    output.push_str("declare i64 @vec_capacity(ptr)\n");
    output.push_str("declare i32 @vec_get(ptr, i64, i64, ptr)\n");
    output.push_str("declare ptr @vec_get_ptr(ptr, i64, i64)\n");
    output.push_str("declare i32 @vec_contains(ptr, ptr, i64)\n");
    output.push_str("declare void @vec_reverse(ptr, i64)\n");
    output.push_str("declare void @vec_first(ptr, i64, ptr)\n");
    output.push_str("declare void @vec_last(ptr, i64, ptr)\n");
    output.push_str("declare void @vec_free(ptr, i64)\n");

    output.push_str("\n; Option method runtime declarations\n");
    output.push_str("declare i32 @option_is_some(ptr)\n");
    output.push_str("declare i32 @option_is_none(ptr)\n");
    output.push_str("declare void @option_unwrap(ptr, i64, ptr)\n");
    output.push_str("declare void @option_as_ref(ptr, i64, ptr)\n");

    output.push_str("\n; Slice method runtime declarations\n");
    output.push_str("declare i64 @slice_len(ptr)\n");

    // Region memory management runtime wrappers
    // The runtime uses blood_region_* prefix; we provide region_* wrappers for codegen
    output.push_str("\n; Region memory management\n");
    output.push_str("declare i64 @blood_region_create(i64, i64)\n");
    output.push_str("declare void @blood_region_destroy(i64)\n");
    output.push_str("declare void @blood_region_activate(i64)\n");
    output.push_str("declare void @blood_region_deactivate()\n");
    output.push_str("declare i64 @blood_region_alloc(i64, i64, i64)\n");
    output.push_str("declare i32 @blood_region_exit_scope(i64)\n");
    output.push_str("declare i64 @blood_region_used(i64)\n");
    output.push_str("declare void @blood_region_trim(i64)\n");
    output.push_str("declare i64 @blood_region_committed(i64)\n");
    output.push_str("declare i64 @blood_region_alloc_count(i64)\n");
    output.push_str("declare i64 @blood_system_alloc_live_bytes()\n");
    output.push_str("define internal i64 @region_create(i64 %0, i64 %1) { %r = call i64 @blood_region_create(i64 %0, i64 %1) ret i64 %r }\n");
    output.push_str("define internal void @region_destroy(i64 %0) { call void @blood_region_destroy(i64 %0) ret void }\n");
    output.push_str("define internal void @region_activate(i64 %0) { call void @blood_region_activate(i64 %0) ret void }\n");
    output.push_str("define internal void @region_deactivate() { call void @blood_region_deactivate() ret void }\n");
    output.push_str("define internal i64 @region_alloc(i64 %0, i64 %1, i64 %2) { %r = call i64 @blood_region_alloc(i64 %0, i64 %1, i64 %2) ret i64 %r }\n");
    output.push_str("define internal i32 @region_exit_scope(i64 %0) { %r = call i32 @blood_region_exit_scope(i64 %0) ret i32 %r }\n");
    output.push_str("define internal i64 @region_used(i64 %0) { %r = call i64 @blood_region_used(i64 %0) ret i64 %r }\n");
    output.push_str("define internal void @region_trim(i64 %0) { call void @blood_region_trim(i64 %0) ret void }\n");
    output.push_str("define internal i64 @region_committed(i64 %0) { %r = call i64 @blood_region_committed(i64 %0) ret i64 %r }\n");
    output.push_str("define internal i64 @region_alloc_count(i64 %0) { %r = call i64 @blood_region_alloc_count(i64 %0) ret i64 %r }\n");
    output.push_str("define internal i64 @system_alloc_live_bytes() { %r = call i64 @blood_system_alloc_live_bytes() ret i64 %r }\n");
    output.push_str("declare i64 @blood_realloc_diag_count()\n");
    output.push_str("declare i64 @blood_realloc_diag_wasted()\n");
    output.push_str("declare i64 @blood_realloc_diag_inplace()\n");
    output.push_str("declare i64 @blood_realloc_diag_inplace_bytes()\n");
    output.push_str("declare i64 @blood_realloc_diag_offset_delta()\n");
    output.push_str("declare void @blood_realloc_stats_reset()\n");
    output.push_str("declare void @blood_print_alloc_hist()\n");
    output.push_str("declare void @blood_alloc_hist_reset()\n");
    output.push_str("define internal i64 @realloc_diag_count() { %r = call i64 @blood_realloc_diag_count() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_wasted() { %r = call i64 @blood_realloc_diag_wasted() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_inplace() { %r = call i64 @blood_realloc_diag_inplace() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_inplace_bytes() { %r = call i64 @blood_realloc_diag_inplace_bytes() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_offset_delta() { %r = call i64 @blood_realloc_diag_offset_delta() ret i64 %r }\n");
    output.push_str("define internal void @realloc_stats_reset() { call void @blood_realloc_stats_reset() ret void }\n");
    output.push_str("define internal void @print_alloc_hist() { call void @blood_print_alloc_hist() ret void }\n");
    output.push_str("define internal void @alloc_hist_reset() { call void @blood_alloc_hist_reset() ret void }\n");

    // Memory management - generational references
    output.push_str("\n; Memory management - generational references\n");
    output.push_str("declare i64 @blood_alloc_or_abort(i64, ptr)\n");
    output.push_str("declare void @blood_free(i64, i64)\n");
    output.push_str("declare i32 @blood_register_allocation(i64, i64)\n");
    output.push_str("declare void @blood_unregister_allocation(i64)\n");
    output.push_str("declare i32 @blood_validate_generation(i64, i32)\n");
    output.push_str("declare i32 @blood_get_generation(i64)\n");
    output.push_str("declare void @blood_increment_generation(ptr)\n");
    output.push_str("declare void @blood_stale_reference_panic(i32, i32)\n");

    // Persistent allocation (reference counting)
    output.push_str("\n; Persistent allocation (reference counting)\n");
    output.push_str("declare ptr @blood_persistent_alloc(i64, i64, i32, ptr)\n");
    output.push_str("declare void @blood_persistent_decrement(i64)\n");

    // Blood-name → runtime-name wrappers
    // Blood registers builtins with user-friendly names (e.g., "print"),
    // but the runtime exports them under different names (e.g., "print_str").
    // These wrappers bridge the gap. Uses named temps to avoid SSA numbering issues.
    output.push_str("\n; Blood builtin name wrappers\n");

    // print/println/eprint/eprintln → *_str runtime variants (for &str args)
    output.push_str("declare void @print_str({ ptr, i64 })\n");
    output.push_str("declare void @println_str({ ptr, i64 })\n");
    output.push_str("declare void @eprint_str({ ptr, i64 })\n");
    output.push_str("declare void @eprintln_str({ ptr, i64 })\n");
    output.push_str("define internal void @print({ ptr, i64 } %s) {\n  call void @print_str({ ptr, i64 } %s)\n  ret void\n}\n");
    output.push_str("define internal void @println({ ptr, i64 } %s) {\n  call void @println_str({ ptr, i64 } %s)\n  ret void\n}\n");
    output.push_str("define internal void @eprint({ ptr, i64 } %s) {\n  call void @eprint_str({ ptr, i64 } %s)\n  ret void\n}\n");
    output.push_str("define internal void @eprintln({ ptr, i64 } %s) {\n  call void @eprintln_str({ ptr, i64 } %s)\n  ret void\n}\n");

    // assert → blood_assert (Blood bool/i1 → runtime i32 conversion)
    output.push_str("declare void @blood_assert(i32)\n");
    output.push_str("declare void @blood_assert_eq_int(i32, i32)\n");
    output.push_str("declare void @blood_assert_eq_bool(i1, i1)\n");
    output.push_str("define internal void @assert(i1 %cond) {\n  %ext = zext i1 %cond to i32\n  call void @blood_assert(i32 %ext)\n  ret void\n}\n");
    output.push_str("define internal void @assert_eq_int(i32 %a, i32 %b) {\n  call void @blood_assert_eq_int(i32 %a, i32 %b)\n  ret void\n}\n");
    output.push_str("define internal void @assert_eq_bool(i1 %a, i1 %b) {\n  call void @blood_assert_eq_bool(i1 %a, i1 %b)\n  ret void\n}\n");

    // unreachable/todo → panic with message string constants
    // Note: @panic is declared by the runtime function codegen path, not here.
    output.push_str("@.str.unreachable = private unnamed_addr constant [26 x i8] c\"unreachable code reached!\\00\"\n");
    output.push_str("@.str.todo = private unnamed_addr constant [21 x i8] c\"not yet implemented!\\00\"\n");
    output.push_str("define internal void @unreachable() noreturn {\n  call void @panic({ ptr, i64 } { ptr @.str.unreachable, i64 25 })\n  unreachable\n}\n");
    output.push_str("define internal void @todo() noreturn {\n  call void @panic({ ptr, i64 } { ptr @.str.todo, i64 20 })\n  unreachable\n}\n");

    // process_exit → libc exit
    output.push_str("declare void @exit(i32) noreturn\n");
    output.push_str("define internal void @process_exit(i32 %code) noreturn {\n  call void @exit(i32 %code)\n  unreachable\n}\n");

    // Low-level memory builtins → blood runtime (all i64 addresses)
    output.push_str("declare i64 @blood_alloc_simple(i64)\n");
    output.push_str("declare i64 @blood_realloc(i64, i64)\n");
    output.push_str("declare void @blood_free_simple(i64)\n");
    output.push_str("declare i64 @blood_memcpy(i64, i64, i64)\n");
    output.push_str("define internal i64 @alloc(i64 %sz) {\n  %r = call i64 @blood_alloc_simple(i64 %sz)\n  ret i64 %r\n}\n");
    output.push_str("define internal i64 @realloc(i64 %p, i64 %sz) {\n  %r = call i64 @blood_realloc(i64 %p, i64 %sz)\n  ret i64 %r\n}\n");
    output.push_str("define internal void @free(i64 %p) {\n  call void @blood_free_simple(i64 %p)\n  ret void\n}\n");
    output.push_str("define internal i64 @memcpy(i64 %d, i64 %s, i64 %n) {\n  %r = call i64 @blood_memcpy(i64 %d, i64 %s, i64 %n)\n  ret i64 %r\n}\n");

    // str_concat → blood_str_concat
    output.push_str("declare { ptr, i64 } @blood_str_concat({ ptr, i64 }, { ptr, i64 })\n");
    output.push_str("define internal { ptr, i64 } @str_concat({ ptr, i64 } %a, { ptr, i64 } %b) {\n  %r = call { ptr, i64 } @blood_str_concat({ ptr, i64 } %a, { ptr, i64 } %b)\n  ret { ptr, i64 } %r\n}\n");

    // Builtins whose Blood types (Option<T>, String) don't match runtime ABI.
    // The runtime uses concrete types, not opaque ptrs.
    output.push_str("\n; Parsing / conversion / IO runtime declarations\n");
    output.push_str("declare double @parse_f64({ ptr, i64 })\n");
    output.push_str("declare i64 @parse_i64_radix({ ptr, i64 }, i32)\n");
    output.push_str("declare i32 @char_from_u32(i32)\n");
    output.push_str("declare { ptr, i64 } @read_line()\n");

    // Math library wrappers (Blood name → libm name where they differ)
    output.push_str("\n; Math library wrappers\n");
    output.push_str("declare double @fabs(double)\n");
    output.push_str("declare float @fabsf(float)\n");
    output.push_str("declare float @sqrtf(float)\n");
    output.push_str("define internal double @abs(double %x) {\n  %r = call double @fabs(double %x)\n  ret double %r\n}\n");
    output.push_str("define internal float @abs_f32(float %x) {\n  %r = call float @fabsf(float %x)\n  ret float %r\n}\n");
    output.push_str("define internal float @sqrt_f32(float %x) {\n  %r = call float @sqrtf(float %x)\n  ret float %r\n}\n");

    // Thread builtins → blood_thread_spawn / blood_thread_join runtime wrappers
    output.push_str("\n; Thread runtime declarations\n");
    output.push_str("declare i64 @blood_thread_spawn(i64, i64)\n");
    output.push_str("declare i64 @blood_thread_join(i64)\n");
    output.push_str("define internal i64 @thread_spawn(i64 %f, i64 %a) {\n  %r = call i64 @blood_thread_spawn(i64 %f, i64 %a)\n  ret i64 %r\n}\n");
    output.push_str("define internal i64 @thread_join(i64 %h) {\n  %r = call i64 @blood_thread_join(i64 %h)\n  ret i64 %r\n}\n");

    output
}

// ============================================================
// External Function Declarations
// ============================================================

/// Generates an external function declaration.
pub fn extern_function(name: &str, params: &Vec<String>, ret_ty: &str) -> String {
    let mut output = String::new();
    output.push_str("declare ");
    output.push_str(ret_ty);
    output.push_str(" @");
    output.push_str(name);
    output.push_str("(");
    let mut i: usize = 0;
    while i < params.len() {
        if i > 0 {
            output.push_str(", ");
        }
        output.push_str(params[i].as_str());
        i = i + 1;
    }
    output.push_str(")\n");
    output
}

// ============================================================
// String Helpers
// ============================================================

/// Checks if an LLVM type string is "{}" (empty struct / unit type).
fn is_empty_struct_type(ty: &str) -> bool {
    let bytes = ty.as_bytes();
    if bytes.len() == 2 {
        bytes[0] == 123 && bytes[1] == 125
    } else {
        false
    }
}

/// Clones a String.
fn clone_string(s: &String) -> String {
    let mut result = String::new();
    result.push_str(s.as_str());
    result
}

/// Compares two &str for equality.
fn string_eq_str(a: &str, b: &str) -> bool {
    let a_bytes = a.as_bytes();
    let b_bytes = b.as_bytes();
    if a_bytes.len() != b_bytes.len() {
        return false;
    }
    let mut i: usize = 0;
    while i < a_bytes.len() {
        if a_bytes[i] != b_bytes[i] {
            return false;
        }
        i = i + 1;
    }
    true
}

/// Appends a u32 as decimal digits to a string.
fn append_u32(s: &mut String, n: u32) {
    if n == 0 {
        s.push('0');
        return;
    }
    let mut val = n;
    // Stack-based digit buffer
    let mut digits: [u8; 10] = [0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8];
    let mut count: usize = 0;
    while val > 0 {
        digits[count] = ((val % 10) as u8) + 48u8; // '0' = 48
        val = val / 10;
        count = count + 1;
    }
    // Reverse order
    while count > 0 {
        count = count - 1;
        s.push(digits[count] as char);
    }
}

// ============================================================
// Integration Tests (compile-time verification)
// ============================================================

/// Generates a minimal test module to verify codegen works.
pub fn generate_test_module() -> String {
    let mut output = String::new();

    // Module header
    output.push_str("; Test module for Blood codegen\n");
    output.push_str("source_filename = \"test.blood\"\n\n");

    // Simple function that returns 42
    output.push_str("define i64 @test_return() {\n");
    output.push_str("entry:\n");
    output.push_str("    ret i64 42\n");
    output.push_str("}\n\n");

    // Function with parameters
    output.push_str("define i64 @test_add(i64 %a, i64 %b) {\n");
    output.push_str("entry:\n");
    output.push_str("    %result = add i64 %a, %b\n");
    output.push_str("    ret i64 %result\n");
    output.push_str("}\n\n");

    // Function with control flow
    output.push_str("define i64 @test_if(i64 %cond) {\n");
    output.push_str("entry:\n");
    output.push_str("    %cmp = icmp ne i64 %cond, 0\n");
    output.push_str("    br i1 %cmp, label %then, label %else\n");
    output.push_str("then:\n");
    output.push_str("    br label %merge\n");
    output.push_str("else:\n");
    output.push_str("    br label %merge\n");
    output.push_str("merge:\n");
    output.push_str("    %result = phi i64 [ 1, %then ], [ 0, %else ]\n");
    output.push_str("    ret i64 %result\n");
    output.push_str("}\n");

    output
}
