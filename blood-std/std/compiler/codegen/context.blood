//! Code Generation Context
//!
//! This module provides the main code generation context which coordinates
//! LLVM code generation for a Blood program.
//!
//! ## Responsibilities
//!
//! - Manages LLVM context, module, and builder lifecycle
//! - Tracks compiled functions and their LLVM values
//! - Maps local variables to stack allocations
//! - Manages struct and enum type definitions
//! - Coordinates escape analysis results for optimization
//! - Tracks effect handlers and their operations
//! - Handles monomorphization of generic functions
//!
//! ## Memory Model
//!
//! The context tracks memory tiers for allocations:
//! - **Stack** (NoEscape): Values that don't escape, no generation checks needed
//! - **Region** (ArgEscape): Values that escape to caller, may need generation checks
//! - **Persistent** (GlobalEscape): Values that escape globally, full generation tracking

use std::collections::HashMap;

use super::llvm::{
    LLVMContext, LLVMModule, LLVMBuilder,
    LLVMContextRef, LLVMModuleRef, LLVMBuilderRef, LLVMValueRef,
    LLVMTypeRef, LLVMBasicBlockRef,
};
use super::llvm::target::LLVMTargetData;

use crate.compiler.hir::{DefId, LocalId, Type, BodyId, Body, FnDef, Crate as HirCrate};
use crate.compiler.mir::{MirBody, EscapeResults};
use crate.compiler.typeck::effects::{EffectInfo, HandlerInfo};
use crate.compiler.diagnostics::Diagnostic;

// ============================================================================
// Loop Context
// ============================================================================

/// Loop context for break/continue support.
///
/// Tracks the blocks needed to implement break and continue within loops.
pub struct LoopContext {
    /// The loop's continue block (condition or body start).
    pub continue_block: LLVMBasicBlockRef,
    /// The loop's exit block.
    pub exit_block: LLVMBasicBlockRef,
    /// Optional loop ID for named loops.
    pub loop_id: Option<u32>,
    /// Storage for break values (for loop expressions that return values).
    pub break_value_store: Option<LLVMValueRef>,
}

// ============================================================================
// Memory Tier
// ============================================================================

/// Memory tier for allocation strategy.
///
/// Based on escape analysis results, determines where values are allocated
/// and whether generation checks are needed.
pub enum MemoryTier {
    /// Stack allocation, no generation checks needed.
    /// For values that don't escape their defining scope.
    Stack,
    /// Region allocation, may need generation checks on entry/exit.
    /// For values that escape to caller but not globally.
    Region,
    /// Persistent allocation with full generation tracking.
    /// For values that may escape globally.
    Persistent,
}

// ============================================================================
// Codegen Context
// ============================================================================

/// The code generation context.
///
/// This is the main coordinator for LLVM code generation. It holds all state
/// needed during compilation of a Blood program to LLVM IR.
pub struct CodegenContext {
    /// The LLVM context.
    context: LLVMContext,
    /// The LLVM module being built.
    module: LLVMModule,
    /// The LLVM IR builder.
    builder: LLVMBuilder,
    /// Target data layout for size/alignment queries.
    target_data: Option<LLVMTargetData>,

    // === Function and Variable Tracking ===

    /// Map from DefId to LLVM function value.
    pub functions: HashMap<DefId, LLVMValueRef>,
    /// Map from LocalId to stack allocation (in current function).
    pub locals: HashMap<LocalId, LLVMValueRef>,
    /// The current function being compiled.
    pub current_fn: Option<LLVMValueRef>,
    /// The current function's DefId for escape analysis lookup.
    pub current_fn_def_id: Option<DefId>,

    // === Type Definitions ===

    /// Struct definitions: DefId -> field types.
    pub struct_defs: HashMap<DefId, Vec<Type>>,
    /// Enum definitions: DefId -> variants, each with field types.
    pub enum_defs: HashMap<DefId, Vec<Vec<Type>>>,

    // === Escape Analysis ===

    /// Escape analysis results per function.
    pub escape_analysis: HashMap<DefId, EscapeResults>,
    /// Map from region-allocated LocalId to generation storage (stack alloca).
    pub local_generations: HashMap<LocalId, LLVMValueRef>,

    // === Control Flow ===

    /// Stack of loop contexts for break/continue.
    pub loop_stack: Vec<LoopContext>,

    // === Effects System ===

    /// Compiled effect definitions: effect DefId -> metadata.
    pub effect_defs: HashMap<DefId, EffectInfo>,
    /// Compiled handler definitions: handler DefId -> metadata.
    pub handler_defs: HashMap<DefId, HandlerInfo>,
    /// Handler function pointers: (handler_id, op_index) -> LLVM function.
    pub handler_ops: HashMap<(DefId, usize), LLVMValueRef>,
    /// Current continuation pointer for deep handler operations.
    pub current_continuation: Option<LLVMValueRef>,
    /// Whether the current handler operation is multi-shot.
    pub is_multishot_handler: bool,

    // === Generics and Monomorphization ===

    /// Generic function definitions: DefId -> (FnDef, Body).
    pub generic_fn_defs: HashMap<DefId, (FnDef, Body)>,
    /// Generic function MIR bodies: DefId -> MirBody.
    pub generic_mir_bodies: HashMap<DefId, MirBody>,
    /// Monomorphization cache: (generic DefId, type args) -> mono DefId.
    pub mono_cache: HashMap<(DefId, Vec<Type>), DefId>,
    /// Counter for generating unique monomorphized DefIds.
    pub mono_counter: u32,

    // === Closures ===

    /// Closure bodies for compilation.
    pub closure_bodies: HashMap<BodyId, Body>,
    /// Counter for generating unique closure function names.
    pub closure_counter: u32,
    /// Wrapper functions for plain functions used as fn() pointers.
    pub fn_ptr_wrappers: HashMap<DefId, LLVMValueRef>,

    // === Dynamic Dispatch ===

    /// Methods requiring dynamic dispatch: DefId -> slot number.
    pub dynamic_dispatch_methods: HashMap<DefId, u64>,
    /// Next dispatch table slot to assign.
    pub next_dispatch_slot: u64,
    /// Generated vtables: (trait_id, type_def_id) -> vtable global.
    pub vtables: HashMap<(DefId, DefId), LLVMValueRef>,
    /// Vtable slot mappings: trait_id -> Vec<(method_name, slot_index)>.
    pub vtable_layouts: HashMap<DefId, Vec<(String, usize)>>,

    // === Globals ===

    /// Global constants: DefId -> LLVM global value.
    pub const_globals: HashMap<DefId, LLVMValueRef>,
    /// Global statics: DefId -> LLVM global value.
    pub static_globals: HashMap<DefId, LLVMValueRef>,

    // === Builtins ===

    /// Builtin functions: DefId -> runtime function name.
    pub builtin_fns: HashMap<DefId, String>,

    // === Main Function ===

    /// The DefId of the main function, if present.
    pub main_fn_def_id: Option<DefId>,

    // === Inline Handlers ===

    /// Inline handler bodies for try/with blocks.
    pub inline_handler_bodies: HashMap<DefId, MirBody>,

    // === Errors ===

    /// Errors encountered during codegen.
    pub errors: Vec<Diagnostic>,
}

impl CodegenContext {
    /// Create a new code generation context.
    pub fn new(module_name: &str) -> CodegenContext {
        let context = LLVMContext::new();
        let module = LLVMModule::new(module_name, &context);
        let builder = LLVMBuilder::new(context.raw());

        CodegenContext {
            context,
            module,
            builder,
            target_data: None,
            functions: HashMap::new(),
            locals: HashMap::new(),
            current_fn: None,
            current_fn_def_id: None,
            struct_defs: HashMap::new(),
            enum_defs: HashMap::new(),
            escape_analysis: HashMap::new(),
            local_generations: HashMap::new(),
            loop_stack: Vec::new(),
            effect_defs: HashMap::new(),
            handler_defs: HashMap::new(),
            handler_ops: HashMap::new(),
            current_continuation: None,
            is_multishot_handler: false,
            generic_fn_defs: HashMap::new(),
            generic_mir_bodies: HashMap::new(),
            mono_cache: HashMap::new(),
            mono_counter: 0,
            closure_bodies: HashMap::new(),
            closure_counter: 0,
            fn_ptr_wrappers: HashMap::new(),
            dynamic_dispatch_methods: HashMap::new(),
            next_dispatch_slot: 0,
            vtables: HashMap::new(),
            vtable_layouts: HashMap::new(),
            const_globals: HashMap::new(),
            static_globals: HashMap::new(),
            builtin_fns: HashMap::new(),
            main_fn_def_id: None,
            inline_handler_bodies: HashMap::new(),
            errors: Vec::new(),
        }
    }

    // === Accessors ===

    /// Get the LLVM context.
    pub fn llvm_context(&self) -> &LLVMContext {
        &self.context
    }

    /// Get the raw LLVM context reference.
    pub fn llvm_context_ref(&self) -> LLVMContextRef {
        self.context.raw();
    }

    /// Get the LLVM module.
    pub fn llvm_module(&self) -> &LLVMModule {
        &self.module
    }

    /// Get the raw LLVM module reference.
    pub fn llvm_module_ref(&self) -> LLVMModuleRef {
        self.module.raw();
    }

    /// Get the LLVM builder.
    pub fn llvm_builder(&self) -> &LLVMBuilder {
        &self.builder
    }

    /// Get the raw LLVM builder reference.
    pub fn llvm_builder_ref(&self) -> LLVMBuilderRef {
        self.builder.raw();
    }

    /// Get the target data layout.
    pub fn target_data(&self) -> Option<&LLVMTargetData> {
        self.target_data.as_ref();
    }

    // === Configuration ===

    /// Set the target triple for the module.
    pub fn set_target_triple(&self, triple: &str) {
        self.module.set_target(triple);
    }

    /// Set the data layout for the module.
    pub fn set_data_layout(&self, layout: &str) {
        self.module.set_data_layout(layout);
    }

    /// Set the target data for size/alignment queries.
    pub fn set_target_data(&mut self, target_data: LLVMTargetData) {
        self.target_data = Some(target_data);
    }

    // === Escape Analysis ===

    /// Set escape analysis results for optimization.
    pub fn set_escape_analysis(&mut self, escape_analysis: HashMap<DefId, EscapeResults>) {
        self.escape_analysis = escape_analysis;
    }

    /// Get the memory tier for a local variable.
    ///
    /// Returns the appropriate tier based on escape analysis results.
    pub fn get_local_tier(&self, local_id: LocalId) -> MemoryTier {
        if let Some(def_id) = self.current_fn_def_id {
            if let Some(results) = self.escape_analysis.get(&def_id) {
                return match results.get_escape_state(local_id) {
                    crate.compiler.mir.EscapeState::NoEscape => MemoryTier::Stack,
                    crate.compiler.mir.EscapeState::ArgEscape => MemoryTier::Region,
                    crate.compiler.mir.EscapeState::GlobalEscape => MemoryTier::Persistent,
                };
            }
        }
        // Default to persistent if no escape analysis available
        MemoryTier::Persistent
    }

    /// Check if generation checks should be skipped for a local.
    ///
    /// Stack-allocated values that don't escape don't need generation checks.
    pub fn should_skip_gen_check(&self, local_id: LocalId) -> bool {
        matches!(self.get_local_tier(local_id), MemoryTier::Stack)
    }

    // === Function Management ===

    /// Set the current function being compiled.
    pub fn set_current_function(&mut self, func: LLVMValueRef, def_id: DefId) {
        self.current_fn = Some(func);
        self.current_fn_def_id = Some(def_id);
        self.locals.clear();
        self.local_generations.clear();
    }

    /// Clear the current function.
    pub fn clear_current_function(&mut self) {
        self.current_fn = None;
        self.current_fn_def_id = None;
        self.locals.clear();
        self.local_generations.clear();
    }

    /// Check if we're currently compiling the main function.
    pub fn is_main_function(&self) -> bool {
        if let (Some(current), Some(main)) = (self.current_fn_def_id, self.main_fn_def_id) {
            current == main;
        } else {
            false
        }
    }

    // === Loop Management ===

    /// Push a loop context onto the stack.
    pub fn push_loop(&mut self, ctx: LoopContext) {
        self.loop_stack.push(ctx);
    }

    /// Pop a loop context from the stack.
    pub fn pop_loop(&mut self) -> Option<LoopContext> {
        self.loop_stack.pop();
    }

    /// Get the current innermost loop context.
    pub fn current_loop(&self) -> Option<&LoopContext> {
        self.loop_stack.last();
    }

    /// Find a loop by its ID.
    pub fn find_loop(&self, loop_id: u32) -> Option<&LoopContext> {
        for ctx in self.loop_stack.iter().rev() {
            if ctx.loop_id == Some(loop_id) {
                return Some(ctx);
            }
        }
        None
    }

    // === Monomorphization ===

    /// Get or create a monomorphized instance of a generic function.
    ///
    /// Returns the DefId for the monomorphized version.
    pub fn get_monomorphized(&mut self, generic_def_id: DefId, type_args: Vec<Type>) -> DefId {
        let key = (generic_def_id, type_args.clone());

        if let Some(&mono_def_id) = self.mono_cache.get(&key) {
            return mono_def_id;
        };

        // Create a new synthetic DefId for this monomorphization
        self.mono_counter += 1;
        let mono_def_id = DefId::synthetic(self.mono_counter);

        self.mono_cache.insert(key, mono_def_id);
        mono_def_id
    }

    // === Closure Management ===

    /// Generate a unique name for a closure function.
    pub fn next_closure_name(&mut self, base: &str) -> String {
        self.closure_counter += 1;
        format!("{}$closure${}", base, self.closure_counter)
    }

    // === Error Reporting ===

    /// Report an error during code generation.
    pub fn report_error(&mut self, diagnostic: Diagnostic) {
        self.errors.push(diagnostic);
    }

    /// Report an error with a message and source span.
    pub fn error(&mut self, message: String, span: crate.compiler.span.Span) {
        self.errors.push(Diagnostic::error(message, span));
    }

    /// Check if there are any errors.
    pub fn has_errors(&self) -> bool {
        !self.errors.is_empty()
    }

    /// Take and return all accumulated errors.
    pub fn take_errors(&mut self) -> Vec<Diagnostic> {
        core::mem::take(&mut self.errors)
    }

    // === Module Output ===

    /// Verify the module.
    pub fn verify(&self) -> Result<(), String> {
        self.module.verify();
    }

    /// Print the module to a string (LLVM IR text).
    pub fn print_to_string(&self) -> String {
        self.module.print_to_string();
    }

    /// Print the module to a file.
    pub fn print_to_file(&self, filename: &str) -> Result<(), String> {
        self.module.print_to_file(filename);
    }
}

// ============================================================================
// Type Normalization Helpers
// ============================================================================

/// Build a mapping from arbitrary type variable IDs to sequential indices.
///
/// This collects all unique type variable IDs from a list of types, sorts them
/// by their original ID (to maintain a consistent order), and maps them to
/// sequential indices (0, 1, 2, ...).
pub fn build_tyvar_mapping(types: &[Type]) -> HashMap<u32, u32> {
    let mut all_tyvars = Vec::new();
    for ty in types {
        collect_tyvars(ty, &mut all_tyvars);
    };

    // Sort by ID value to get consistent ordering
    all_tyvars.sort();
    all_tyvars.dedup();

    // Build mapping: first unique ID -> 0, second -> 1, etc.
    let mut mapping = HashMap::new();
    for (idx, tyvar) in all_tyvars.iter().enumerate() {
        mapping.insert(*tyvar, idx as u32);
    }
    mapping
}

/// Collect all type variable IDs from a type.
fn collect_tyvars(ty: &Type, tyvars: &mut Vec<u32>) {
    match ty.kind() {
        crate.compiler.hir.TypeKind::Param(id) => {
            if !tyvars.contains(&id.0) {
                tyvars.push(id.0);
            }
        };
        crate.compiler.hir.TypeKind::Tuple(fields) => {
            for f in fields {
                collect_tyvars(f, tyvars);
            }
        };
        crate.compiler.hir.TypeKind::Array { element, .. } |
        crate.compiler.hir.TypeKind::Slice { element } => {
            collect_tyvars(element, tyvars);
        };
        crate.compiler.hir.TypeKind::Ref { inner, .. } |
        crate.compiler.hir.TypeKind::Ptr { inner, .. } => {
            collect_tyvars(inner, tyvars);
        };
        crate.compiler.hir.TypeKind::Adt { args, .. } => {
            for arg in args {
                collect_tyvars(arg, tyvars);
            }
        };
        crate.compiler.hir.TypeKind::Fn { params, ret, effects } => {
            for p in params {
                collect_tyvars(p, tyvars);
            };
            collect_tyvars(ret, tyvars);
            for eff in effects {
                for ty_arg in &eff.type_args {
                    collect_tyvars(ty_arg, tyvars);
                }
            }
        }
        _ => {}
    }
}

/// Normalize multiple types together using a shared type variable mapping.
///
/// This should be used when normalizing struct/enum fields to ensure all fields
/// share the same type variable ID-to-index mapping.
pub fn normalize_types_together(types: &[Type]) -> Vec<Type> {
    let tyvar_to_idx = build_tyvar_mapping(types);
    types.iter()
        .map(|ty| normalize_type_recursive(ty, &tyvar_to_idx))
        .collect();
}

/// Recursively replace type variable IDs with normalized parameter indices.
fn normalize_type_recursive(ty: &Type, tyvar_to_idx: &HashMap<u32, u32>) -> Type {
    match ty.kind() {
        crate.compiler.hir.TypeKind::Param(id) => {
            if let Some(&idx) = tyvar_to_idx.get(&id.0) {
                Type::param(crate.compiler.hir.TyVarId(idx))
            } else {
                ty.clone();
            }
        };
        crate.compiler.hir.TypeKind::Tuple(fields) => {
            let normalized: Vec<Type> = fields.iter()
                .map(|f| normalize_type_recursive(f, tyvar_to_idx))
                .collect();
            Type::tuple(normalized)
        };
        crate.compiler.hir.TypeKind::Array { element, size } => {
            let normalized = normalize_type_recursive(element, tyvar_to_idx);
            Type::array(normalized, *size)
        };
        crate.compiler.hir.TypeKind::Slice { element } => {
            let normalized = normalize_type_recursive(element, tyvar_to_idx);
            Type::slice(normalized)
        };
        crate.compiler.hir.TypeKind::Ref { inner, mutable } => {
            let normalized = normalize_type_recursive(inner, tyvar_to_idx);
            Type::reference(normalized, *mutable)
        };
        crate.compiler.hir.TypeKind::Ptr { inner, mutable } => {
            let normalized = normalize_type_recursive(inner, tyvar_to_idx);
            Type::ptr(normalized, *mutable)
        };
        crate.compiler.hir.TypeKind::Adt { def_id, args } => {
            let normalized_args: Vec<Type> = args.iter()
                .map(|a| normalize_type_recursive(a, tyvar_to_idx))
                .collect();
            Type::adt(*def_id, normalized_args)
        };
        crate.compiler.hir.TypeKind::Fn { params, ret, effects } => {
            let normalized_params: Vec<Type> = params.iter()
                .map(|p| normalize_type_recursive(p, tyvar_to_idx))
                .collect();
            let normalized_ret = normalize_type_recursive(ret, tyvar_to_idx);
            let normalized_effects: Vec<crate.compiler.hir.FnEffect> = effects.iter()
                .map(|eff| crate.compiler.hir.FnEffect {
                    def_id: eff.def_id,
                    type_args: eff.type_args.iter()
                        .map(|ty| normalize_type_recursive(ty, tyvar_to_idx))
                        .collect(),
                })
                .collect();
            Type::function_with_effects(normalized_params, normalized_ret, normalized_effects)
        }
        _ => ty.clone(),
    }
}

// ============================================================================
// MIR Type Substitution
// ============================================================================

/// Substitute type parameters in a type with concrete types.
pub fn substitute_type(ty: &Type, subst: &HashMap<u32, Type>) -> Type {
    match ty.kind() {
        crate.compiler.hir.TypeKind::Param(id) => {
            if let Some(concrete) = subst.get(&id.0) {
                concrete.clone();
            } else {
                ty.clone();
            }
        };
        crate.compiler.hir.TypeKind::Tuple(fields) => {
            let subst_fields: Vec<Type> = fields.iter()
                .map(|f| substitute_type(f, subst))
                .collect();
            Type::tuple(subst_fields)
        };
        crate.compiler.hir.TypeKind::Array { element, size } => {
            Type::array(substitute_type(element, subst), *size)
        };
        crate.compiler.hir.TypeKind::Slice { element } => {
            Type::slice(substitute_type(element, subst))
        };
        crate.compiler.hir.TypeKind::Ref { inner, mutable } => {
            Type::reference(substitute_type(inner, subst), *mutable)
        };
        crate.compiler.hir.TypeKind::Ptr { inner, mutable } => {
            Type::ptr(substitute_type(inner, subst), *mutable)
        };
        crate.compiler.hir.TypeKind::Adt { def_id, args } => {
            let subst_args: Vec<Type> = args.iter()
                .map(|a| substitute_type(a, subst))
                .collect();
            Type::adt(*def_id, subst_args)
        };
        crate.compiler.hir.TypeKind::Fn { params, ret, effects } => {
            let subst_params: Vec<Type> = params.iter()
                .map(|p| substitute_type(p, subst))
                .collect();
            let subst_effects: Vec<crate.compiler.hir.FnEffect> = effects.iter()
                .map(|eff| crate.compiler.hir.FnEffect {
                    def_id: eff.def_id,
                    type_args: eff.type_args.iter()
                        .map(|ty| substitute_type(ty, subst))
                        .collect(),
                })
                .collect();
            Type::function_with_effects(subst_params, substitute_type(ret, subst), subst_effects)
        }
        _ => ty.clone(),
    }
}

/// Infer type arguments by unifying generic signature with concrete types.
///
/// This matches the generic parameter types (which contain TypeKind::Param) with
/// the concrete parameter types to determine what each type variable maps to.
pub fn infer_type_args(
    generic_params: &[Type],
    concrete_params: &[Type],
    generic_ret: &Type,
    concrete_ret: &Type,
) -> HashMap<u32, Type> {
    let mut subst: HashMap<u32, Type> = HashMap::new();

    // Unify parameters
    for (generic, concrete) in generic_params.iter().zip(concrete_params.iter()) {
        unify_types(generic, concrete, &mut subst);
    };

    // Unify return type
    unify_types(generic_ret, concrete_ret, &mut subst);

    subst
}

/// Recursively unify a generic type with a concrete type, populating the substitution map.
fn unify_types(generic: &Type, concrete: &Type, subst: &mut HashMap<u32, Type>) {
    match generic.kind() {
        crate.compiler.hir.TypeKind::Param(id) => {
            subst.entry(id.0).or_insert_with(|| concrete.clone());
        };
        crate.compiler.hir.TypeKind::Fn { params: gen_params, ret: gen_ret, effects: gen_effects } => {
            if let crate.compiler.hir.TypeKind::Fn { params: conc_params, ret: conc_ret, effects: conc_effects } = concrete.kind() {
                for (gp, cp) in gen_params.iter().zip(conc_params.iter()) {
                    unify_types(gp, cp, subst);
                };
                unify_types(gen_ret, conc_ret, subst);
                for gen_eff in gen_effects {
                    for conc_eff in conc_effects {
                        if gen_eff.def_id == conc_eff.def_id {
                            for (gen_arg, conc_arg) in gen_eff.type_args.iter().zip(conc_eff.type_args.iter()) {
                                unify_types(gen_arg, conc_arg, subst);
                            }
                        }
                    }
                }
            }
        };
        crate.compiler.hir.TypeKind::Tuple(gen_fields) => {
            if let crate.compiler.hir.TypeKind::Tuple(conc_fields) = concrete.kind() {
                for (gf, cf) in gen_fields.iter().zip(conc_fields.iter()) {
                    unify_types(gf, cf, subst);
                }
            }
        };
        crate.compiler.hir.TypeKind::Array { element: gen_elem, .. } => {
            if let crate.compiler.hir.TypeKind::Array { element: conc_elem, .. } = concrete.kind() {
                unify_types(gen_elem, conc_elem, subst);
            }
        };
        crate.compiler.hir.TypeKind::Slice { element: gen_elem } => {
            if let crate.compiler.hir.TypeKind::Slice { element: conc_elem } = concrete.kind() {
                unify_types(gen_elem, conc_elem, subst);
            }
        };
        crate.compiler.hir.TypeKind::Ref { inner: gen_inner, .. } => {
            if let crate.compiler.hir.TypeKind::Ref { inner: conc_inner, .. } = concrete.kind() {
                unify_types(gen_inner, conc_inner, subst);
            }
        };
        crate.compiler.hir.TypeKind::Ptr { inner: gen_inner, .. } => {
            if let crate.compiler.hir.TypeKind::Ptr { inner: conc_inner, .. } = concrete.kind() {
                unify_types(gen_inner, conc_inner, subst);
            }
        };
        crate.compiler.hir.TypeKind::Adt { args: gen_args, .. } => {
            if let crate.compiler.hir.TypeKind::Adt { args: conc_args, .. } = concrete.kind() {
                for (ga, ca) in gen_args.iter().zip(conc_args.iter()) {
                    unify_types(ga, ca, subst);
                }
            }
        }
        _ => {}
    }
}
