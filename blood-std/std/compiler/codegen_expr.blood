// Blood Self-Hosted Compiler - Codegen Expressions
//
// This module handles generating LLVM IR for MIR operands and rvalues.

mod common;
mod hir_def;
mod hir_ty;
mod mir_def;
mod mir_types;
mod mir_stmt;
mod mir_term;
mod mir_body;
mod codegen_types;
mod codegen_ctx;
mod codegen_size;
mod type_intern;

// ============================================================
// Operand Codegen
// ============================================================

/// Generates LLVM IR for an operand, returning the value name.
pub fn emit_operand(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> String {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            emit_place_load(ctx, place)
        }
        &mir_types::Operand::Move(ref place) => {
            emit_place_load(ctx, place)
        }
        &mir_types::Operand::Constant(ref constant) => {
            emit_constant(ctx, constant)
        }
    }
}

/// Generates LLVM IR for an operand with type information, returning (value, llvm_type).
pub fn emit_operand_typed(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> (String, String) {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            emit_place_load_with_type(ctx, place)
        }
        &mir_types::Operand::Move(ref place) => {
            emit_place_load_with_type(ctx, place)
        }
        &mir_types::Operand::Constant(ref constant) => {
            let val = emit_constant(ctx, constant);
            let const_hir_ty = type_intern::ty_id_to_type(constant.ty);
            // Check if this FnDef is actually a const or static item
            // (MIR lowering produces FnDef for all path expressions)
            let fn_def_id = match &constant.kind {
                &mir_types::ConstantKind::FnDef(ref did) => Option::Some(did.index),
                _ => Option::None,
            };
            let is_const_item = match fn_def_id {
                Option::Some(did) => ctx.is_const(did),
                Option::None => false,
            };
            let is_static_item = match fn_def_id {
                Option::Some(did) => ctx.is_static(did),
                Option::None => false,
            };
            if is_const_item {
                // Const item: call the const body function to get the value
                let ret_ty = codegen_size::type_to_llvm_with_ctx(ctx, &const_hir_ty);
                let call_result = ctx.fresh_temp_cg();
                ctx.write_indent();
                ctx.write_cgname(&call_result);
                ctx.write(" = call ");
                ctx.write_string(&ret_ty);
                ctx.write(" ");
                ctx.write_string(&val);
                ctx.write("()\n");
                (cgname_to_string(&call_result), ret_ty)
            } else if is_static_item {
                // Static item: load from the global address
                // val already has @ prefix from emit_constant's FnDef handler
                let load_ty = codegen_size::type_to_llvm_with_ctx(ctx, &const_hir_ty);
                let load_result = ctx.fresh_temp_cg();
                ctx.emit_load_cg(&load_result, load_ty.as_str(), val.as_str());
                (cgname_to_string(&load_result), load_ty)
            } else if match fn_def_id { Option::Some(_) => true, Option::None => false } {
                // Regular function reference — pointer-typed
                (val, common::make_string("ptr"))
            } else if match &constant.kind { &mir_types::ConstantKind::Float(_) => true, _ => false } {
                // Check if f32 or f64 based on the constant's HIR type
                let float_ty = match &const_hir_ty.kind {
                    &hir_ty::TypeKind::Primitive(hir_ty::PrimitiveTy::F32) => common::make_string("float"),
                    _ => common::make_string("double"),
                };
                (val, float_ty)
            } else {
                // Check if the constant has a reference type to a SIZED type
                // (e.g., const 1: &i32). This happens when the type checker
                // unifies an argument with a &T parameter type (e.g.,
                // HashMap.get(key) where key: &K). We must materialize the
                // inner value in a temp alloca and return a pointer to it.
                //
                // For unsized types (&str, &[T]), the constant is already a
                // fat pointer { ptr, i64 } and should NOT be wrapped.
                let is_sized_ref = match &const_hir_ty.kind {
                    &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                        !codegen_types::is_unsized_type(inner.as_ref())
                    }
                    _ => false,
                };
                if is_sized_ref {
                    let inner_ty = match &const_hir_ty.kind {
                        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                            codegen_size::type_to_llvm_with_ctx(ctx, inner.as_ref())
                        }
                        _ => common::make_string("i64"),
                    };
                    // Alloca a temp, store the value, return pointer
                    let ref_temp = ctx.fresh_temp_cg();
                    ctx.emit_alloca_cg(&ref_temp, inner_ty.as_str());
                    ctx.emit_store_str_cg(inner_ty.as_str(), val.as_str(), &ref_temp);
                    (cgname_to_string(&ref_temp), common::make_string("ptr"))
                } else {
                    let ty = codegen_types::type_to_llvm(&const_hir_ty);
                    (val, ty)
                }
            }
        }
    }
}

/// Generates LLVM IR for a constant, returning the value.
fn emit_constant(
    ctx: &mut codegen_ctx::CodegenCtx,
    constant: &mir_types::Constant,
) -> String {
    match &constant.kind {
        &mir_types::ConstantKind::Int(v) => codegen_types::format_i128(v),
        &mir_types::ConstantKind::Uint(v) => codegen_types::format_u128(v),
        &mir_types::ConstantKind::Bool(b) => {
            if b { common::make_string("1") } else { common::make_string("0") }
        }
        &mir_types::ConstantKind::Char(c) => {
            codegen_types::format_u64(c as u64)
        }
        &mir_types::ConstantKind::Float(bits) => {
            // MIR always stores float bits as f64 representation (u64).
            // LLVM accepts double-precision hex for both float and double types,
            // converting to the target precision automatically.
            codegen_types::f64_bits_to_llvm_hex(bits)
        }
        &mir_types::ConstantKind::String(ref s) => {
            // Build fat pointer: { ptr @.str.N, i64 len }
            let label = ctx.add_string_constant(s);
            let mut result = common::make_string("{ ptr ");
            result.push_str(label.as_str());
            result.push_str(", i64 ");
            let len_str = codegen_types::format_u64(s.len() as u64);
            result.push_str(len_str.as_str());
            result.push_str(" }");
            result
        }
        &mir_types::ConstantKind::ByteString(ref bytes) => {
            // Convert byte string to regular string for storage
            let mut s = String::new();
            let mut i: usize = 0;
            while i < bytes.len() {
                s.push(bytes[i] as char);
                i = i + 1;
            }
            // Build fat pointer: { ptr @.str.N, i64 len }
            let label = ctx.add_string_constant(&s);
            let mut result = common::make_string("{ ptr ");
            result.push_str(label.as_str());
            result.push_str(", i64 ");
            let len_str = codegen_types::format_u64(bytes.len() as u64);
            result.push_str(len_str.as_str());
            result.push_str(" }");
            result
        }
        &mir_types::ConstantKind::Unit => common::make_string("undef"),
        &mir_types::ConstantKind::FnDef(ref def_id) => {
            // Function pointer - look up the function name
            match ctx.lookup_def_name(def_id.index) {
                Option::Some(name) => {
                    let mut result = common::make_string("@");
                    result.push_str(name.as_str());
                    result
                }
                Option::None => {
                    // Fallback: generate a placeholder name
                    let mut err_msg = common::make_string("function def_id ");
                    err_msg.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    err_msg.push_str(" not found in def_names table");
                    ctx.codegen_error(
                        codegen_ctx::CodegenErrorKind::FnLookupFailed,
                        err_msg,
                    );
                    let mut result = common::make_string("@fn_");
                    result.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    result
                }
            }
        }
        &mir_types::ConstantKind::ConstDef(ref def_id) => {
            // Const reference - look up and inline the const value
            // For now, generate a reference (full const eval would inline the value)
            match ctx.lookup_def_name(def_id.index) {
                Option::Some(name) => {
                    let mut result = common::make_string("@");
                    result.push_str(name.as_str());
                    result
                }
                Option::None => {
                    // Fallback: generate a placeholder
                    let mut err_msg = common::make_string("const def_id ");
                    err_msg.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    err_msg.push_str(" not found in def_names table");
                    ctx.codegen_error(
                        codegen_ctx::CodegenErrorKind::FnLookupFailed,
                        err_msg,
                    );
                    let mut result = common::make_string("@const_");
                    result.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    result
                }
            }
        }
        &mir_types::ConstantKind::StaticDef(ref def_id) => {
            // Static reference - look up the static name
            match ctx.lookup_def_name(def_id.index) {
                Option::Some(name) => {
                    let mut result = common::make_string("@");
                    result.push_str(name.as_str());
                    result
                }
                Option::None => {
                    // Fallback: generate a placeholder name
                    let mut err_msg = common::make_string("static def_id ");
                    err_msg.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    err_msg.push_str(" not found in def_names table");
                    ctx.codegen_error(
                        codegen_ctx::CodegenErrorKind::StaticLookupFailed,
                        err_msg,
                    );
                    let mut result = common::make_string("@static_");
                    result.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    result
                }
            }
        }
        &mir_types::ConstantKind::ZeroSized => common::make_string("undef"),
    }
}

/// Loads a value from a place, returning the value name.
fn emit_place_load(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> String {
    let ptr = emit_place_data_ptr(ctx, place);
    // Use the projected type (accounts for field access, deref, etc.)
    let llvm_ty = resolve_place_elem_type(ctx, place);
    // Skip load for unit type {} — it has zero size in LLVM
    if str_eq(llvm_ty.as_str(), "{}") {
        return common::make_string("undef");
    }
    let result = ctx.fresh_temp_cg();
    ctx.emit_load_cg(&result, llvm_ty.as_str(), ptr.as_str());
    // Zero-extend i8 to i32 for &str byte indexing (byte → char promotion)
    // Only apply when loading from an Index projection on a str-like type
    if str_eq(llvm_ty.as_str(), "i8") && is_str_index_place(ctx, place) {
        let extended = ctx.fresh_temp_cg();
        ctx.emit_cast_cg2(&extended, "zext", "i8", &result, "i32");
        return cgname_to_string(&extended);
    }
    cgname_to_string(&result)
}

/// Returns the data pointer for a place, handling region/persistent indirection.
/// For region/persistent locals with no projections, the stack alloca holds a ptr
/// to heap memory. This function dereferences to return the heap pointer where
/// the actual data lives. For stack locals, returns the alloca directly.
pub fn emit_place_data_ptr(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> String {
    let ptr = emit_place_addr(ctx, place);
    if place.projection.len() == 0
        && (ctx.is_region_allocated(place.local) || ctx.is_persistent_allocated(place.local)
            || ctx.is_handler_state_ptr(place.local))
    {
        let heap_ptr = ctx.fresh_temp_cg();
        ctx.emit_load_cg2(&heap_ptr, "ptr", &ptr);
        return cgname_to_string(&heap_ptr);
    }
    cgname_to_string(&ptr)
}

/// Loads a value from a place, returning (value, llvm_type).
fn emit_place_load_with_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> (String, String) {
    let ptr = emit_place_data_ptr(ctx, place);
    // Use the projected type (accounts for field access, deref, etc.)
    let llvm_ty = resolve_place_elem_type(ctx, place);
    // Skip load for unit type {} — it has zero size in LLVM
    if str_eq(llvm_ty.as_str(), "{}") {
        return (common::make_string("undef"), llvm_ty);
    }
    let result = ctx.fresh_temp_cg();
    ctx.emit_load_cg(&result, llvm_ty.as_str(), ptr.as_str());
    // Zero-extend i8 to i32 for &str byte indexing (byte → char promotion)
    // Only apply when loading from an Index projection on a str-like type
    if str_eq(llvm_ty.as_str(), "i8") && is_str_index_place(ctx, place) {
        let extended = ctx.fresh_temp_cg();
        ctx.emit_cast_cg2(&extended, "zext", "i8", &result, "i32");
        return (cgname_to_string(&extended), common::make_string("i32"));
    }
    (cgname_to_string(&result), llvm_ty)
}

/// Computes the LLVM type for the value at a place after all projections.
/// When a place has projections (Field, Deref, Downcast), the loaded type
/// differs from the base local's type. For example, loading field 0 of a
/// `{ i32, i32 }` struct should use `i32`, not the struct type.
fn resolve_place_elem_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> String {
    // For static places, use the registered static LLVM type
    if place.is_static() {
        match place.get_static_def_id() {
            Option::Some(def_id) => {
                match ctx.get_static_type(def_id.index) {
                    Option::Some(ty) => { return ty; }
                    Option::None => {}
                }
            }
            Option::None => {}
        }
    }

    // If no projections, use the local's registered LLVM type
    if place.projection.len() == 0 {
        return ctx.get_local_type(place.local);
    }

    // Check the last projection to determine the final type
    let last_idx = place.projection.len() - 1;
    match &place.projection[last_idx] {
        &mir_types::PlaceElem::Field(field_idx) => {
            // Field access: look up the field's type from the struct/enum layout.
            // Count Deref projections and check for Downcast before this field.
            let mut deref_count: usize = 0;
            let mut downcast_variant: Option<u32> = Option::None;
            let mut j: usize = 0;
            while j < last_idx {
                match &place.projection[j] {
                    &mir_types::PlaceElem::Deref => {
                        deref_count = deref_count + 1;
                    }
                    &mir_types::PlaceElem::Downcast(vi) => {
                        downcast_variant = Option::Some(vi);
                    }
                    _ => {}
                }
                j = j + 1;
            }

            // Resolve the ADT def_id by walking through Ref/Ptr layers
            let adt_def_id = if deref_count > 0 {
                resolve_deref_adt_def_id(ctx, place.local, deref_count - 1)
            } else {
                match ctx.get_local_hir_type(place.local) {
                    Option::Some(ty_id) => {
                        type_intern::resolve_adt_def_id_id(ty_id)
                    }
                    Option::None => Option::None,
                }
            };

            match &adt_def_id {
                &Option::Some(def_id) => {
                    match &downcast_variant {
                        &Option::Some(vi) => {
                            // Enum variant field
                            let mut found_field = false;
                            match ctx.lookup_enum(def_id) {
                                Option::Some(layout) => {
                                    let mut k: usize = 0;
                                    while k < layout.variants.len() {
                                        if layout.variants[k].variant_idx == vi {
                                            if (field_idx as usize) < layout.variants[k].fields.len() {
                                                let fty = &layout.variants[k].fields[field_idx as usize].llvm_type;
                                                // Check if the field type is unsubstituted (param/infer).
                                                // For generic enums like Option<T>, the registered layout has
                                                // the unsubstituted field type. Check via the field's HIR type.
                                                let field_is_param = match &layout.variants[k].fields[field_idx as usize].hir_type {
                                                    &Option::Some(ht_id) => type_intern::is_param_or_infer_id(ht_id),
                                                    &Option::None => false,
                                                };
                                                if !field_is_param {
                                                    return clone_string(fty);
                                                }
                                                found_field = true;
                                            }
                                            break;
                                        }
                                        k = k + 1;
                                    }
                                }
                                Option::None => {
                                    found_field = true;
                                }
                            }
                            // For generic enum fields (param/infer type or enum not in registry),
                            // resolve the concrete field type from the local's HIR type args.
                            if found_field {
                                match ctx.get_local_hir_type(place.local) {
                                    Option::Some(ty_id) => {
                                        let unwrapped = unwrap_ref_type(ty_id);
                                        match type_intern::get_adt_args(unwrapped) {
                                            Option::Some(args) => {
                                                let interner = type_intern::type_interner();
                                                let args_len = interner.ty_list_len(args);
                                                // For enums, field_idx maps to type arg index
                                                // (e.g., Option<T>.Some.0 → T, Result<T,E>.Ok.0 → T)
                                                if (field_idx as usize) < args_len {
                                                    let arg_ty_id = interner.get_ty_list_element(args, field_idx as usize);
                                                    return codegen_size::type_to_llvm_with_ctx_id(ctx, arg_ty_id);
                                                }
                                            }
                                            Option::None => {}
                                        }
                                    }
                                    Option::None => {}
                                }
                            }
                        }
                        &Option::None => {
                            // Struct field
                            match ctx.lookup_struct(def_id) {
                                Option::Some(layout) => {
                                    if (field_idx as usize) < layout.fields.len() {
                                        // Check if this field has an unsubstituted param/infer type.
                                        // If so, resolve the concrete type from the local's type args.
                                        let field_is_param = match &layout.fields[field_idx as usize].hir_type {
                                            &Option::Some(ht_id) => {
                                                type_intern::is_param_or_infer_id(ht_id)
                                            }
                                            &Option::None => false,
                                        };
                                        if field_is_param {
                                            // Try to get concrete type arg from local's HIR type
                                            let resolved = resolve_generic_field_type(ctx, place.local, layout, field_idx as usize);
                                            match resolved {
                                                Option::Some(ty) => { return ty; }
                                                Option::None => {}
                                            }
                                        }
                                        return clone_string(&layout.fields[field_idx as usize].llvm_type);
                                    }
                                }
                                Option::None => {}
                            }
                        }
                    }
                }
                &Option::None => {}
            }

            // Fallback: use the local's type
            ctx.get_local_type(place.local)
        }
        &mir_types::PlaceElem::Index(_) => {
            // After indexing, the type is the container's element type, not the container type
            match ctx.get_local_hir_type(place.local) {
                Option::Some(ty_id) => {
                    let hir_type = type_intern::ty_id_to_type(ty_id);
                    resolve_index_element_type(ctx, &hir_type)
                }
                Option::None => ctx.get_local_type(place.local),
            }
        }
        &mir_types::PlaceElem::ConstantIndex { offset: _, min_length: _, from_end: _ } => {
            // After constant indexing, the type is the container's element type
            match ctx.get_local_hir_type(place.local) {
                Option::Some(ty_id) => {
                    let hir_type = type_intern::ty_id_to_type(ty_id);
                    resolve_index_element_type(ctx, &hir_type)
                }
                Option::None => ctx.get_local_type(place.local),
            }
        }
        &mir_types::PlaceElem::Deref => {
            // Deref projection: unwrap Ref/Ptr layers from the local's HIR type
            // to find the pointed-to type. E.g., *const u8 → i8, &String → { ptr, i64, i64 }.
            match ctx.get_local_hir_type(place.local) {
                Option::Some(hir_type) => {
                    // Count Deref projections in the chain
                    let mut deref_count: usize = 0;
                    let mut di: usize = 0;
                    while di < place.projection.len() {
                        match &place.projection[di] {
                            &mir_types::PlaceElem::Deref => {
                                deref_count = deref_count + 1;
                            }
                            _ => {}
                        }
                        di = di + 1;
                    }
                    // Unwrap one layer
                    match apply_deref_to_type(hir_type) {
                        Option::Some(inner_ty) => {
                            // Apply remaining Derefs
                            let mut final_ty = inner_ty;
                            let mut applied: usize = 1;
                            while applied < deref_count {
                                match apply_deref_to_type(final_ty) {
                                    Option::Some(next) => {
                                        final_ty = next;
                                        applied = applied + 1;
                                    }
                                    Option::None => { break; }
                                }
                            }
                            codegen_size::type_to_llvm_with_ctx_id(ctx, final_ty)
                        }
                        Option::None => ctx.get_local_type(place.local),
                    }
                }
                Option::None => ctx.get_local_type(place.local),
            }
        }
        _ => {
            // For Downcast and other projections, use the local's type
            ctx.get_local_type(place.local)
        }
    }
}

/// Emits the address of a place, returning the pointer value.
pub fn emit_place_addr(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> codegen_ctx::CgName {
    // Check if this is a static place - use global variable address directly
    if place.is_static() {
        match place.get_static_def_id() {
            Option::Some(def_id) => {
                // Look up the global variable name for this static
                match ctx.lookup_def_name(def_id.index) {
                    Option::Some(name) => {
                        // Return the global variable name with @ prefix.
                        // Static global variables are already addresses.
                        // Convention: names are stored without @, add it here.
                        let mut result = common::make_string("@");
                        result.push_str(name.as_str());
                        return codegen_ctx::CgName::Str(result);
                    }
                    Option::None => {
                        // BUG: Static def_id has no name mapping — emit trap instead of null
                        // to avoid silent null pointer dereference in generated code
                        let mut err_msg = common::make_string("static def_name lookup failed for def_id ");
                        err_msg.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                        ctx.codegen_error(codegen_ctx::CodegenErrorKind::StaticLookupFailed, err_msg);
                        ctx.write("    ; BUG: static def_name lookup failed for def_id ");
                        ctx.write(codegen_types::format_u64(def_id.index as u64).as_str());
                        ctx.write("\n");
                        ctx.write("    call void @llvm.trap()\n");
                        ctx.emit_unreachable();
                        return codegen_ctx::CgName::Str(common::make_string("null"));
                    }
                }
            }
            Option::None => {
                // BUG: Static place has no def_id — emit trap instead of null
                ctx.codegen_error(
                    codegen_ctx::CodegenErrorKind::StaticLookupFailed,
                    common::make_string("static place missing def_id"),
                );
                ctx.write("    ; BUG: static place missing def_id\n");
                ctx.write("    call void @llvm.trap()\n");
                ctx.emit_unreachable();
                return codegen_ctx::CgName::Str(common::make_string("null"));
            }
        }
    }

    let mut current = ctx.local_cg(place.local);

    // Resolve the local's ADT type for projection lookups.
    // This looks through Ref types to find the inner ADT.
    let base_type = resolve_local_base_type(ctx, place.local);

    let mut i: usize = 0;
    // Track the current base type string through projections
    let mut current_base = base_type;
    // Track variant index after Downcast
    let mut downcast_variant: Option<u32> = Option::None;
    // Track the ADT def_id for field lookups
    let mut current_adt_def_id: Option<u32> = resolve_local_adt_def_id(ctx, place.local);
    // Track the current HIR type for proper indexing element size calculation.
    // Keep the full type including references - projections will unwrap as needed.
    let mut current_hir_type: Option<type_intern::TyId> = ctx.get_local_hir_type(place.local);

    // Region/persistent auto-deref: if the local is heap-allocated via region/persistent
    // and there are projections, load the heap pointer first. The alloca only holds a ptr
    // to the heap; projections must start from the heap data.
    if place.projection.len() > 0
        && (ctx.is_region_allocated(place.local) || ctx.is_persistent_allocated(place.local))
    {
        let loaded = ctx.fresh_temp_cg();
        ctx.emit_load_cg2(&loaded, "ptr", &current);
        current = loaded;
    }

    // Auto-deref: if the local is a reference type and the first projection is Field,
    // insert an implicit load of the pointer. The MIR should have a Deref projection
    // but the self-hosted compiler sometimes omits it for &self field access.
    if place.projection.len() > 0 && is_local_ref_type(ctx, place.local) {
        let first_is_field = match &place.projection[0] {
            &mir_types::PlaceElem::Field(_) => true,
            &mir_types::PlaceElem::Downcast(_) => true,
            _ => false,
        };
        if first_is_field {
            let loaded = ctx.fresh_temp_cg();
            ctx.emit_load_cg2(&loaded, "ptr", &current);
            current = loaded;
            // Also update HIR type through implicit deref
            current_hir_type = match &current_hir_type {
                &Option::Some(ty_id) => apply_deref_to_type(ty_id),
                &Option::None => Option::None,
            };
        }
    }

    while i < place.projection.len() {
        let proj = &place.projection[i];
        match proj {
            &mir_types::PlaceElem::Deref => {
                // Load the pointer value
                let result = ctx.fresh_temp_cg();
                ctx.emit_load_cg2(&result, "ptr", &current);
                // Emit generation check if the local has a tracked generation
                emit_generation_check(ctx, place.local, &result);
                current = result;
                // After deref, try to get the inner type's ADT info
                current_adt_def_id = resolve_deref_adt_def_id(ctx, place.local, i);
                current_base = match &current_adt_def_id {
                    &Option::Some(def_id) => ctx.adt_llvm_type(def_id),
                    &Option::None => common::make_string("{ i64 }"),
                };
                downcast_variant = Option::None;
                // Track HIR type through deref
                current_hir_type = match &current_hir_type {
                    &Option::Some(ty_id) => apply_deref_to_type(ty_id),
                    &Option::None => Option::None,
                };
            }
            &mir_types::PlaceElem::Field(idx) => {
                let result = ctx.fresh_temp_cg();

                // Determine the GEP base type from context
                let gep_type = match &downcast_variant {
                    &Option::Some(vi) => {
                        // After Downcast: use variant payload type
                        resolve_variant_payload_type(ctx, &current_adt_def_id, vi)
                    }
                    &Option::None => {
                        // Direct field access: use the struct/tuple LLVM type
                        clone_string(&current_base)
                    }
                };

                // If GEP base type is a scalar (not struct/array), use byte offset
                // instead of struct field indexing. Scalars like i64, ptr can't be
                // indexed with struct field indices.
                // Also bounds-check: if the field index exceeds the struct's field
                // count, fall back to byte-offset GEP.
                let field_count = count_struct_fields(&gep_type);
                if is_struct_or_array_type(&gep_type) && (idx as u64) < (field_count as u64) {
                    let mut indices: Vec<String> = Vec::new();
                    indices.push(common::make_string("0"));
                    indices.push(codegen_types::format_u64(idx as u64));
                    ctx.emit_gep_cg(&result, gep_type.as_str(), &current, &indices);
                } else {
                    // ICE: GEP base type is not a struct/array, or field index
                    // exceeds struct field count. This indicates incomplete type
                    // resolution in codegen — the MIR place projection references
                    // a field that doesn't exist in the resolved LLVM type.
                    ctx.write("    ; ICE: field GEP failed — base type '");
                    ctx.write_string(&gep_type);
                    ctx.write("' has ");
                    ctx.write(codegen_types::format_u64(field_count as u64).as_str());
                    ctx.write(" fields, tried to access field ");
                    ctx.write(codegen_types::format_u64(idx as u64).as_str());
                    ctx.write("\n");
                    ctx.write("    ; ICE: This is a compiler bug (codegen_expr: field GEP fallback)\n");
                    ctx.write("    call void @llvm.trap()\n");
                    ctx.emit_unreachable();
                }

                current = result;
                // After field access, try to preserve the field's HIR type for indexing
                current_hir_type = match &current_adt_def_id {
                    &Option::Some(def_id) => ctx.lookup_field_hir_type(def_id, idx),
                    &Option::None => Option::None,
                };
                current_adt_def_id = Option::None;
                current_base = common::make_string("{ i64 }");
                // If the field type is an ADT, update current_base and current_adt_def_id
                // to reflect the field's actual LLVM layout. This is critical for
                // subsequent Index projections (e.g., self.buckets[idx]) so that
                // is_vec_like_type correctly detects Vec-like types and loads the
                // data pointer before indexing.
                match &current_hir_type {
                    &Option::Some(ty_id) => {
                        match type_intern::get_adt_def_id(ty_id) {
                            Option::Some(def_id) => {
                                current_base = ctx.adt_llvm_type(def_id.index);
                                current_adt_def_id = Option::Some(def_id.index);
                            }
                            Option::None => {}
                        }
                    }
                    &Option::None => {}
                }
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::Index(ref local) => {
                // For Vec/container indexing, the current address points to the Vec struct
                // { ptr, i64, i64 } where the first field is the data pointer. We need to
                // load the data pointer before indexing into the heap-allocated array.
                // Detect Vec-like types by checking if current_base starts with "{ ptr"
                if is_vec_like_type(&current_base) {
                    // When the local is a reference to a Vec (LLVM type "ptr") and there's
                    // no preceding Deref projection, current points to the alloca containing
                    // the reference. Load through the reference first to get the Vec struct address.
                    if i == 0 {
                        let local_llvm_ty = ctx.get_local_type(place.local);
                        if string_eq_str(local_llvm_ty.as_str(), "ptr") {
                            let vec_ptr = ctx.fresh_temp_cg();
                            ctx.emit_load_cg2(&vec_ptr, "ptr", &current);
                            current = vec_ptr;
                        }
                    }
                    let data_ptr = ctx.fresh_temp_cg();
                    ctx.emit_load_cg2(&data_ptr, "ptr", &current);

                    // Null check: trap if data pointer is null (empty/dropped Vec)
                    let is_null = ctx.fresh_temp_cg();
                    ctx.emit_icmp_cg2(&is_null, "eq", "ptr", &data_ptr, "null");
                    let trap_label = ctx.fresh_label_cg();
                    let ok_label = ctx.fresh_label_cg();
                    ctx.emit_cond_br_cg(&is_null, &trap_label, &ok_label);
                    ctx.emit_label_cg(&trap_label);
                    ctx.write("    call void @llvm.trap()\n");
                    ctx.emit_unreachable();
                    ctx.emit_label_cg(&ok_label);

                    current = data_ptr;
                }

                // Get the element size using tracked HIR type for proper byte-offset calculation
                let elem_size = match &current_hir_type {
                    &Option::Some(ty_id) => {
                        get_element_size_from_hir_id(ctx, ty_id)
                    }
                    &Option::None => get_indexing_element_size(ctx, place.local),
                };

                // Load the index value
                let idx_val = ctx.local_cg(*local);
                let idx_loaded = ctx.fresh_temp_cg();
                ctx.emit_load_cg2(&idx_loaded, "i64", &idx_val);

                // Calculate byte offset = index * element_size
                // Use "mul nuw" (no unsigned wrap) to mark overflow as UB.
                // This allows sanitizers to trap on overflow and prevents silent
                // wraparound that could produce backward GEP into arbitrary memory.
                let elem_size_str = codegen_types::format_u64(elem_size);
                let byte_offset = ctx.fresh_temp_cg();
                let idx_loaded_str = cgname_to_string(&idx_loaded);
                ctx.emit_binop_cg(&byte_offset, "mul nuw", "i64", idx_loaded_str.as_str(), elem_size_str.as_str());

                // Use byte-offset GEP with i8 element type
                let result = ctx.fresh_temp_cg();
                let mut indices: Vec<String> = Vec::new();
                indices.push(cgname_to_string(&byte_offset));
                ctx.emit_gep_cg(&result, "i8", &current, &indices);
                current = result;
                current_adt_def_id = Option::None;
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::ConstantIndex { offset, min_length: _, from_end } => {
                // For Vec/container indexing, load the data pointer first
                if is_vec_like_type(&current_base) {
                    // Handle reference-to-Vec (same as Index case above)
                    if i == 0 {
                        let local_llvm_ty = ctx.get_local_type(place.local);
                        if string_eq_str(local_llvm_ty.as_str(), "ptr") {
                            let vec_ptr = ctx.fresh_temp_cg();
                            ctx.emit_load_cg2(&vec_ptr, "ptr", &current);
                            current = vec_ptr;
                        }
                    }
                    let data_ptr = ctx.fresh_temp_cg();
                    ctx.emit_load_cg2(&data_ptr, "ptr", &current);

                    // Null check: trap if data pointer is null (empty/dropped Vec)
                    let is_null = ctx.fresh_temp_cg();
                    ctx.emit_icmp_cg2(&is_null, "eq", "ptr", &data_ptr, "null");
                    let trap_label = ctx.fresh_label_cg();
                    let ok_label = ctx.fresh_label_cg();
                    ctx.emit_cond_br_cg(&is_null, &trap_label, &ok_label);
                    ctx.emit_label_cg(&trap_label);
                    ctx.write("    call void @llvm.trap()\n");
                    ctx.emit_unreachable();
                    ctx.emit_label_cg(&ok_label);

                    current = data_ptr;
                }

                // Get the element size using tracked HIR type for proper byte-offset calculation
                let elem_size = match &current_hir_type {
                    &Option::Some(ty_id) => {
                        get_element_size_from_hir_id(ctx, ty_id)
                    }
                    &Option::None => get_indexing_element_size(ctx, place.local),
                };

                // Calculate byte offset = offset * element_size
                let byte_offset = if from_end {
                    offset * elem_size
                } else {
                    offset * elem_size
                };

                let result = ctx.fresh_temp_cg();
                let mut indices: Vec<String> = Vec::new();
                indices.push(codegen_types::format_u64(byte_offset));
                ctx.emit_gep_cg(&result, "i8", &current, &indices);
                current = result;
                current_adt_def_id = Option::None;
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::Subslice { from, to: _, from_end: _ } => {
                // Get the element size using tracked HIR type for proper byte-offset calculation
                let elem_size = match &current_hir_type {
                    &Option::Some(ty_id) => {
                        get_element_size_from_hir_id(ctx, ty_id)
                    }
                    &Option::None => get_indexing_element_size(ctx, place.local),
                };

                // Calculate byte offset = from * element_size
                let byte_offset = from * elem_size;

                let result = ctx.fresh_temp_cg();
                let mut indices: Vec<String> = Vec::new();
                indices.push(codegen_types::format_u64(byte_offset));
                ctx.emit_gep_cg(&result, "i8", &current, &indices);
                current = result;
                current_adt_def_id = Option::None;
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::Downcast(variant_idx) => {
                // Enum downcast: project into variant data for a specific variant.
                ctx.write("    ; downcast to variant ");
                ctx.write_string(&codegen_types::format_u64(variant_idx as u64));
                ctx.write("\n");

                let result = ctx.fresh_temp_cg();

                // Only use struct GEP when the type has 2+ fields (discriminant + data).
                // Fallback types like { i64 } from Deref need byte-offset GEP.
                let fc = count_struct_fields(&current_base);
                if is_struct_or_array_type(&current_base) && fc >= 2 {
                    let mut indices: Vec<String> = Vec::new();
                    indices.push(common::make_string("0"));
                    // Skip discriminant at index 0, variant data at index 1
                    indices.push(common::make_string("1"));
                    ctx.emit_gep_cg(&result, current_base.as_str(), &current, &indices);
                } else {
                    // Scalar or fallback base type (e.g., heap-allocated locals where
                    // current_base is "ptr"). Try to resolve the actual enum LLVM type
                    // from the HIR type so we can use struct GEP with proper alignment.
                    let mut resolved = false;
                    match &current_hir_type {
                        &Option::Some(ty_id) => {
                            let actual_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, ty_id);
                            let afc = count_struct_fields(&actual_ty);
                            if is_struct_or_array_type(&actual_ty) && afc >= 2 {
                                let mut indices: Vec<String> = Vec::new();
                                indices.push(common::make_string("0"));
                                indices.push(common::make_string("1"));
                                ctx.emit_gep_cg(&result, actual_ty.as_str(), &current, &indices);
                                resolved = true;
                            }
                        }
                        &Option::None => {}
                    }
                    if !resolved {
                        // ICE: Enum downcast failed — could not determine variant
                        // payload offset. The base type is not a struct with 2+
                        // fields, and HIR type resolution also failed to produce
                        // a valid enum layout.
                        ctx.write("    ; ICE: enum downcast failed — base type '");
                        ctx.write_string(&current_base);
                        ctx.write("', variant ");
                        ctx.write(codegen_types::format_u64(variant_idx as u64).as_str());
                        ctx.write("\n");
                        ctx.write("    ; ICE: This is a compiler bug (codegen_expr: downcast fallback)\n");
                        ctx.write("    call void @llvm.trap()\n");
                        ctx.emit_unreachable();
                    }
                }
                current = result;
                downcast_variant = Option::Some(variant_idx);
                // Keep current_adt_def_id for field resolution after downcast
            }
        }
        i = i + 1;
    }

    current
}

/// Emits a generation validation check for a dereferenced pointer.
/// If the local has a tracked generation (i.e., it was region-allocated),
/// validates that the pointer's generation matches the expected generation.
/// No-ops for stack-allocated locals or locals without generation tracking.
fn emit_generation_check(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
    ptr_name: &codegen_ctx::CgName,
) {
    // Only emit check for locals with tracked generations
    let gen_alloca = match ctx.get_local_generation(local) {
        Option::Some(name) => name,
        Option::None => { return; }
    };

    // Load expected generation from stack alloca
    let expected_gen = ctx.fresh_temp_cg();
    ctx.emit_load_cg(&expected_gen, "i32", gen_alloca.as_str());

    // Convert pointer to i64 address for runtime call
    let ptr_addr = ctx.fresh_temp_cg();
    let ptr_str = cgname_to_string(ptr_name);
    ctx.emit_cast_cg(&ptr_addr, "ptrtoint", "ptr", ptr_str.as_str(), "i64");

    // Call blood_validate_generation(address, expected_generation) -> i32
    // Returns 0 if valid, 1 if stale
    let gen_result = ctx.fresh_temp_cg();
    ctx.begin_call(Option::Some(&gen_result), "i32", "@blood_validate_generation");
    ctx.call_arg_cg(true, "i64", &ptr_addr);
    ctx.call_arg_cg(false, "i32", &expected_gen);
    ctx.end_call();

    // Check if stale (result != 0)
    let is_stale = ctx.fresh_temp_cg();
    ctx.emit_icmp_cg2(&is_stale, "ne", "i32", &gen_result, "0");

    // Branch: stale -> panic, valid -> continue
    let stale_label = ctx.fresh_label_cg();
    let valid_label = ctx.fresh_label_cg();
    ctx.emit_cond_br_cg(&is_stale, &stale_label, &valid_label);

    // Stale path: get actual generation for diagnostic, then panic
    ctx.emit_label_cg(&stale_label);
    let actual_gen = ctx.fresh_temp_cg();
    ctx.begin_call(Option::Some(&actual_gen), "i32", "@blood_get_generation");
    ctx.call_arg_cg(true, "i64", &ptr_addr);
    ctx.end_call();
    ctx.begin_call(Option::None, "void", "@blood_stale_reference_panic");
    ctx.call_arg_cg(true, "i32", &expected_gen);
    ctx.call_arg_cg(false, "i32", &actual_gen);
    ctx.end_call();
    ctx.emit_unreachable();

    // Valid path: continue with dereferenced pointer
    ctx.emit_label_cg(&valid_label);
}

/// For a generic struct field, resolves the concrete LLVM type by matching
/// param/infer fields with the local's type args.
fn resolve_generic_field_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
    layout: &codegen_ctx::StructLayout,
    field_idx: usize,
) -> Option<String> {
    // Get the local's HIR type to find type args
    let hir_type_id = match ctx.get_local_hir_type(local) {
        Option::Some(ty_id) => ty_id,
        Option::None => { return Option::None; }
    };
    // Walk through Ref/Ptr to find the ADT
    let adt_type_id = unwrap_ref_type(hir_type_id);
    let adt_args = match type_intern::get_adt_args(adt_type_id) {
        Option::Some(args) => args,
        Option::None => { return Option::None; }
    };
    let interner = type_intern::type_interner();
    let args_len = interner.ty_list_len(adt_args);
    if args_len == 0 {
        return Option::None;
    }
    // Count which param index this field corresponds to
    let mut param_idx: usize = 0;
    let mut fi: usize = 0;
    while fi < layout.fields.len() {
        let is_param = match &layout.fields[fi].hir_type {
            &Option::Some(ht_id) => {
                type_intern::is_param_or_infer_id(ht_id)
            }
            &Option::None => false,
        };
        if fi == field_idx {
            if is_param && param_idx < args_len {
                let arg_id = interner.get_ty_list_element(adt_args, param_idx);
                return Option::Some(codegen_size::type_to_llvm_with_ctx_id(ctx, arg_id));
            }
            return Option::None;
        }
        if is_param {
            param_idx = param_idx + 1;
        }
        fi = fi + 1;
    }
    Option::None
}

/// Resolves the LLVM base type for a MIR local.
/// Returns the ADT's LLVM type if the local is a struct/enum, or a fallback type.
fn resolve_local_base_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> String {
    match ctx.get_local_hir_type(local) {
        Option::Some(ty_id) => {
            let hir_type = type_intern::ty_id_to_type(ty_id);
            let result = resolve_base_type_from_hir(ctx, &hir_type);
            // If resolve returned "ptr" (fallback for unknown ADT), the local might
            // be a builtin generic (Option<T>, Result<T,E>) not in the ADT registry.
            // Fall back to the alloca type which was computed correctly.
            let rb = result.as_bytes();
            if rb.len() == 3 && rb[0] == 112 && rb[1] == 116 && rb[2] == 114 {
                let alloca_type = ctx.get_local_type(local);
                if is_struct_or_array_type(&alloca_type) {
                    return alloca_type;
                }
            }
            // For generic ADTs (e.g., Wrapper<i32>), the registry returns the
            // unsubstituted layout (e.g., { i64 }), but the alloca was correctly
            // computed with concrete types (e.g., { i32 }). Prefer the alloca type
            // when they differ and the alloca is a struct type.
            let is_generic_adt = match &hir_type.kind {
                &hir_ty::TypeKind::Adt { def_id: _, ref args } => args.len() > 0,
                &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                    match &inner.as_ref().kind {
                        &hir_ty::TypeKind::Adt { def_id: _, ref args } => args.len() > 0,
                        _ => false,
                    }
                }
                _ => false,
            };
            if is_generic_adt {
                let alloca_type = ctx.get_local_type(local);
                if is_struct_or_array_type(&alloca_type) {
                    return alloca_type;
                }
            }
            result
        }
        Option::None => {
            let mut err_msg = common::make_string("local _");
            err_msg.push_str(codegen_types::format_u64(local.index as u64).as_str());
            err_msg.push_str(" has no HIR type, using fallback { i64 }");
            ctx.codegen_error(
                codegen_ctx::CodegenErrorKind::InternalError,
                err_msg,
            );
            common::make_string("{ i64 }")
        }
    }
}

/// Resolves the LLVM base type for a given HIR type, looking through references.
fn resolve_base_type_from_hir(
    ctx: &mut codegen_ctx::CodegenCtx,
    hir_type: &hir_ty::Type,
) -> String {
    match &hir_type.kind {
        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
            ctx.adt_llvm_type(def_id.index)
        }
        &hir_ty::TypeKind::Tuple(ref _elems) => {
            ctx.type_to_llvm_with_ctx(hir_type)
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            // Look through reference to get the pointed-to type
            resolve_base_type_from_hir(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            resolve_base_type_from_hir(ctx, inner.as_ref())
        }
        _ => {
            ctx.type_to_llvm_with_ctx(hir_type)
        }
    }
}

/// Resolves the ADT def_id for a MIR local, if it's an ADT type.
fn resolve_local_adt_def_id(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> Option<u32> {
    match ctx.get_local_hir_type(local) {
        Option::Some(ty_id) => {
            type_intern::resolve_adt_def_id_id(ty_id)
        }
        Option::None => Option::None,
    }
}

/// Returns true if the local's HIR type is a reference (Ref or Ptr).
fn is_local_ref_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> bool {
    match ctx.get_local_hir_type(local) {
        Option::Some(ty_id) => {
            let kind = type_intern::type_interner().get(ty_id);
            match kind {
                &type_intern::InternedTypeKind::Ref { inner: _, mutable: _ } => true,
                &type_intern::InternedTypeKind::Ptr { inner: _, mutable: _ } => true,
                _ => false,
            }
        }
        Option::None => false,
    }
}

/// Extracts the ADT def_id from an HIR type, looking through references.
fn resolve_adt_def_id_from_hir(hir_type: &hir_ty::Type) -> Option<u32> {
    match &hir_type.kind {
        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
            Option::Some(def_id.index)
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            resolve_adt_def_id_from_hir(inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            resolve_adt_def_id_from_hir(inner.as_ref())
        }
        _ => Option::None,
    }
}

/// Unwraps a reference type to get the inner type (TyId version).
/// Uses direct interner query — no Type tree reconstruction.
fn unwrap_ref_type(ty_id: type_intern::TyId) -> type_intern::TyId {
    type_intern::unwrap_ref_id(ty_id)
}

/// Applies a Deref projection to an HIR type, returning the inner type (TyId version).
/// Uses direct interner query — no Type tree reconstruction.
fn apply_deref_to_type(ty_id: type_intern::TyId) -> Option<type_intern::TyId> {
    type_intern::deref_id(ty_id)
}

/// Resolves the ADT def_id for a deref'd local (Ref<Adt>).
fn resolve_deref_adt_def_id(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
    deref_depth: usize,
) -> Option<u32> {
    match ctx.get_local_hir_type(local) {
        Option::Some(ty_id) => {
            let hir_type = type_intern::ty_id_to_type(ty_id);
            // Walk through Ref types
            let mut ty: &hir_ty::Type = &hir_type;
            let mut depth: usize = 0;
            while depth <= deref_depth {
                match &ty.kind {
                    &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                        ty = inner.as_ref();
                        depth = depth + 1;
                    }
                    &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
                        ty = inner.as_ref();
                        depth = depth + 1;
                    }
                    _ => {
                        return Option::None;
                    }
                }
            }
            // Now check if the dereferenced type is an ADT
            match &ty.kind {
                &hir_ty::TypeKind::Adt { def_id, args: _ } => {
                    Option::Some(def_id.index)
                }
                _ => Option::None,
            }
        }
        Option::None => Option::None,
    }
}

/// Resolves the LLVM type for a variant's payload.
fn resolve_variant_payload_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    adt_def_id: &Option<u32>,
    variant_idx: u32,
) -> String {
    match adt_def_id {
        &Option::Some(def_id) => {
            match ctx.lookup_enum(def_id) {
                Option::Some(enum_layout) => {
                    // Find the variant layout
                    let mut i: usize = 0;
                    while i < enum_layout.variants.len() {
                        if enum_layout.variants[i].variant_idx == variant_idx {
                            return clone_string(&enum_layout.variants[i].payload_llvm_type);
                        }
                        i = i + 1;
                    }
                    // Variant not found in registry, fallback
                    let mut err_msg = common::make_string("variant index ");
                    err_msg.push_str(codegen_types::format_u64(variant_idx as u64).as_str());
                    err_msg.push_str(" not found in enum def_id ");
                    err_msg.push_str(codegen_types::format_u64(def_id as u64).as_str());
                    ctx.codegen_error(codegen_ctx::CodegenErrorKind::VariantLookupFailed, err_msg);
                    common::make_string("{ i64 }")
                }
                Option::None => {
                    let mut err_msg = common::make_string("enum def_id ");
                    err_msg.push_str(codegen_types::format_u64(def_id as u64).as_str());
                    err_msg.push_str(" not found in ADT registry");
                    ctx.codegen_error(codegen_ctx::CodegenErrorKind::AdtLookupFailed, err_msg);
                    common::make_string("{ i64 }")
                }
            }
        }
        &Option::None => common::make_string("{ i64 }"),
    }
}

/// Returns the size of the element type if known, or 8 (pointer size) as default.
fn get_indexing_element_size(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> u64 {
    match ctx.get_local_hir_type(local) {
        Option::Some(ty_id) => {
            get_element_size_from_hir_id(ctx, ty_id)
        }
        Option::None => 8, // Default to pointer size
    }
}

/// Extracts the element size from an HIR type (TyId) that can be indexed.
fn get_element_size_from_hir_id(ctx: &mut codegen_ctx::CodegenCtx, ty_id: type_intern::TyId) -> u64 {
    let kind = type_intern::type_interner().get(ty_id);
    match kind {
        &type_intern::InternedTypeKind::Array { element, size: _ } => {
            codegen_size::type_size_with_ctx_id(ctx, element)
        }
        &type_intern::InternedTypeKind::Slice { element } => {
            codegen_size::type_size_with_ctx_id(ctx, element)
        }
        &type_intern::InternedTypeKind::Adt { def_id: _, args } => {
            // Vec<T> has T as first type argument
            let interner = type_intern::type_interner();
            let arg_len = interner.ty_list_len(args);
            if arg_len > 0 {
                let first_arg = interner.get_ty_list_element(args, 0);
                codegen_size::type_size_with_ctx_id(ctx, first_arg)
            } else {
                8 // Default to pointer size
            }
        }
        &type_intern::InternedTypeKind::Ref { inner, mutable: _ } => {
            // Look through reference
            get_element_size_from_hir_id(ctx, inner)
        }
        &type_intern::InternedTypeKind::Ptr { inner, mutable: _ } => {
            // Look through pointer
            get_element_size_from_hir_id(ctx, inner)
        }
        &type_intern::InternedTypeKind::Primitive(hir_ty::PrimitiveTy::Str) => {
            // &str indexing accesses individual bytes
            1
        }
        _ => 8, // Default to pointer size
    }
}

/// Returns true if the given place is an Index projection into a &str type.
/// Used to determine when byte→char zero-extension is needed after loading.
fn is_str_index_place(ctx: &mut codegen_ctx::CodegenCtx, place: &mir_types::Place) -> bool {
    // Check if any projection is an Index
    let mut has_index = false;
    let mut pi: usize = 0;
    while pi < place.projection.len() {
        match &place.projection[pi] {
            &mir_types::PlaceElem::Index(_) => { has_index = true; }
            _ => {}
        }
        pi = pi + 1;
    }
    if !has_index { return false; }
    // Check if the local's HIR type is &str or str
    match ctx.get_local_hir_type(place.local) {
        Option::Some(ty_id) => {
            is_str_ty_id(ty_id)
        }
        Option::None => false,
    }
}

/// Returns true if the TyId is &str or str (looking through references).
fn is_str_ty_id(ty_id: type_intern::TyId) -> bool {
    let kind = type_intern::type_interner().get(ty_id);
    match kind {
        &type_intern::InternedTypeKind::Primitive(hir_ty::PrimitiveTy::Str) => true,
        &type_intern::InternedTypeKind::Ref { inner, mutable: _ } => is_str_ty_id(inner),
        _ => false,
    }
}

/// Resolves the LLVM element type for an indexing operation on a container HIR type.
/// For Vec<T>, returns the LLVM type of T. For Array/Slice, returns element type.
fn resolve_index_element_type(ctx: &mut codegen_ctx::CodegenCtx, container_ty: &hir_ty::Type) -> String {
    match &container_ty.kind {
        &hir_ty::TypeKind::Array { ref element, size: _ } => {
            codegen_size::type_to_llvm_with_ctx(ctx, element.as_ref())
        }
        &hir_ty::TypeKind::Slice { ref element } => {
            codegen_size::type_to_llvm_with_ctx(ctx, element.as_ref())
        }
        &hir_ty::TypeKind::Adt { def_id: _, ref args } => {
            // Vec<T> has T as first type argument
            if args.len() > 0 {
                codegen_size::type_to_llvm_with_ctx(ctx, &args[0])
            } else {
                common::make_string("i64")
            }
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            resolve_index_element_type(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            resolve_index_element_type(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Primitive(hir_ty::PrimitiveTy::Str) => {
            // &str indexing accesses individual bytes (i8)
            common::make_string("i8")
        }
        _ => common::make_string("i64"),
    }
}

// ============================================================
// Rvalue Codegen
// ============================================================

/// Generates LLVM IR for an rvalue, storing result at dest.
pub fn emit_rvalue(
    ctx: &mut codegen_ctx::CodegenCtx,
    dest: &str,
    rvalue: &mir_types::Rvalue,
) {
    match rvalue {
        &mir_types::Rvalue::Use(ref operand) => {
            let (val, ty) = emit_operand_typed(ctx, operand);
            // Skip store for unit type {} — it has zero size in LLVM
            if !str_eq(ty.as_str(), "{}") {
                ctx.emit_store(ty.as_str(), val.as_str(), dest);
            }
        }
        &mir_types::Rvalue::Ref { ref place, mutable: _ } => {
            let addr = emit_place_data_ptr(ctx, place);
            ctx.emit_store("ptr", addr.as_str(), dest);
        }
        &mir_types::Rvalue::BinaryOp { op: ref bin_op, ref left, ref right } => {
            // Get typed operands
            let (left_val, left_ty) = emit_operand_typed(ctx, left);
            let (right_val, right_ty) = emit_operand_typed(ctx, right);
            // Determine signedness from the left operand's type
            let is_signed = operand_is_signed(ctx, left);
            // Coerce right operand to match left type if they differ
            let coerced_right = if !string_eq_str(left_ty.as_str(), right_ty.as_str()) {
                let left_w = llvm_int_bit_width(left_ty.as_str());
                let right_w = llvm_int_bit_width(right_ty.as_str());
                if left_w > 0 && right_w > 0 {
                    // Both are integer types - truncate or extend
                    let cast = ctx.fresh_temp_cg();
                    if right_w > left_w {
                        ctx.emit_cast_cg(&cast, "trunc", right_ty.as_str(), right_val.as_str(), left_ty.as_str());
                    } else {
                        if is_signed {
                            ctx.emit_cast_cg(&cast, "sext", right_ty.as_str(), right_val.as_str(), left_ty.as_str());
                        } else {
                            ctx.emit_cast_cg(&cast, "zext", right_ty.as_str(), right_val.as_str(), left_ty.as_str());
                        }
                    }
                    cgname_to_string(&cast)
                } else {
                    right_val
                }
            } else {
                right_val
            };
            // Use the left operand's type for the binary operation
            let result = emit_binop_typed(ctx, bin_op, &left_val, &coerced_right, left_ty.as_str(), is_signed);
            // For comparison operations, result is i1 (bool)
            if bin_op.is_comparison() {
                ctx.emit_store_cg("i1", &result, dest);
            } else {
                ctx.emit_store_cg(left_ty.as_str(), &result, dest);
            }
        }
        &mir_types::Rvalue::UnaryOp { op: ref un_op, ref operand } => {
            let (val, ty) = emit_operand_typed(ctx, operand);
            let result = emit_unop_typed(ctx, un_op, &val, ty.as_str());
            ctx.emit_store_cg(ty.as_str(), &result, dest);
        }
        &mir_types::Rvalue::AddressOf { ref place, mutable: _ } => {
            let addr = emit_place_data_ptr(ctx, place);
            ctx.emit_store("ptr", addr.as_str(), dest);
        }
        &mir_types::Rvalue::ArrayToSlice { ref array_ref, array_len } => {
            // Convert array ref to fat pointer (ptr + len).
            // Slices are represented as { ptr, i64 } in LLVM IR.
            let arr_val = emit_operand(ctx, array_ref);

            // Store pointer at offset 0 of the fat pointer
            let ptr_field = ctx.fresh_temp_cg();
            ctx.begin_gep_str(&ptr_field, "{ ptr, i64 }", dest);
            ctx.gep_ptr_offset(0);
            ctx.gep_field(0);
            ctx.end_gep();
            ctx.emit_store_str_cg("ptr", arr_val.as_str(), &ptr_field);

            // Store length at offset 1 of the fat pointer
            let len_field = ctx.fresh_temp_cg();
            ctx.begin_gep_str(&len_field, "{ ptr, i64 }", dest);
            ctx.gep_ptr_offset(0);
            ctx.gep_field(1);
            ctx.end_gep();
            let len_val = codegen_types::format_u64(array_len);
            ctx.emit_store_str_cg("i64", len_val.as_str(), &len_field);
        }
        &mir_types::Rvalue::ZeroInit(ref ty) => {
            // Zero-initialize the destination
            let llvm_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, *ty);
            // Skip store for unit type {} — it has zero size in LLVM
            if !str_eq(llvm_ty.as_str(), "{}") {
                let zero = get_zero_value(llvm_ty.as_str());
                ctx.emit_store(llvm_ty.as_str(), zero.as_str(), dest);
            }
        }
        &mir_types::Rvalue::Cast { ref operand, ref target_ty } => {
            // Get source type from operand
            let (val, src_ty) = emit_operand_typed(ctx, operand);
            let tgt_llvm = codegen_size::type_to_llvm_with_ctx_id(ctx, *target_ty);
            // Use the type-aware cast if we have source type info.
            // For Copy/Move operands, look up the local's HIR type so we get
            // correct sign-awareness (zext for unsigned, sext for signed).
            let src_ty_opt = match operand {
                &mir_types::Operand::Constant(ref constant) => Option::Some(type_intern::ty_id_to_type(constant.ty)),
                &mir_types::Operand::Copy(ref place) => {
                    match ctx.get_local_hir_type(place.local) {
                        Option::Some(ty_id) => Option::Some(type_intern::ty_id_to_type(ty_id)),
                        Option::None => Option::None,
                    }
                }
                &mir_types::Operand::Move(ref place) => {
                    match ctx.get_local_hir_type(place.local) {
                        Option::Some(ty_id) => Option::Some(type_intern::ty_id_to_type(ty_id)),
                        Option::None => Option::None,
                    }
                }
            };
            let target_hir_ty = type_intern::ty_id_to_type(*target_ty);
            let result = match src_ty_opt {
                Option::Some(ref src_type) => emit_cast_with_types(ctx, &val, src_type, &target_hir_ty),
                Option::None => {
                    // Fallback: construct approximate source type from LLVM type
                    emit_cast_from_llvm_types(ctx, &val, src_ty.as_str(), tgt_llvm.as_str())
                }
            };
            ctx.emit_store_cg(tgt_llvm.as_str(), &result, dest);
        }
        &mir_types::Rvalue::Aggregate { ref kind, ref operands } => {
            emit_aggregate(ctx, dest, kind, operands);
        }
        &mir_types::Rvalue::Len(ref place) => {
            // For slices - load the length field
            let mut ptr = emit_place_data_ptr(ctx, place);
            // Auto-deref for Ref-typed locals: the alloca (or heap slot) holds a pointer
            // to the actual data, not the data itself. Load through the pointer first.
            if place.projection.len() == 0 {
                match ctx.get_local_hir_type(place.local) {
                    Option::Some(ty_id) => {
                        if type_intern::is_ref_id(ty_id) {
                            let deref = ctx.fresh_temp_cg();
                            ctx.emit_load_cg(&deref, "ptr", ptr.as_str());
                            ptr = cgname_to_string(&deref);
                        }
                    }
                    Option::None => {}
                }
            }
            let len_ptr = ctx.fresh_temp_cg();
            ctx.begin_gep_str(&len_ptr, "{ ptr, i64 }", ptr.as_str());
            ctx.gep_ptr_offset(0);
            ctx.gep_field(1);
            ctx.end_gep();
            let len_val = ctx.fresh_temp_cg();
            ctx.emit_load_cg2(&len_val, "i64", &len_ptr);
            ctx.emit_store_cg("i64", &len_val, dest);
        }
        &mir_types::Rvalue::Discriminant(ref place) => {
            // Load discriminant field of enum
            let mut ptr = emit_place_data_ptr(ctx, place);
            // Auto-deref for Ref-typed locals: the alloca (or heap slot) holds a pointer
            // to the actual enum data, not the enum itself. Load through the pointer first.
            if place.projection.len() == 0 {
                match ctx.get_local_hir_type(place.local) {
                    Option::Some(ty_id) => {
                        if type_intern::is_ref_id(ty_id) {
                            let deref = ctx.fresh_temp_cg();
                            ctx.emit_load_cg(&deref, "ptr", ptr.as_str());
                            ptr = cgname_to_string(&deref);
                        }
                    }
                    Option::None => {}
                }
            }

            // Try to look up enum layout for correct discriminant type
            let mut discr_ty = common::make_string("i64");
            let mut enum_llvm_ty = common::make_string("{ i64, i64 }");
            let mut found_enum = false;

            match ctx.get_local_hir_type(place.local) {
                Option::Some(ty_id) => {
                    // Extract the enum DefId, unwrapping through Ref/Ptr via interner.
                    let enum_def_idx = type_intern::resolve_adt_def_id_id(ty_id);
                    match enum_def_idx {
                        Option::Some(def_idx) => {
                            match ctx.lookup_enum(def_idx) {
                                Option::Some(layout) => {
                                    discr_ty = clone_string(&layout.discriminant_type);
                                    enum_llvm_ty = clone_string(&layout.llvm_type);
                                    found_enum = true;
                                }
                                Option::None => {}
                            }
                        }
                        Option::None => {}
                    }
                }
                Option::None => {}
            }

            if found_enum {
                // GEP to discriminant field (index 0) of the enum type
                let discr_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&discr_ptr, enum_llvm_ty.as_str(), ptr.as_str());
                ctx.gep_ptr_offset(0);
                ctx.gep_field(0);
                ctx.end_gep();
                let discr_val = ctx.fresh_temp_cg();
                ctx.emit_load_cg2(&discr_val, discr_ty.as_str(), &discr_ptr);
                // Extend discriminant to destination type if needed (dest is typically i64)
                if string_eq_str(discr_ty.as_str(), "i64") {
                    ctx.emit_store_cg(discr_ty.as_str(), &discr_val, dest);
                } else {
                    // Zero-extend discriminant to i64 for use in switch
                    let extended = ctx.fresh_temp_cg();
                    ctx.emit_cast_cg2(&extended, "zext", discr_ty.as_str(), &discr_val, "i64");
                    ctx.emit_store_cg("i64", &extended, dest);
                }
            } else {
                // ICE: Enum not found in ADT registry during discriminant read.
                // All enums must be registered before codegen so their discriminant
                // type and layout are known. An unregistered enum here indicates a
                // missing registration in the codegen ADT setup pass.
                ctx.write("    ; ICE: discriminant read on unregistered enum, local=");
                ctx.write(codegen_types::format_u64(place.local.index as u64).as_str());
                ctx.write("\n");
                ctx.write("    ; ICE: This is a compiler bug (codegen_expr: discriminant load fallback)\n");
                ctx.write("    call void @llvm.trap()\n");
                ctx.emit_unreachable();
            }
        }
    }
}

/// Gets the zero value for an LLVM type.
fn get_zero_value(llvm_ty: &str) -> String {
    if string_starts_with(llvm_ty, "float") {
        common::make_string("0.0")
    } else if string_starts_with(llvm_ty, "double") {
        common::make_string("0.0")
    } else if string_starts_with(llvm_ty, "ptr") {
        common::make_string("null")
    } else if string_starts_with(llvm_ty, "{") {
        common::make_string("zeroinitializer")
    } else if string_starts_with(llvm_ty, "[") {
        common::make_string("zeroinitializer")
    } else {
        common::make_string("0")
    }
}

/// Emits a cast based only on LLVM type strings.
fn emit_cast_from_llvm_types(
    ctx: &mut codegen_ctx::CodegenCtx,
    val: &String,
    src_ty: &str,
    tgt_ty: &str,
) -> codegen_ctx::CgName {
    // Quick check: if same type, just return value
    if string_eq_str(src_ty, tgt_ty) {
        return codegen_ctx::CgName::Str(clone_string(val));
    }

    let result = ctx.fresh_temp_cg();

    let src_is_float = string_starts_with(src_ty, "float") || string_starts_with(src_ty, "double");
    let tgt_is_float = string_starts_with(tgt_ty, "float") || string_starts_with(tgt_ty, "double");
    let src_is_ptr = string_starts_with(src_ty, "ptr");
    let tgt_is_ptr = string_starts_with(tgt_ty, "ptr");
    // Fat pointers (structs like { ptr, i64 }) should also be treated as ptr-like
    let src_is_fat_ptr = string_starts_with(src_ty, "{");

    if src_is_float && tgt_is_float {
        // Float to float
        let src_size = if string_starts_with(src_ty, "float") { 4u64 } else { 8u64 };
        let tgt_size = if string_starts_with(tgt_ty, "float") { 4u64 } else { 8u64 };
        if tgt_size < src_size {
            ctx.emit_cast_cg(&result, "fptrunc", src_ty, val.as_str(), tgt_ty);
        } else if tgt_size > src_size {
            ctx.emit_cast_cg(&result, "fpext", src_ty, val.as_str(), tgt_ty);
        } else {
            return codegen_ctx::CgName::Str(clone_string(val));
        }
    } else if !src_is_float && tgt_is_float {
        // Int to float (default signed)
        ctx.emit_cast_cg(&result, "sitofp", src_ty, val.as_str(), tgt_ty);
    } else if src_is_float && !tgt_is_float {
        // Float to int (default signed)
        ctx.emit_cast_cg(&result, "fptosi", src_ty, val.as_str(), tgt_ty);
    } else if src_is_fat_ptr && tgt_is_ptr {
        // Fat pointer to thin pointer: extract the data pointer (field 0)
        ctx.write_indent();
        ctx.write_cgname(&result);
        ctx.write(" = extractvalue ");
        ctx.write(src_ty);
        ctx.write(" ");
        ctx.write_string(val);
        ctx.write(", 0\n");
    } else if src_is_fat_ptr && !tgt_is_ptr {
        // Fat pointer to int: extract ptr, then ptrtoint
        let extracted = ctx.fresh_temp_cg();
        ctx.write_indent();
        ctx.write_cgname(&extracted);
        ctx.write(" = extractvalue ");
        ctx.write(src_ty);
        ctx.write(" ");
        ctx.write_string(val);
        ctx.write(", 0\n");
        ctx.emit_cast_cg2(&result, "ptrtoint", "ptr", &extracted, tgt_ty);
    } else if src_is_ptr && !tgt_is_ptr {
        // Pointer to int
        ctx.emit_cast_cg(&result, "ptrtoint", src_ty, val.as_str(), tgt_ty);
    } else if !src_is_ptr && !src_is_fat_ptr && tgt_is_ptr {
        // Int to pointer (but not fat pointer source)
        ctx.emit_cast_cg(&result, "inttoptr", src_ty, val.as_str(), tgt_ty);
    } else if src_is_ptr && tgt_is_ptr {
        // Pointer to pointer - bitcast
        ctx.emit_cast_cg(&result, "bitcast", src_ty, val.as_str(), tgt_ty);
    } else {
        // Int to int - determine by size
        let src_size = get_int_type_size(src_ty);
        let tgt_size = get_int_type_size(tgt_ty);
        if tgt_size < src_size {
            ctx.emit_cast_cg(&result, "trunc", src_ty, val.as_str(), tgt_ty);
        } else if tgt_size > src_size {
            // Default to sign extend
            ctx.emit_cast_cg(&result, "sext", src_ty, val.as_str(), tgt_ty);
        } else {
            return codegen_ctx::CgName::Str(clone_string(val));
        }
    }

    result
}

/// Gets the size in bits of an LLVM integer type (e.g., "i32" -> 32).
fn get_int_type_size(llvm_ty: &str) -> u64 {
    let bytes = llvm_ty.as_bytes();
    if bytes.len() < 2 {
        return 64; // Default
    }
    if bytes[0] != 105 {
        return 64; // Not 'i'
    }
    // Parse number after 'i'
    let mut n: u64 = 0;
    let mut i: usize = 1;
    while i < bytes.len() {
        let b = bytes[i];
        if b >= 48 && b <= 57 {
            n = n * 10 + ((b - 48) as u64);
        } else {
            break;
        }
        i = i + 1;
    }
    if n == 0 { 64 } else { n }
}

/// Returns the bit width for an LLVM integer type string (e.g., "i32" -> 32).
/// Checks if an LLVM type string is a struct or array type (starts with '{' or '[').
fn is_struct_or_array_type(ty: &String) -> bool {
    let bytes = ty.as_bytes();
    if bytes.len() > 0 {
        bytes[0] == 123 || bytes[0] == 91 // '{' or '['
    } else {
        false
    }
}

/// Returns true if the LLVM type looks like a Vec/container type whose first
/// field is a data pointer. These types have layout { ptr, ... } and require
/// loading the data pointer before indexing into the heap-allocated array.
fn is_vec_like_type(ty: &String) -> bool {
    // Check for "{ ptr" at the start — this matches Vec<T> = { ptr, i64, i64 }
    // and similar container types where field 0 is the heap data pointer.
    let bytes = ty.as_bytes();
    if bytes.len() >= 5 {
        bytes[0] == 123 && bytes[1] == 32 && bytes[2] == 112 && bytes[3] == 116 && bytes[4] == 114
        // '{' ' ' 'p' 't' 'r'
    } else {
        false
    }
}

/// Returns 0 for non-integer types.
fn llvm_int_bit_width(ty: &str) -> u32 {
    let bytes = ty.as_bytes();
    if bytes.len() < 2 {
        return 0;
    }
    if bytes[0] != 105 { // 'i'
        return 0;
    }
    // Parse the number after 'i'
    let mut val: u32 = 0;
    let mut idx: usize = 1;
    while idx < bytes.len() {
        let b = bytes[idx];
        if b >= 48 && b <= 57 {
            val = val * 10 + ((b - 48) as u32);
        } else {
            return 0; // Non-digit character means not a simple integer type
        }
        idx = idx + 1;
    }
    val
}

/// Extracts the first field type from a struct type string.
/// E.g., "{ i8 }" -> "i8", "{ i64, ptr }" -> "i64".
/// Returns "i64" as fallback if parsing fails.
fn extract_first_field_type(struct_ty: &str) -> String {
    let bytes = struct_ty.as_bytes();
    // Find start: skip "{ " (or just past '{')
    let mut start: usize = 0;
    let mut i: usize = 0;
    while i < bytes.len() {
        if bytes[i] == 123 {
            // '{'
            start = i + 1;
            // Skip whitespace
            while start < bytes.len() && bytes[start] == 32 {
                start = start + 1;
            }
            break;
        }
        i = i + 1;
    }
    // Find end: first ',', ' }', or '}'
    let mut end: usize = start;
    while end < bytes.len() {
        if bytes[end] == 44 || bytes[end] == 125 {
            // ',' or '}'
            break;
        }
        end = end + 1;
    }
    // Trim trailing whitespace
    while end > start && bytes[end - 1] == 32 {
        end = end - 1;
    }
    if end > start {
        let mut result = String::new();
        let mut j: usize = start;
        while j < end {
            result.push(bytes[j] as char);
            j = j + 1;
        }
        result
    } else {
        common::make_string("i64")
    }
}

/// Counts the number of top-level fields in a struct type string.
/// E.g., "{ i8 }" -> 1, "{ i64, ptr }" -> 2, "{ i8, [17 x i8] }" -> 2.
/// Returns 0 for non-struct types.
fn count_struct_fields(ty: &String) -> u32 {
    let bytes = ty.as_bytes();
    if bytes.len() < 2 || bytes[0] != 123 {
        return 0;
    }
    // Count commas at nesting depth 0 (inside the outermost braces)
    let mut count: u32 = 1; // At least 1 field if it's a struct
    let mut depth: u32 = 0;
    let mut i: usize = 1; // Skip opening '{'
    while i < bytes.len() {
        let b = bytes[i];
        if b == 123 || b == 91 {
            // '{' or '['
            depth = depth + 1;
        } else if b == 125 || b == 93 {
            // '}' or ']'
            if depth > 0 {
                depth = depth - 1;
            } else {
                break; // End of outermost struct
            }
        } else if b == 44 && depth == 0 {
            // ',' at top level
            count = count + 1;
        }
        i = i + 1;
    }
    // Handle empty struct "{}"
    if bytes.len() == 2 && bytes[0] == 123 && bytes[1] == 125 {
        return 0;
    }
    count
}

/// Compares string with &str.
fn string_eq_str(s: &str, other: &str) -> bool {
    let s_bytes = s.as_bytes();
    let other_bytes = other.as_bytes();
    if s_bytes.len() != other_bytes.len() {
        return false;
    }
    let mut i: usize = 0;
    while i < s_bytes.len() {
        if s_bytes[i] != other_bytes[i] {
            return false;
        }
        i = i + 1;
    }
    true
}

/// Emits a binary operation, returning the result value.
/// Uses i64 as the default type and assumes signed (legacy behavior).
fn emit_binop(
    ctx: &mut codegen_ctx::CodegenCtx,
    bin_op: &mir_types::MirBinOp,
    left: &String,
    right: &String,
) -> codegen_ctx::CgName {
    emit_binop_typed(ctx, bin_op, left, right, "i64", true)
}

/// Emits a binary operation with explicit type, returning the result value.
/// Handles both integer and floating-point operations based on the type.
/// The `signed` parameter indicates whether the operands are signed integers
/// (used for choosing sdiv vs udiv, srem vs urem, slt vs ult, etc.).
pub fn emit_binop_typed(
    ctx: &mut codegen_ctx::CodegenCtx,
    bin_op: &mir_types::MirBinOp,
    left: &String,
    right: &String,
    llvm_ty: &str,
    signed: bool,
) -> codegen_ctx::CgName {
    // If the type is an aggregate (struct), extract the first field for comparison.
    // LLVM icmp/binops don't work on aggregate types.
    let ty_bytes = llvm_ty.as_bytes();
    if ty_bytes.len() > 0 && ty_bytes[0] == 123 {
        // Aggregate type - extract first element and compare as that type
        let inner_ty = extract_first_field_type(llvm_ty);
        let left_elem_cg = ctx.fresh_temp_cg();
        ctx.write_indent();
        ctx.write_cgname(&left_elem_cg);
        ctx.write(" = extractvalue ");
        ctx.write(llvm_ty);
        ctx.write(" ");
        ctx.write_string(left);
        ctx.write(", 0\n");
        let left_elem = cgname_to_string(&left_elem_cg);
        let right_elem_cg = ctx.fresh_temp_cg();
        ctx.write_indent();
        ctx.write_cgname(&right_elem_cg);
        ctx.write(" = extractvalue ");
        ctx.write(llvm_ty);
        ctx.write(" ");
        ctx.write_string(right);
        ctx.write(", 0\n");
        let right_elem = cgname_to_string(&right_elem_cg);
        return emit_binop_typed(ctx, bin_op, &left_elem, &right_elem, inner_ty.as_str(), signed);
    }

    let result = ctx.fresh_temp_cg();
    let l = left.as_str();
    let r = right.as_str();

    // Check if this is a floating-point type
    let is_float = string_starts_with(llvm_ty, "float") || string_starts_with(llvm_ty, "double");

    if is_float {
        // Floating-point operations
        match bin_op {
            &mir_types::MirBinOp::Add => ctx.emit_binop_cg(&result, "fadd", llvm_ty, l, r),
            &mir_types::MirBinOp::Sub => ctx.emit_binop_cg(&result, "fsub", llvm_ty, l, r),
            &mir_types::MirBinOp::Mul => ctx.emit_binop_cg(&result, "fmul", llvm_ty, l, r),
            &mir_types::MirBinOp::Div => ctx.emit_binop_cg(&result, "fdiv", llvm_ty, l, r),
            &mir_types::MirBinOp::Rem => ctx.emit_binop_cg(&result, "frem", llvm_ty, l, r),
            // Floating-point comparisons use ordered comparisons (NaN returns false)
            &mir_types::MirBinOp::Eq => ctx.emit_fcmp_cg(&result, "oeq", llvm_ty, l, r),
            &mir_types::MirBinOp::Ne => ctx.emit_fcmp_cg(&result, "one", llvm_ty, l, r),
            &mir_types::MirBinOp::Lt => ctx.emit_fcmp_cg(&result, "olt", llvm_ty, l, r),
            &mir_types::MirBinOp::Le => ctx.emit_fcmp_cg(&result, "ole", llvm_ty, l, r),
            &mir_types::MirBinOp::Gt => ctx.emit_fcmp_cg(&result, "ogt", llvm_ty, l, r),
            &mir_types::MirBinOp::Ge => ctx.emit_fcmp_cg(&result, "oge", llvm_ty, l, r),
            // Bitwise operations don't apply to floats - emit error
            &mir_types::MirBinOp::BitAnd => {
                ctx.codegen_error_with_note(
                    codegen_ctx::CodegenErrorKind::UnsupportedOperation,
                    common::make_string("bitwise AND on float type"),
                    common::make_string("bitwise operations require integer operands; cast to integer first"),
                );
                ctx.write("    ; ERROR: bitwise AND on float\n");
                ctx.emit_binop_cg(&result, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::BitOr => {
                ctx.codegen_error_with_note(
                    codegen_ctx::CodegenErrorKind::UnsupportedOperation,
                    common::make_string("bitwise OR on float type"),
                    common::make_string("bitwise operations require integer operands; cast to integer first"),
                );
                ctx.write("    ; ERROR: bitwise OR on float\n");
                ctx.emit_binop_cg(&result, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::BitXor => {
                ctx.codegen_error_with_note(
                    codegen_ctx::CodegenErrorKind::UnsupportedOperation,
                    common::make_string("bitwise XOR on float type"),
                    common::make_string("bitwise operations require integer operands; cast to integer first"),
                );
                ctx.write("    ; ERROR: bitwise XOR on float\n");
                ctx.emit_binop_cg(&result, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::Shl => {
                ctx.write("    ; ERROR: shift left on float\n");
                ctx.emit_binop_cg(&result, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::Shr => {
                ctx.write("    ; ERROR: shift right on float\n");
                ctx.emit_binop_cg(&result, "fadd", llvm_ty, l, "0.0");
            }
            // Checked operations - floats don't have overflow, treat as unchecked
            &mir_types::MirBinOp::AddChecked => ctx.emit_binop_cg(&result, "fadd", llvm_ty, l, r),
            &mir_types::MirBinOp::SubChecked => ctx.emit_binop_cg(&result, "fsub", llvm_ty, l, r),
            &mir_types::MirBinOp::MulChecked => ctx.emit_binop_cg(&result, "fmul", llvm_ty, l, r),
        }
    } else {
        // Integer operations with correct signedness
        let is_unsigned = !signed;

        match bin_op {
            &mir_types::MirBinOp::Add => ctx.emit_binop_cg(&result, "add", llvm_ty, l, r),
            &mir_types::MirBinOp::Sub => ctx.emit_binop_cg(&result, "sub", llvm_ty, l, r),
            &mir_types::MirBinOp::Mul => ctx.emit_binop_cg(&result, "mul", llvm_ty, l, r),
            &mir_types::MirBinOp::Div => {
                if is_unsigned {
                    ctx.emit_binop_cg(&result, "udiv", llvm_ty, l, r);
                } else {
                    ctx.emit_binop_cg(&result, "sdiv", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Rem => {
                if is_unsigned {
                    ctx.emit_binop_cg(&result, "urem", llvm_ty, l, r);
                } else {
                    ctx.emit_binop_cg(&result, "srem", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::BitAnd => ctx.emit_binop_cg(&result, "and", llvm_ty, l, r),
            &mir_types::MirBinOp::BitOr => ctx.emit_binop_cg(&result, "or", llvm_ty, l, r),
            &mir_types::MirBinOp::BitXor => ctx.emit_binop_cg(&result, "xor", llvm_ty, l, r),
            &mir_types::MirBinOp::Shl => ctx.emit_binop_cg(&result, "shl", llvm_ty, l, r),
            &mir_types::MirBinOp::Shr => {
                if is_unsigned {
                    ctx.emit_binop_cg(&result, "lshr", llvm_ty, l, r);
                } else {
                    ctx.emit_binop_cg(&result, "ashr", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Eq => ctx.emit_icmp_cg(&result, "eq", llvm_ty, l, r),
            &mir_types::MirBinOp::Ne => ctx.emit_icmp_cg(&result, "ne", llvm_ty, l, r),
            &mir_types::MirBinOp::Lt => {
                if is_unsigned {
                    ctx.emit_icmp_cg(&result, "ult", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp_cg(&result, "slt", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Le => {
                if is_unsigned {
                    ctx.emit_icmp_cg(&result, "ule", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp_cg(&result, "sle", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Gt => {
                if is_unsigned {
                    ctx.emit_icmp_cg(&result, "ugt", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp_cg(&result, "sgt", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Ge => {
                if is_unsigned {
                    ctx.emit_icmp_cg(&result, "uge", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp_cg(&result, "sge", llvm_ty, l, r);
                }
            }
            // Checked operations - use LLVM overflow intrinsics and trap on overflow
            &mir_types::MirBinOp::AddChecked => {
                if is_unsigned {
                    emit_checked_binop(ctx, &result, "uadd", llvm_ty, l, r);
                } else {
                    emit_checked_binop(ctx, &result, "sadd", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::SubChecked => {
                if is_unsigned {
                    emit_checked_binop(ctx, &result, "usub", llvm_ty, l, r);
                } else {
                    emit_checked_binop(ctx, &result, "ssub", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::MulChecked => {
                if is_unsigned {
                    emit_checked_binop(ctx, &result, "umul", llvm_ty, l, r);
                } else {
                    emit_checked_binop(ctx, &result, "smul", llvm_ty, l, r);
                }
            }
        }
    }

    result
}

/// Emits a checked binary operation using LLVM overflow intrinsics.
/// On overflow, traps with @llvm.trap().
///
/// Uses intrinsics like @llvm.sadd.with.overflow.i64, @llvm.ssub.with.overflow.i64, etc.
/// These return { iN, i1 } where the second element is the overflow flag.
fn emit_checked_binop(
    ctx: &mut codegen_ctx::CodegenCtx,
    result: &codegen_ctx::CgName,
    intrinsic_base: &str,
    llvm_ty: &str,
    left: &str,
    right: &str,
) {
    // Build the intrinsic name: @llvm.sadd.with.overflow.i64
    let mut intrinsic_name = common::make_string("@llvm.");
    intrinsic_name.push_str(intrinsic_base);
    intrinsic_name.push_str(".with.overflow.");
    intrinsic_name.push_str(llvm_ty);

    // Build the return type: { i64, i1 }
    let mut ret_ty = common::make_string("{ ");
    ret_ty.push_str(llvm_ty);
    ret_ty.push_str(", i1 }");

    // Call the intrinsic
    let overflow_result = ctx.fresh_temp_cg();
    ctx.write_indent();
    ctx.write_cgname(&overflow_result);
    ctx.write(" = call ");
    ctx.write_string(&ret_ty);
    ctx.write(" ");
    ctx.write_string(&intrinsic_name);
    ctx.write("(");
    ctx.write(llvm_ty);
    ctx.write(" ");
    ctx.write(left);
    ctx.write(", ");
    ctx.write(llvm_ty);
    ctx.write(" ");
    ctx.write(right);
    ctx.write(")\n");

    // Extract the result value
    ctx.write_indent();
    ctx.write_cgname(result);
    ctx.write(" = extractvalue ");
    ctx.write_string(&ret_ty);
    ctx.write(" ");
    ctx.write_cgname(&overflow_result);
    ctx.write(", 0\n");

    // Extract the overflow flag
    let overflow_flag = ctx.fresh_temp_cg();
    ctx.write_indent();
    ctx.write_cgname(&overflow_flag);
    ctx.write(" = extractvalue ");
    ctx.write_string(&ret_ty);
    ctx.write(" ");
    ctx.write_cgname(&overflow_result);
    ctx.write(", 1\n");

    // Emit conditional trap on overflow using basic blocks
    let trap_label = ctx.fresh_label_cg();
    let continue_label = ctx.fresh_label_cg();

    ctx.emit_cond_br_cg(&overflow_flag, &trap_label, &continue_label);

    // Trap block
    ctx.emit_label_cg(&trap_label);
    ctx.indent();
    ctx.write("    call void @llvm.trap()\n");
    ctx.emit_unreachable();
    ctx.dedent();

    // Continue block
    ctx.emit_label_cg(&continue_label);
}

/// Checks if a string starts with a prefix.
fn string_starts_with(s: &str, prefix: &str) -> bool {
    let s_bytes = s.as_bytes();
    let prefix_bytes = prefix.as_bytes();
    if prefix_bytes.len() > s_bytes.len() {
        return false;
    }
    let mut i: usize = 0;
    while i < prefix_bytes.len() {
        if s_bytes[i] != prefix_bytes[i] {
            return false;
        }
        i = i + 1;
    }
    true
}

/// Determines whether an operand is signed, using local signedness tracking
/// for Copy/Move operands and HIR type info for constants.
fn operand_is_signed(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> bool {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            ctx.is_local_signed(place.local)
        }
        &mir_types::Operand::Move(ref place) => {
            ctx.is_local_signed(place.local)
        }
        &mir_types::Operand::Constant(ref constant) => {
            let const_hir_ty = type_intern::ty_id_to_type(constant.ty);
            codegen_types::is_signed(&const_hir_ty)
        }
    }
}

/// Emits a unary operation, returning the result value.
fn emit_unop(
    ctx: &mut codegen_ctx::CodegenCtx,
    un_op: &mir_types::MirUnOp,
    operand: &String,
) -> codegen_ctx::CgName {
    emit_unop_typed(ctx, un_op, operand, "i64")
}

/// Emits a unary operation with explicit type, returning the result value.
/// Handles both integer and floating-point operations.
fn emit_unop_typed(
    ctx: &mut codegen_ctx::CodegenCtx,
    un_op: &mir_types::MirUnOp,
    operand: &String,
    llvm_ty: &str,
) -> codegen_ctx::CgName {
    let result = ctx.fresh_temp_cg();
    let v = operand.as_str();

    // Check if this is a floating-point type
    let is_float = string_starts_with(llvm_ty, "float") || string_starts_with(llvm_ty, "double");

    match un_op {
        &mir_types::MirUnOp::Neg => {
            if is_float {
                // fneg is a unary op: %res = fneg <ty> <val>
                ctx.write_indent();
                ctx.write_cgname(&result);
                ctx.write(" = fneg ");
                ctx.write(llvm_ty);
                ctx.write(" ");
                ctx.write(v);
                ctx.write("\n");
            } else {
                ctx.emit_binop_cg(&result, "sub", llvm_ty, "0", v);
            }
        }
        &mir_types::MirUnOp::Not => {
            if is_float {
                // Not doesn't make sense for floats - emit error
                ctx.codegen_error_with_note(
                    codegen_ctx::CodegenErrorKind::UnsupportedOperation,
                    common::make_string("bitwise NOT on float type"),
                    common::make_string("bitwise operations require integer operands; cast to integer first"),
                );
                ctx.write("    ; ERROR: bitwise NOT on float\n");
                ctx.emit_binop_cg(&result, "fadd", llvm_ty, v, "0.0");
            } else {
                ctx.emit_binop_cg(&result, "xor", llvm_ty, v, "-1");
            }
        }
    }

    result
}

/// Emits a cast operation, returning the result value.
/// Takes the source type and target type to determine the correct cast instruction.
fn emit_cast_with_types(
    ctx: &mut codegen_ctx::CodegenCtx,
    val: &String,
    source_ty: &hir_ty::Type,
    target_ty: &hir_ty::Type,
) -> codegen_ctx::CgName {
    let src_llvm = ctx.type_to_llvm_with_ctx(source_ty);
    let tgt_llvm = ctx.type_to_llvm_with_ctx(target_ty);
    let result = ctx.fresh_temp_cg();

    // Determine the cast instruction based on types
    let src_is_int = codegen_types::is_integer(source_ty);
    let tgt_is_int = codegen_types::is_integer(target_ty);
    let src_is_float = codegen_types::is_float(source_ty);
    let tgt_is_float = codegen_types::is_float(target_ty);
    let src_is_signed = codegen_types::is_signed(source_ty);
    let src_is_ptr = codegen_types::is_pointer_like(source_ty);
    let tgt_is_ptr = codegen_types::is_pointer_like(target_ty);

    let src_size = codegen_size::type_size_with_ctx(ctx, source_ty);
    let tgt_size = codegen_size::type_size_with_ctx(ctx, target_ty);

    if src_is_int && tgt_is_int {
        // Integer to integer cast
        if tgt_size < src_size {
            ctx.emit_cast_cg(&result, "trunc", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else if tgt_size > src_size {
            if src_is_signed {
                ctx.emit_cast_cg(&result, "sext", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
            } else {
                ctx.emit_cast_cg(&result, "zext", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
            }
        } else {
            // Same size - bitcast or just copy
            return codegen_ctx::CgName::Str(clone_string(val));
        }
    } else if src_is_float && tgt_is_float {
        // Float to float cast
        if tgt_size < src_size {
            ctx.emit_cast_cg(&result, "fptrunc", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else if tgt_size > src_size {
            ctx.emit_cast_cg(&result, "fpext", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else {
            return codegen_ctx::CgName::Str(clone_string(val));
        }
    } else if src_is_int && tgt_is_float {
        // Integer to float
        if src_is_signed {
            ctx.emit_cast_cg(&result, "sitofp", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else {
            ctx.emit_cast_cg(&result, "uitofp", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        }
    } else if src_is_float && tgt_is_int {
        // Float to integer
        let tgt_is_signed = codegen_types::is_signed(target_ty);
        if tgt_is_signed {
            ctx.emit_cast_cg(&result, "fptosi", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else {
            ctx.emit_cast_cg(&result, "fptoui", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        }
    } else if src_is_ptr && tgt_is_int {
        // Pointer to integer
        ctx.emit_cast_cg(&result, "ptrtoint", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
    } else if src_is_int && tgt_is_ptr {
        // Integer to pointer
        ctx.emit_cast_cg(&result, "inttoptr", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
    } else if src_is_ptr && tgt_is_ptr {
        // Pointer to pointer
        // Check if source is a fat pointer (struct) being cast to thin pointer
        let src_bytes = src_llvm.as_bytes();
        let tgt_bytes = tgt_llvm.as_bytes();
        let src_is_fat = src_bytes.len() > 0 && src_bytes[0] == 123;  // '{'
        let tgt_is_thin = tgt_bytes.len() > 0 && tgt_bytes[0] == 112; // 'p' for "ptr"
        if src_is_fat && tgt_is_thin {
            // Fat pointer to thin pointer: extract the data pointer (field 0)
            ctx.write_indent();
            ctx.write_cgname(&result);
            ctx.write(" = extractvalue ");
            ctx.write_string(&src_llvm);
            ctx.write(" ");
            ctx.write_string(val);
            ctx.write(", 0\n");
        } else if src_is_fat {
            // Fat pointer to fat pointer: just copy
            return codegen_ctx::CgName::Str(clone_string(val));
        } else {
            // Thin pointer to pointer: bitcast or just copy if same
            if string_eq_str(src_llvm.as_str(), tgt_llvm.as_str()) {
                return codegen_ctx::CgName::Str(clone_string(val));
            } else {
                ctx.emit_cast_cg(&result, "bitcast", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
            }
        }
    } else {
        // Fallback: delegate to LLVM-type-based cast logic which correctly
        // handles int-to-int (trunc/sext), fat pointer extraction, etc.
        // This path is reached when HIR types are Infer/Param (unresolved).
        return emit_cast_from_llvm_types(ctx, val, src_llvm.as_str(), tgt_llvm.as_str());
    }

    result
}

/// Gets the LLVM type string for an operand without emitting any IR.
fn operand_llvm_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> String {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            ctx.get_local_type(place.local)
        }
        &mir_types::Operand::Move(ref place) => {
            ctx.get_local_type(place.local)
        }
        &mir_types::Operand::Constant(ref constant) => {
            codegen_size::type_to_llvm_with_ctx_id(ctx, constant.ty)
        }
    }
}

/// Builds an LLVM struct type string from operand types (for tuples, records, closures).
/// Returns e.g. "{ i32, i64, ptr }".
fn build_tuple_llvm_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    operands: &Vec<mir_types::Operand>,
) -> String {
    let mut result = common::make_string("{ ");
    let mut i: usize = 0;
    while i < operands.len() {
        if i > 0 {
            result.push_str(", ");
        }
        let ty = operand_llvm_type(ctx, &operands[i]);
        result.push_str(ty.as_str());
        i = i + 1;
    }
    result.push_str(" }");
    result
}

/// Emits an ADT aggregate (struct or enum variant) using the ADT registry.
fn emit_aggregate_adt(
    ctx: &mut codegen_ctx::CodegenCtx,
    dest: &str,
    def_id: u32,
    variant_idx: u32,
    operands: &Vec<mir_types::Operand>,
    type_args: &Vec<hir_ty::Type>,
) {
    // Try struct first
    match ctx.lookup_struct(def_id) {
        Option::Some(layout) => {
            // Check if any field has an unresolved Param/Infer HIR type
            let has_params = layout_has_param_fields(layout);
            // Collect base field types from registry
            let mut field_types: Vec<String> = Vec::new();
            let mut fi: usize = 0;
            while fi < layout.fields.len() {
                field_types.push(clone_string(&layout.fields[fi].llvm_type));
                fi = fi + 1;
            }
            let struct_ty = clone_string(&layout.llvm_type);
            // If the struct has param/infer fields and concrete type args are available,
            // compute concrete field types by substituting type args for param fields.
            if has_params && type_args.len() > 0 {
                let mut param_idx: usize = 0;
                let mut fj: usize = 0;
                while fj < layout.fields.len() {
                    let is_param = match &layout.fields[fj].hir_type {
                        &Option::Some(ht_id) => {
                            type_intern::is_param_or_infer_id(ht_id)
                        }
                        &Option::None => false,
                    };
                    if is_param && param_idx < type_args.len() {
                        field_types[fj] = codegen_types::type_to_llvm(&type_args[param_idx]);
                        param_idx = param_idx + 1;
                    }
                    fj = fj + 1;
                }
            }
            // Rebuild struct_ty from field_types if params were substituted
            let struct_ty = if has_params && type_args.len() > 0 {
                let mut s = common::make_string("{ ");
                let mut si: usize = 0;
                while si < field_types.len() {
                    if si > 0 {
                        s.push_str(", ");
                    }
                    s.push_str(field_types[si].as_str());
                    si = si + 1;
                }
                s.push_str(" }");
                s
            } else {
                struct_ty
            };
            // Store each field using actual types from the struct layout.
            // If the operand type differs from the field type (e.g., i64 vs i32),
            // emit a trunc or zext to match the target field width.
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let operand_val = typed.0;
                let operand_ty = typed.1;
                let field_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&field_ptr, struct_ty.as_str(), dest);
                ctx.gep_ptr_offset(0);
                ctx.gep_field(i as u32);
                ctx.end_gep();
                // Use actual field type from the struct layout.
                // If the field index exceeds the known field types, this is
                // a compiler bug — the aggregate has more operands than the
                // struct layout has fields.
                let field_ty_str = if i < field_types.len() {
                    field_types[i].as_str()
                } else {
                    ctx.write("    ; ICE: aggregate field ");
                    ctx.write(codegen_types::format_u64(i as u64).as_str());
                    ctx.write(" exceeds field_types.len()=");
                    ctx.write(codegen_types::format_u64(field_types.len() as u64).as_str());
                    ctx.write("\n");
                    ctx.write("    ; ICE: This is a compiler bug (codegen_expr: field type fallback)\n");
                    ctx.write("    call void @llvm.trap()\n");
                    ctx.emit_unreachable();
                    "i64" // dead code — satisfies type checker
                };
                // Check if operand type matches field type
                if string_eq_str(operand_ty.as_str(), field_ty_str) {
                    ctx.emit_store_str_cg(field_ty_str, operand_val.as_str(), &field_ptr);
                } else {
                    let src_w = llvm_int_bit_width(operand_ty.as_str());
                    let dst_w = llvm_int_bit_width(field_ty_str);
                    if src_w > dst_w && dst_w > 0 {
                        // Wider to narrower: truncate
                        let cast_tmp = ctx.fresh_temp_cg();
                        ctx.emit_cast_cg(&cast_tmp, "trunc", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                        ctx.emit_store_cg2(field_ty_str, &cast_tmp, &field_ptr);
                    } else if src_w < dst_w && src_w > 0 {
                        // Narrower to wider: zero-extend
                        let cast_tmp = ctx.fresh_temp_cg();
                        ctx.emit_cast_cg(&cast_tmp, "zext", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                        ctx.emit_store_cg2(field_ty_str, &cast_tmp, &field_ptr);
                    } else if src_w > 0 && string_eq_str(field_ty_str, "ptr") {
                        // Integer to pointer: inttoptr
                        let cast_tmp = ctx.fresh_temp_cg();
                        ctx.emit_cast_cg(&cast_tmp, "inttoptr", operand_ty.as_str(), operand_val.as_str(), "ptr");
                        ctx.emit_store_cg2("ptr", &cast_tmp, &field_ptr);
                    } else if dst_w > 0 && string_eq_str(operand_ty.as_str(), "ptr") {
                        // Pointer to integer: ptrtoint
                        let cast_tmp = ctx.fresh_temp_cg();
                        ctx.emit_cast_cg(&cast_tmp, "ptrtoint", "ptr", operand_val.as_str(), field_ty_str);
                        ctx.emit_store_cg2(field_ty_str, &cast_tmp, &field_ptr);
                    } else {
                        // Other mismatch (e.g., i64 vs struct type from unresolved inference).
                        // Store with the operand's own type so the IR is valid.
                        ctx.emit_store_str_cg(operand_ty.as_str(), operand_val.as_str(), &field_ptr);
                    }
                }
                i = i + 1;
            }
            return;
        }
        Option::None => {}
    }
    // Try enum
    match ctx.lookup_enum(def_id) {
        Option::Some(layout) => {
            let enum_ty = clone_string(&layout.llvm_type);
            let discr_ty = clone_string(&layout.discriminant_type);
            // Find the variant's payload type and field types
            let mut payload_ty = common::make_string("{}");
            let mut variant_field_types: Vec<String> = Vec::new();
            let mut vi: usize = 0;
            while vi < layout.variants.len() {
                if layout.variants[vi].variant_idx == variant_idx {
                    payload_ty = clone_string(&layout.variants[vi].payload_llvm_type);
                    let mut vfi: usize = 0;
                    while vfi < layout.variants[vi].fields.len() {
                        variant_field_types.push(clone_string(&layout.variants[vi].fields[vfi].llvm_type));
                        vfi = vfi + 1;
                    }
                }
                vi = vi + 1;
            }

            // Store discriminant at field 0 of the enum type
            let discr_ptr = ctx.fresh_temp_cg();
            ctx.begin_gep_str(&discr_ptr, enum_ty.as_str(), dest);
            ctx.gep_ptr_offset(0);
            ctx.gep_field(0);
            ctx.end_gep();
            let discr_val = codegen_types::format_u64(variant_idx as u64);
            ctx.emit_store_str_cg(discr_ty.as_str(), discr_val.as_str(), &discr_ptr);

            // Store payload fields only if there are operands
            if operands.len() > 0 {
                // Get pointer to payload area (field 1 of enum type)
                let data_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&data_ptr, enum_ty.as_str(), dest);
                ctx.gep_ptr_offset(0);
                ctx.gep_field(1);
                ctx.end_gep();

                // Store each operand field using the variant's payload type
                let mut i: usize = 0;
                while i < operands.len() {
                    let typed = emit_operand_typed(ctx, &operands[i]);
                    let operand_val = typed.0;
                    let operand_ty = typed.1;
                    let field_ptr = ctx.fresh_temp_cg();
                    ctx.begin_gep(&field_ptr, payload_ty.as_str(), &data_ptr);
                    ctx.gep_ptr_offset(0);
                    ctx.gep_field(i as u32);
                    ctx.end_gep();
                    // Use actual field type if available, with type conversion if needed
                    let field_ty_str = if i < variant_field_types.len() {
                        variant_field_types[i].as_str()
                    } else {
                        "i64"
                    };
                    // Check if operand type matches field type
                    if string_eq_str(operand_ty.as_str(), field_ty_str) {
                        ctx.emit_store_str_cg(field_ty_str, operand_val.as_str(), &field_ptr);
                    } else {
                        let src_w = llvm_int_bit_width(operand_ty.as_str());
                        let dst_w = llvm_int_bit_width(field_ty_str);
                        if src_w > dst_w && dst_w > 0 {
                            // Wider to narrower: truncate
                            let cast_tmp = ctx.fresh_temp_cg();
                            ctx.emit_cast_cg(&cast_tmp, "trunc", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                            ctx.emit_store_cg2(field_ty_str, &cast_tmp, &field_ptr);
                        } else if src_w < dst_w && src_w > 0 {
                            // Narrower to wider: zero-extend
                            let cast_tmp = ctx.fresh_temp_cg();
                            ctx.emit_cast_cg(&cast_tmp, "zext", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                            ctx.emit_store_cg2(field_ty_str, &cast_tmp, &field_ptr);
                        } else if src_w > 0 && string_eq_str(field_ty_str, "ptr") {
                            // Integer to pointer: inttoptr
                            let cast_tmp = ctx.fresh_temp_cg();
                            ctx.emit_cast_cg(&cast_tmp, "inttoptr", operand_ty.as_str(), operand_val.as_str(), "ptr");
                            ctx.emit_store_cg2("ptr", &cast_tmp, &field_ptr);
                        } else if dst_w > 0 && string_eq_str(operand_ty.as_str(), "ptr") {
                            // Pointer to integer: ptrtoint
                            let cast_tmp = ctx.fresh_temp_cg();
                            ctx.emit_cast_cg(&cast_tmp, "ptrtoint", "ptr", operand_val.as_str(), field_ty_str);
                            ctx.emit_store_cg2(field_ty_str, &cast_tmp, &field_ptr);
                        } else {
                            // Other mismatch (e.g., aggregate type from nested enum).
                            // Store with the operand's own type so the IR is valid.
                            ctx.emit_store_str_cg(operand_ty.as_str(), operand_val.as_str(), &field_ptr);
                        }
                    }
                    i = i + 1;
                }
            }
            return;
        }
        Option::None => {}
    }
    // Fallback: ADT not in registry (builtin generic enum like Option<T>, Result<T,E>).
    // Emit as enum: store i32 discriminant, then payload at alignment-correct offset.
    let mut vals: Vec<String> = Vec::new();
    let mut tys: Vec<String> = Vec::new();
    let mut k: usize = 0;
    while k < operands.len() {
        let typed = emit_operand_typed(ctx, &operands[k]);
        vals.push(typed.0);
        tys.push(typed.1);
        k = k + 1;
    }

    // Store i32 discriminant at byte 0
    ctx.emit_store("i32", codegen_types::format_u64(variant_idx as u64).as_str(), dest);

    // Store payload fields after discriminant, respecting alignment
    if vals.len() > 0 {
        // Build payload struct type from operand types
        let mut payload_ty = common::make_string("{ ");
        let mut pi: usize = 0;
        while pi < tys.len() {
            if pi > 0 {
                payload_ty.push_str(", ");
            }
            payload_ty.push_str(tys[pi].as_str());
            pi = pi + 1;
        }
        payload_ty.push_str(" }");

        // Compute payload byte offset: i32 (4 bytes) + padding for alignment
        let payload_align = codegen_size::llvm_type_alignment(payload_ty.as_str());
        let discrim_size: u64 = 4;
        let padding = (payload_align - (discrim_size % payload_align)) % payload_align;
        let byte_offset = discrim_size + padding;

        let payload_ptr = ctx.fresh_temp_cg();
        ctx.begin_gep_str(&payload_ptr, "i8", dest);
        ctx.gep_ptr_offset(byte_offset);
        ctx.end_gep();

        // Store each field in the payload
        let mut i: usize = 0;
        while i < vals.len() {
            let field_ptr = ctx.fresh_temp_cg();
            ctx.begin_gep(&field_ptr, payload_ty.as_str(), &payload_ptr);
            ctx.gep_ptr_offset(0);
            ctx.gep_field(i as u32);
            ctx.end_gep();
            ctx.emit_store_str_cg(tys[i].as_str(), vals[i].as_str(), &field_ptr);
            i = i + 1;
        }
    }
}

/// Checks if any field in a struct layout has a Param or Infer HIR type.
fn layout_has_param_fields(layout: &codegen_ctx::StructLayout) -> bool {
    let mut i: usize = 0;
    while i < layout.fields.len() {
        match &layout.fields[i].hir_type {
            &Option::Some(ht_id) => {
                if type_intern::is_param_or_infer_id(ht_id) {
                    return true;
                }
            }
            &Option::None => {}
        }
        i = i + 1;
    }
    false
}

/// Emits an aggregate construction.
fn emit_aggregate(
    ctx: &mut codegen_ctx::CodegenCtx,
    dest: &str,
    kind: &mir_types::AggregateKind,
    operands: &Vec<mir_types::Operand>,
) {
    match kind {
        &mir_types::AggregateKind::Tuple => {
            // Build the tuple LLVM type from operand types
            let tuple_llvm = build_tuple_llvm_type(ctx, operands);
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let field_val = typed.0;
                let field_ty = typed.1;
                let field_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&field_ptr, tuple_llvm.as_str(), dest);
                ctx.gep_ptr_offset(0);
                ctx.gep_field(i as u32);
                ctx.end_gep();
                ctx.emit_store_str_cg(field_ty.as_str(), field_val.as_str(), &field_ptr);
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Array(ref elem_ty) => {
            let mut elem_llvm = codegen_size::type_to_llvm_with_ctx_id(ctx, *elem_ty);
            // If the element type is unresolved (Infer → i64 fallback), use
            // the actual type from the first operand instead.
            if operands.len() > 0 {
                let (first_val, first_ty) = emit_operand_typed(ctx, &operands[0]);
                if !str_eq(first_ty.as_str(), elem_llvm.as_str()) {
                    elem_llvm = clone_string(&first_ty);
                }
                let elem_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&elem_ptr, elem_llvm.as_str(), dest);
                ctx.gep_ptr_offset(0);
                ctx.end_gep();
                ctx.emit_store_str_cg(elem_llvm.as_str(), first_val.as_str(), &elem_ptr);
            }
            let mut i: usize = 1;
            while i < operands.len() {
                let elem_val = emit_operand(ctx, &operands[i]);
                let elem_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&elem_ptr, elem_llvm.as_str(), dest);
                ctx.gep_ptr_offset(i as u64);
                ctx.end_gep();
                ctx.emit_store_str_cg(elem_llvm.as_str(), elem_val.as_str(), &elem_ptr);
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Adt { ref def_id, variant_idx, ref type_args } => {
            // Convert TyId type_args to hir_ty::Type for emit_aggregate_adt
            let mut hir_type_args: Vec<hir_ty::Type> = Vec::new();
            let mut ta: usize = 0;
            while ta < type_args.len() {
                hir_type_args.push(type_intern::ty_id_to_type(type_args[ta]));
                ta = ta + 1;
            }
            // Look up the ADT in the registry to determine if it's a struct or enum
            emit_aggregate_adt(ctx, dest, def_id.index, variant_idx, operands, &hir_type_args);
        }
        &mir_types::AggregateKind::Record => {
            // Extensible records - store fields with actual types
            let record_llvm = build_tuple_llvm_type(ctx, operands);
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let field_val = typed.0;
                let field_ty = typed.1;
                let field_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&field_ptr, record_llvm.as_str(), dest);
                ctx.gep_ptr_offset(0);
                ctx.gep_field(i as u32);
                ctx.end_gep();
                ctx.emit_store_str_cg(field_ty.as_str(), field_val.as_str(), &field_ptr);
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Closure { def_id: _ } => {
            // Closures: store captures with actual types
            let closure_llvm = build_tuple_llvm_type(ctx, operands);
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let cap_val = typed.0;
                let cap_ty = typed.1;
                let cap_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&cap_ptr, closure_llvm.as_str(), dest);
                ctx.gep_ptr_offset(0);
                ctx.gep_field(i as u32);
                ctx.end_gep();
                ctx.emit_store_str_cg(cap_ty.as_str(), cap_val.as_str(), &cap_ptr);
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Range { ref element, inclusive: _ } => {
            // Ranges: store start and end with element type
            let elem_llvm = codegen_size::type_to_llvm_with_ctx_id(ctx, *element);
            // Range struct is { elem_type, elem_type } (start, end)
            let mut range_llvm = common::make_string("{ ");
            let mut fi: usize = 0;
            while fi < operands.len() {
                if fi > 0 {
                    range_llvm.push_str(", ");
                }
                range_llvm.push_str(elem_llvm.as_str());
                fi = fi + 1;
            }
            range_llvm.push_str(" }");

            let mut i: usize = 0;
            while i < operands.len() {
                let val = emit_operand(ctx, &operands[i]);
                let ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&ptr, range_llvm.as_str(), dest);
                ctx.gep_ptr_offset(0);
                ctx.gep_field(i as u32);
                ctx.end_gep();
                ctx.emit_store_str_cg(elem_llvm.as_str(), val.as_str(), &ptr);
                i = i + 1;
            }
        }
    }
}

// ============================================================
// String Helpers
// ============================================================

/// Clones a String.
fn clone_string(s: &String) -> String {
    let mut result = String::new();
    result.push_str(s.as_str());
    result
}

/// Converts a CgName to String for use at boundaries where String is required.
fn cgname_to_string(name: &codegen_ctx::CgName) -> String {
    match name {
        &codegen_ctx::CgName::Temp(n) => {
            let mut s = common::make_string("%tmp");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Local(n) => {
            let mut s = common::make_string("%_");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Label(n) => {
            let mut s = common::make_string("label");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Block(n) => {
            let mut s = common::make_string("bb");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Str(ref s) => {
            clone_string(s)
        }
    }
}
