// Blood Self-Hosted Compiler - Codegen Expressions
//
// This module handles generating LLVM IR for MIR operands and rvalues.

mod common;
mod hir_def;
mod hir_ty;
mod mir_def;
mod mir_types;
mod mir_stmt;
mod mir_term;
mod mir_body;
mod codegen_types;
mod codegen_ctx;
mod codegen_size;

// ============================================================
// Operand Codegen
// ============================================================

/// Generates LLVM IR for an operand, returning the value name.
pub fn emit_operand(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> String {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            emit_place_load(ctx, place)
        }
        &mir_types::Operand::Move(ref place) => {
            emit_place_load(ctx, place)
        }
        &mir_types::Operand::Constant(ref constant) => {
            emit_constant(ctx, constant)
        }
    }
}

/// Generates LLVM IR for an operand with type information, returning (value, llvm_type).
pub fn emit_operand_typed(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> (String, String) {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            emit_place_load_with_type(ctx, place)
        }
        &mir_types::Operand::Move(ref place) => {
            emit_place_load_with_type(ctx, place)
        }
        &mir_types::Operand::Constant(ref constant) => {
            let val = emit_constant(ctx, constant);
            // Check if this FnDef is actually a const or static item
            // (MIR lowering produces FnDef for all path expressions)
            let fn_def_id = match &constant.kind {
                &mir_types::ConstantKind::FnDef(ref did) => Option::Some(did.index),
                _ => Option::None,
            };
            let is_const_item = match fn_def_id {
                Option::Some(did) => ctx.is_const(did),
                Option::None => false,
            };
            let is_static_item = match fn_def_id {
                Option::Some(did) => ctx.is_static(did),
                Option::None => false,
            };
            if is_const_item {
                // Const item: call the const body function to get the value
                let ret_ty = codegen_size::type_to_llvm_with_ctx(ctx, &constant.ty);
                let call_result = ctx.fresh_temp();
                ctx.write_indent();
                ctx.write_string(&call_result);
                ctx.write(" = call ");
                ctx.write_string(&ret_ty);
                ctx.write(" ");
                ctx.write_string(&val);
                ctx.write("()\n");
                (call_result, ret_ty)
            } else if is_static_item {
                // Static item: load from the global address
                // val already has @ prefix from emit_constant's FnDef handler
                let load_ty = codegen_size::type_to_llvm_with_ctx(ctx, &constant.ty);
                let load_result = ctx.fresh_temp();
                ctx.emit_load(load_result.as_str(), load_ty.as_str(), val.as_str());
                (load_result, load_ty)
            } else if match fn_def_id { Option::Some(_) => true, Option::None => false } {
                // Regular function reference — pointer-typed
                (val, common::make_string("ptr"))
            } else if match &constant.kind { &mir_types::ConstantKind::Float(_) => true, _ => false } {
                // Check if f32 or f64 based on the constant's HIR type
                let float_ty = match &constant.ty.kind {
                    &hir_ty::TypeKind::Primitive(hir_ty::PrimitiveTy::F32) => common::make_string("float"),
                    _ => common::make_string("double"),
                };
                (val, float_ty)
            } else {
                // Check if the constant has a reference type to a SIZED type
                // (e.g., const 1: &i32). This happens when the type checker
                // unifies an argument with a &T parameter type (e.g.,
                // HashMap.get(key) where key: &K). We must materialize the
                // inner value in a temp alloca and return a pointer to it.
                //
                // For unsized types (&str, &[T]), the constant is already a
                // fat pointer { ptr, i64 } and should NOT be wrapped.
                let is_sized_ref = match &constant.ty.kind {
                    &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                        !codegen_types::is_unsized_type(inner.as_ref())
                    }
                    _ => false,
                };
                if is_sized_ref {
                    let inner_ty = match &constant.ty.kind {
                        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                            codegen_size::type_to_llvm_with_ctx(ctx, inner.as_ref())
                        }
                        _ => common::make_string("i64"),
                    };
                    // Alloca a temp, store the value, return pointer
                    let ref_temp = ctx.fresh_temp();
                    ctx.write_indent();
                    ctx.write_string(&ref_temp);
                    ctx.write(" = alloca ");
                    ctx.write_string(&inner_ty);
                    ctx.write("\n");
                    ctx.emit_store(inner_ty.as_str(), val.as_str(), ref_temp.as_str());
                    (ref_temp, common::make_string("ptr"))
                } else {
                    let ty = codegen_types::type_to_llvm(&constant.ty);
                    (val, ty)
                }
            }
        }
    }
}

/// Gets the type of an operand.
pub fn operand_type(operand: &mir_types::Operand) -> Option<hir_ty::Type> {
    match operand {
        &mir_types::Operand::Constant(ref constant) => Option::Some(hir_ty::copy_type(&constant.ty)),
        &mir_types::Operand::Copy(_) => Option::None,
        &mir_types::Operand::Move(_) => Option::None,
    }
}

/// Generates LLVM IR for a constant, returning the value.
fn emit_constant(
    ctx: &mut codegen_ctx::CodegenCtx,
    constant: &mir_types::Constant,
) -> String {
    match &constant.kind {
        &mir_types::ConstantKind::Int(v) => codegen_types::format_i128(v),
        &mir_types::ConstantKind::Uint(v) => codegen_types::format_u128(v),
        &mir_types::ConstantKind::Bool(b) => {
            if b { common::make_string("1") } else { common::make_string("0") }
        }
        &mir_types::ConstantKind::Char(c) => {
            codegen_types::format_u64(c as u64)
        }
        &mir_types::ConstantKind::Float(bits) => {
            // MIR always stores float bits as f64 representation (u64).
            // LLVM accepts double-precision hex for both float and double types,
            // converting to the target precision automatically.
            codegen_types::f64_bits_to_llvm_hex(bits)
        }
        &mir_types::ConstantKind::String(ref s) => {
            // Build fat pointer: { ptr @.str.N, i64 len }
            let label = ctx.add_string_constant(s);
            let mut result = common::make_string("{ ptr ");
            result.push_str(label.as_str());
            result.push_str(", i64 ");
            let len_str = codegen_types::format_u64(s.len() as u64);
            result.push_str(len_str.as_str());
            result.push_str(" }");
            result
        }
        &mir_types::ConstantKind::ByteString(ref bytes) => {
            // Convert byte string to regular string for storage
            let mut s = String::new();
            let mut i: usize = 0;
            while i < bytes.len() {
                s.push(bytes[i] as char);
                i = i + 1;
            }
            // Build fat pointer: { ptr @.str.N, i64 len }
            let label = ctx.add_string_constant(&s);
            let mut result = common::make_string("{ ptr ");
            result.push_str(label.as_str());
            result.push_str(", i64 ");
            let len_str = codegen_types::format_u64(bytes.len() as u64);
            result.push_str(len_str.as_str());
            result.push_str(" }");
            result
        }
        &mir_types::ConstantKind::Unit => common::make_string("undef"),
        &mir_types::ConstantKind::FnDef(ref def_id) => {
            // Function pointer - look up the function name
            match ctx.lookup_def_name(def_id.index) {
                Option::Some(name) => {
                    let mut result = common::make_string("@");
                    result.push_str(name.as_str());
                    result
                }
                Option::None => {
                    // Fallback: generate a placeholder name
                    let mut result = common::make_string("@fn_");
                    result.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    result
                }
            }
        }
        &mir_types::ConstantKind::ConstDef(ref def_id) => {
            // Const reference - look up and inline the const value
            // For now, generate a reference (full const eval would inline the value)
            match ctx.lookup_def_name(def_id.index) {
                Option::Some(name) => {
                    let mut result = common::make_string("@");
                    result.push_str(name.as_str());
                    result
                }
                Option::None => {
                    // Fallback: generate a placeholder
                    let mut result = common::make_string("@const_");
                    result.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    result
                }
            }
        }
        &mir_types::ConstantKind::StaticDef(ref def_id) => {
            // Static reference - look up the static name
            match ctx.lookup_def_name(def_id.index) {
                Option::Some(name) => {
                    let mut result = common::make_string("@");
                    result.push_str(name.as_str());
                    result
                }
                Option::None => {
                    // Fallback: generate a placeholder name
                    let mut result = common::make_string("@static_");
                    result.push_str(codegen_types::format_u64(def_id.index as u64).as_str());
                    result
                }
            }
        }
        &mir_types::ConstantKind::ZeroSized => common::make_string("undef"),
    }
}

/// Loads a value from a place, returning the value name.
fn emit_place_load(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> String {
    let ptr = emit_place_data_ptr(ctx, place);
    // Use the projected type (accounts for field access, deref, etc.)
    let llvm_ty = resolve_place_elem_type(ctx, place);
    // Skip load for unit type {} — it has zero size in LLVM
    if str_eq(llvm_ty.as_str(), "{}") {
        return common::make_string("undef");
    }
    let result = ctx.fresh_temp();
    ctx.emit_load(result.as_str(), llvm_ty.as_str(), ptr.as_str());
    // Zero-extend i8 to i32 for &str byte indexing (byte → char promotion)
    // Only apply when loading from an Index projection on a str-like type
    if str_eq(llvm_ty.as_str(), "i8") && is_str_index_place(ctx, place) {
        let extended = ctx.fresh_temp();
        ctx.emit_cast(extended.as_str(), "zext", "i8", result.as_str(), "i32");
        return extended;
    }
    result
}

/// Returns the data pointer for a place, handling region/persistent indirection.
/// For region/persistent locals with no projections, the stack alloca holds a ptr
/// to heap memory. This function dereferences to return the heap pointer where
/// the actual data lives. For stack locals, returns the alloca directly.
pub fn emit_place_data_ptr(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> String {
    let ptr = emit_place_addr(ctx, place);
    if place.projection.len() == 0
        && (ctx.is_region_allocated(place.local) || ctx.is_persistent_allocated(place.local)
            || ctx.is_handler_state_ptr(place.local))
    {
        let heap_ptr = ctx.fresh_temp();
        ctx.emit_load(heap_ptr.as_str(), "ptr", ptr.as_str());
        return heap_ptr;
    }
    ptr
}

/// Loads a value from a place, returning (value, llvm_type).
fn emit_place_load_with_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> (String, String) {
    let ptr = emit_place_data_ptr(ctx, place);
    // Use the projected type (accounts for field access, deref, etc.)
    let llvm_ty = resolve_place_elem_type(ctx, place);
    // Skip load for unit type {} — it has zero size in LLVM
    if str_eq(llvm_ty.as_str(), "{}") {
        return (common::make_string("undef"), llvm_ty);
    }
    let result = ctx.fresh_temp();
    ctx.emit_load(result.as_str(), llvm_ty.as_str(), ptr.as_str());
    // Zero-extend i8 to i32 for &str byte indexing (byte → char promotion)
    // Only apply when loading from an Index projection on a str-like type
    if str_eq(llvm_ty.as_str(), "i8") && is_str_index_place(ctx, place) {
        let extended = ctx.fresh_temp();
        ctx.emit_cast(extended.as_str(), "zext", "i8", result.as_str(), "i32");
        return (extended, common::make_string("i32"));
    }
    (result, llvm_ty)
}

/// Computes the LLVM type for the value at a place after all projections.
/// When a place has projections (Field, Deref, Downcast), the loaded type
/// differs from the base local's type. For example, loading field 0 of a
/// `{ i32, i32 }` struct should use `i32`, not the struct type.
fn resolve_place_elem_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> String {
    // For static places, use the registered static LLVM type
    if place.is_static() {
        match place.get_static_def_id() {
            Option::Some(def_id) => {
                match ctx.get_static_type(def_id.index) {
                    Option::Some(ty) => { return ty; }
                    Option::None => {}
                }
            }
            Option::None => {}
        }
    }

    // If no projections, use the local's registered LLVM type
    if place.projection.len() == 0 {
        return ctx.get_local_type(place.local);
    }

    // Check the last projection to determine the final type
    let last_idx = place.projection.len() - 1;
    match &place.projection[last_idx] {
        &mir_types::PlaceElem::Field(field_idx) => {
            // Field access: look up the field's type from the struct/enum layout.
            // Count Deref projections and check for Downcast before this field.
            let mut deref_count: usize = 0;
            let mut downcast_variant: Option<u32> = Option::None;
            let mut j: usize = 0;
            while j < last_idx {
                match &place.projection[j] {
                    &mir_types::PlaceElem::Deref => {
                        deref_count = deref_count + 1;
                    }
                    &mir_types::PlaceElem::Downcast(vi) => {
                        downcast_variant = Option::Some(vi);
                    }
                    _ => {}
                }
                j = j + 1;
            }

            // Resolve the ADT def_id by walking through Ref/Ptr layers
            let adt_def_id = if deref_count > 0 {
                resolve_deref_adt_def_id(ctx, place.local, deref_count - 1)
            } else {
                match ctx.get_local_hir_type(place.local) {
                    Option::Some(ty) => resolve_adt_def_id_from_hir(ty),
                    Option::None => Option::None,
                }
            };

            match &adt_def_id {
                &Option::Some(def_id) => {
                    match &downcast_variant {
                        &Option::Some(vi) => {
                            // Enum variant field
                            match ctx.lookup_enum(def_id) {
                                Option::Some(layout) => {
                                    let mut k: usize = 0;
                                    while k < layout.variants.len() {
                                        if layout.variants[k].variant_idx == vi {
                                            if (field_idx as usize) < layout.variants[k].fields.len() {
                                                return clone_string(&layout.variants[k].fields[field_idx as usize].llvm_type);
                                            }
                                            break;
                                        }
                                        k = k + 1;
                                    }
                                }
                                Option::None => {}
                            }
                        }
                        &Option::None => {
                            // Struct field
                            match ctx.lookup_struct(def_id) {
                                Option::Some(layout) => {
                                    if (field_idx as usize) < layout.fields.len() {
                                        // Check if this field has an unsubstituted param/infer type.
                                        // If so, resolve the concrete type from the local's type args.
                                        let field_is_param = match &layout.fields[field_idx as usize].hir_type {
                                            &Option::Some(ref ht) => {
                                                match &ht.kind {
                                                    &hir_ty::TypeKind::Param(_) => true,
                                                    &hir_ty::TypeKind::Infer(_) => true,
                                                    _ => false,
                                                }
                                            }
                                            &Option::None => false,
                                        };
                                        if field_is_param {
                                            // Try to get concrete type arg from local's HIR type
                                            let resolved = resolve_generic_field_type(ctx, place.local, layout, field_idx as usize);
                                            match resolved {
                                                Option::Some(ty) => { return ty; }
                                                Option::None => {}
                                            }
                                        }
                                        return clone_string(&layout.fields[field_idx as usize].llvm_type);
                                    }
                                }
                                Option::None => {}
                            }
                        }
                    }
                }
                &Option::None => {}
            }

            // Fallback: use the local's type
            ctx.get_local_type(place.local)
        }
        &mir_types::PlaceElem::Index(_) => {
            // After indexing, the type is the container's element type, not the container type
            match ctx.get_local_hir_type(place.local) {
                Option::Some(hir_type) => resolve_index_element_type(ctx, hir_type),
                Option::None => ctx.get_local_type(place.local),
            }
        }
        &mir_types::PlaceElem::ConstantIndex { offset: _, min_length: _, from_end: _ } => {
            // After constant indexing, the type is the container's element type
            match ctx.get_local_hir_type(place.local) {
                Option::Some(hir_type) => resolve_index_element_type(ctx, hir_type),
                Option::None => ctx.get_local_type(place.local),
            }
        }
        &mir_types::PlaceElem::Deref => {
            // Deref projection: unwrap Ref/Ptr layers from the local's HIR type
            // to find the pointed-to type. E.g., *const u8 → i8, &String → { ptr, i64, i64 }.
            match ctx.get_local_hir_type(place.local) {
                Option::Some(hir_type) => {
                    // Count Deref projections in the chain
                    let mut deref_count: usize = 0;
                    let mut di: usize = 0;
                    while di < place.projection.len() {
                        match &place.projection[di] {
                            &mir_types::PlaceElem::Deref => {
                                deref_count = deref_count + 1;
                            }
                            _ => {}
                        }
                        di = di + 1;
                    }
                    // Unwrap one layer
                    match apply_deref_to_type(hir_type) {
                        Option::Some(inner_ty) => {
                            // Apply remaining Derefs
                            let mut final_ty = inner_ty;
                            let mut applied: usize = 1;
                            while applied < deref_count {
                                match apply_deref_to_type(&final_ty) {
                                    Option::Some(next) => {
                                        final_ty = next;
                                        applied = applied + 1;
                                    }
                                    Option::None => { break; }
                                }
                            }
                            codegen_size::type_to_llvm_with_ctx(ctx, &final_ty)
                        }
                        Option::None => ctx.get_local_type(place.local),
                    }
                }
                Option::None => ctx.get_local_type(place.local),
            }
        }
        _ => {
            // For Downcast and other projections, use the local's type
            ctx.get_local_type(place.local)
        }
    }
}

/// Emits the address of a place, returning the pointer value.
pub fn emit_place_addr(
    ctx: &mut codegen_ctx::CodegenCtx,
    place: &mir_types::Place,
) -> String {
    // Check if this is a static place - use global variable address directly
    if place.is_static() {
        match place.get_static_def_id() {
            Option::Some(def_id) => {
                // Look up the global variable name for this static
                match ctx.lookup_def_name(def_id.index) {
                    Option::Some(name) => {
                        // Return the global variable name with @ prefix.
                        // Static global variables are already addresses.
                        // Convention: names are stored without @, add it here.
                        let mut result = common::make_string("@");
                        result.push_str(name.as_str());
                        return result;
                    }
                    Option::None => {
                        // Fallback - shouldn't happen
                        return common::make_string("null");
                    }
                }
            }
            Option::None => {
                // Fallback - shouldn't happen
                return common::make_string("null");
            }
        }
    }

    let mut current = ctx.local_name(place.local);

    // Resolve the local's ADT type for projection lookups.
    // This looks through Ref types to find the inner ADT.
    let base_type = resolve_local_base_type(ctx, place.local);

    let mut i: usize = 0;
    // Track the current base type string through projections
    let mut current_base = base_type;
    // Track variant index after Downcast
    let mut downcast_variant: Option<u32> = Option::None;
    // Track the ADT def_id for field lookups
    let mut current_adt_def_id: Option<u32> = resolve_local_adt_def_id(ctx, place.local);
    // Track the current HIR type for proper indexing element size calculation.
    // Keep the full type including references - projections will unwrap as needed.
    let mut current_hir_type: Option<hir_ty::Type> = match ctx.get_local_hir_type(place.local) {
        Option::Some(ty) => Option::Some(hir_ty::copy_type(ty)),
        Option::None => Option::None,
    };

    // Region/persistent auto-deref: if the local is heap-allocated via region/persistent
    // and there are projections, load the heap pointer first. The alloca only holds a ptr
    // to the heap; projections must start from the heap data.
    if place.projection.len() > 0
        && (ctx.is_region_allocated(place.local) || ctx.is_persistent_allocated(place.local))
    {
        let loaded = ctx.fresh_temp();
        ctx.emit_load(loaded.as_str(), "ptr", current.as_str());
        current = loaded;
    }

    // Auto-deref: if the local is a reference type and the first projection is Field,
    // insert an implicit load of the pointer. The MIR should have a Deref projection
    // but the self-hosted compiler sometimes omits it for &self field access.
    if place.projection.len() > 0 && is_local_ref_type(ctx, place.local) {
        let first_is_field = match &place.projection[0] {
            &mir_types::PlaceElem::Field(_) => true,
            &mir_types::PlaceElem::Downcast(_) => true,
            _ => false,
        };
        if first_is_field {
            let loaded = ctx.fresh_temp();
            ctx.emit_load(loaded.as_str(), "ptr", current.as_str());
            current = loaded;
            // Also update HIR type through implicit deref
            current_hir_type = match &current_hir_type {
                &Option::Some(ref ty) => apply_deref_to_type(ty),
                &Option::None => Option::None,
            };
        }
    }

    while i < place.projection.len() {
        let proj = &place.projection[i];
        match proj {
            &mir_types::PlaceElem::Deref => {
                // Load the pointer value
                let result = ctx.fresh_temp();
                ctx.emit_load(result.as_str(), "ptr", current.as_str());
                // Emit generation check if the local has a tracked generation
                emit_generation_check(ctx, place.local, &result);
                current = result;
                // After deref, try to get the inner type's ADT info
                current_adt_def_id = resolve_deref_adt_def_id(ctx, place.local, i);
                current_base = match &current_adt_def_id {
                    &Option::Some(def_id) => ctx.adt_llvm_type(def_id),
                    &Option::None => common::make_string("{ i64 }"),
                };
                downcast_variant = Option::None;
                // Track HIR type through deref
                current_hir_type = match &current_hir_type {
                    &Option::Some(ref ty) => apply_deref_to_type(ty),
                    &Option::None => Option::None,
                };
            }
            &mir_types::PlaceElem::Field(idx) => {
                let result = ctx.fresh_temp();

                // Determine the GEP base type from context
                let gep_type = match &downcast_variant {
                    &Option::Some(vi) => {
                        // After Downcast: use variant payload type
                        resolve_variant_payload_type(ctx, &current_adt_def_id, vi)
                    }
                    &Option::None => {
                        // Direct field access: use the struct/tuple LLVM type
                        clone_string(&current_base)
                    }
                };

                // If GEP base type is a scalar (not struct/array), use byte offset
                // instead of struct field indexing. Scalars like i64, ptr can't be
                // indexed with struct field indices.
                // Also bounds-check: if the field index exceeds the struct's field
                // count, fall back to byte-offset GEP.
                let field_count = count_struct_fields(&gep_type);
                if is_struct_or_array_type(&gep_type) && (idx as u64) < (field_count as u64) {
                    let mut indices: Vec<String> = Vec::new();
                    indices.push(common::make_string("0"));
                    indices.push(codegen_types::format_u64(idx as u64));
                    ctx.emit_gep(result.as_str(), gep_type.as_str(), current.as_str(), &indices);
                } else {
                    // Byte offset: each field is assumed 8 bytes (i64)
                    let byte_offset = (idx as u64) * 8;
                    let mut indices: Vec<String> = Vec::new();
                    indices.push(codegen_types::format_u64(byte_offset));
                    ctx.emit_gep(result.as_str(), "i8", current.as_str(), &indices);
                }

                current = result;
                // After field access, try to preserve the field's HIR type for indexing
                let new_hir_type: Option<hir_ty::Type> = match &current_adt_def_id {
                    &Option::Some(def_id) => {
                        match ctx.lookup_field_hir_type(def_id, idx) {
                            Option::Some(field_ty) => Option::Some(hir_ty::copy_type(field_ty)),
                            Option::None => Option::None,
                        }
                    }
                    &Option::None => Option::None,
                };
                current_hir_type = new_hir_type;
                current_adt_def_id = Option::None;
                current_base = common::make_string("{ i64 }");
                // If the field type is an ADT, update current_base and current_adt_def_id
                // to reflect the field's actual LLVM layout. This is critical for
                // subsequent Index projections (e.g., self.buckets[idx]) so that
                // is_vec_like_type correctly detects Vec-like types and loads the
                // data pointer before indexing.
                match &current_hir_type {
                    &Option::Some(ref field_ty) => {
                        match &field_ty.kind {
                            &hir_ty::TypeKind::Adt { def_id, args: _ } => {
                                current_base = ctx.adt_llvm_type(def_id.index);
                                current_adt_def_id = Option::Some(def_id.index);
                            }
                            _ => {}
                        }
                    }
                    &Option::None => {}
                }
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::Index(ref local) => {
                // For Vec/container indexing, the current address points to the Vec struct
                // { ptr, i64, i64 } where the first field is the data pointer. We need to
                // load the data pointer before indexing into the heap-allocated array.
                // Detect Vec-like types by checking if current_base starts with "{ ptr"
                if is_vec_like_type(&current_base) {
                    // When the local is a reference to a Vec (LLVM type "ptr") and there's
                    // no preceding Deref projection, current points to the alloca containing
                    // the reference. Load through the reference first to get the Vec struct address.
                    if i == 0 {
                        let local_llvm_ty = ctx.get_local_type(place.local);
                        if string_eq_str(local_llvm_ty.as_str(), "ptr") {
                            let vec_ptr = ctx.fresh_temp();
                            ctx.emit_load(vec_ptr.as_str(), "ptr", current.as_str());
                            current = vec_ptr;
                        }
                    }
                    let data_ptr = ctx.fresh_temp();
                    ctx.emit_load(data_ptr.as_str(), "ptr", current.as_str());
                    current = data_ptr;
                }

                // Get the element size using tracked HIR type for proper byte-offset calculation
                let elem_size = match &current_hir_type {
                    &Option::Some(ref ty) => get_element_size_from_hir(ctx, ty),
                    &Option::None => get_indexing_element_size(ctx, place.local),
                };

                // Load the index value
                let idx_val = ctx.local_name(*local);
                let idx_loaded = ctx.fresh_temp();
                ctx.emit_load(idx_loaded.as_str(), "i64", idx_val.as_str());

                // Calculate byte offset = index * element_size
                let elem_size_str = codegen_types::format_u64(elem_size);
                let byte_offset = ctx.fresh_temp();
                ctx.emit_binop(byte_offset.as_str(), "mul", "i64", idx_loaded.as_str(), elem_size_str.as_str());

                // Use byte-offset GEP with i8 element type
                let result = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(clone_string(&byte_offset));
                ctx.emit_gep(result.as_str(), "i8", current.as_str(), &indices);
                current = result;
                current_adt_def_id = Option::None;
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::ConstantIndex { offset, min_length: _, from_end } => {
                // For Vec/container indexing, load the data pointer first
                if is_vec_like_type(&current_base) {
                    // Handle reference-to-Vec (same as Index case above)
                    if i == 0 {
                        let local_llvm_ty = ctx.get_local_type(place.local);
                        if string_eq_str(local_llvm_ty.as_str(), "ptr") {
                            let vec_ptr = ctx.fresh_temp();
                            ctx.emit_load(vec_ptr.as_str(), "ptr", current.as_str());
                            current = vec_ptr;
                        }
                    }
                    let data_ptr = ctx.fresh_temp();
                    ctx.emit_load(data_ptr.as_str(), "ptr", current.as_str());
                    current = data_ptr;
                }

                // Get the element size using tracked HIR type for proper byte-offset calculation
                let elem_size = match &current_hir_type {
                    &Option::Some(ref ty) => get_element_size_from_hir(ctx, ty),
                    &Option::None => get_indexing_element_size(ctx, place.local),
                };

                // Calculate byte offset = offset * element_size
                let byte_offset = if from_end {
                    offset * elem_size
                } else {
                    offset * elem_size
                };

                let result = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(codegen_types::format_u64(byte_offset));
                ctx.emit_gep(result.as_str(), "i8", current.as_str(), &indices);
                current = result;
                current_adt_def_id = Option::None;
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::Subslice { from, to: _, from_end: _ } => {
                // Get the element size using tracked HIR type for proper byte-offset calculation
                let elem_size = match &current_hir_type {
                    &Option::Some(ref ty) => get_element_size_from_hir(ctx, ty),
                    &Option::None => get_indexing_element_size(ctx, place.local),
                };

                // Calculate byte offset = from * element_size
                let byte_offset = from * elem_size;

                let result = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(codegen_types::format_u64(byte_offset));
                ctx.emit_gep(result.as_str(), "i8", current.as_str(), &indices);
                current = result;
                current_adt_def_id = Option::None;
                downcast_variant = Option::None;
            }
            &mir_types::PlaceElem::Downcast(variant_idx) => {
                // Enum downcast: project into variant data for a specific variant.
                ctx.write("    ; downcast to variant ");
                ctx.write_string(&codegen_types::format_u64(variant_idx as u64));
                ctx.write("\n");

                let result = ctx.fresh_temp();

                // Only use struct GEP when the type has 2+ fields (discriminant + data).
                // Fallback types like { i64 } from Deref need byte-offset GEP.
                let fc = count_struct_fields(&current_base);
                if is_struct_or_array_type(&current_base) && fc >= 2 {
                    let mut indices: Vec<String> = Vec::new();
                    indices.push(common::make_string("0"));
                    // Skip discriminant at index 0, variant data at index 1
                    indices.push(common::make_string("1"));
                    ctx.emit_gep(result.as_str(), current_base.as_str(), current.as_str(), &indices);
                } else {
                    // Scalar or fallback base type: use byte-offset GEP
                    // Discriminant is i8 (1 byte), so variant data starts at offset 1
                    let mut indices: Vec<String> = Vec::new();
                    indices.push(common::make_string("1"));
                    ctx.emit_gep(result.as_str(), "i8", current.as_str(), &indices);
                }
                current = result;
                downcast_variant = Option::Some(variant_idx);
                // Keep current_adt_def_id for field resolution after downcast
            }
        }
        i = i + 1;
    }

    current
}

/// Emits a generation validation check for a dereferenced pointer.
/// If the local has a tracked generation (i.e., it was region-allocated),
/// validates that the pointer's generation matches the expected generation.
/// No-ops for stack-allocated locals or locals without generation tracking.
fn emit_generation_check(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
    ptr_name: &String,
) {
    // Only emit check for locals with tracked generations
    let gen_alloca = match ctx.get_local_generation(local) {
        Option::Some(name) => name,
        Option::None => { return; }
    };

    // Load expected generation from stack alloca
    let expected_gen = ctx.fresh_temp();
    ctx.emit_load(expected_gen.as_str(), "i32", gen_alloca.as_str());

    // Convert pointer to i64 address for runtime call
    let ptr_addr = ctx.fresh_temp();
    ctx.emit_cast(ptr_addr.as_str(), "ptrtoint", "ptr", ptr_name.as_str(), "i64");

    // Call blood_validate_generation(address, expected_generation) -> i32
    // Returns 0 if valid, 1 if stale
    let gen_result = ctx.fresh_temp();
    let mut args: Vec<(String, String)> = Vec::new();
    args.push((common::make_string("i64"), clone_string(&ptr_addr)));
    args.push((common::make_string("i32"), clone_string(&expected_gen)));
    ctx.emit_call(Option::Some(gen_result.as_str()), "i32", "@blood_validate_generation", &args);

    // Check if stale (result != 0)
    let is_stale = ctx.fresh_temp();
    ctx.emit_icmp(is_stale.as_str(), "ne", "i32", gen_result.as_str(), "0");

    // Branch: stale -> panic, valid -> continue
    let stale_label = ctx.fresh_label();
    let valid_label = ctx.fresh_label();
    ctx.emit_cond_br(is_stale.as_str(), stale_label.as_str(), valid_label.as_str());

    // Stale path: get actual generation for diagnostic, then panic
    ctx.emit_label(stale_label.as_str());
    let actual_gen = ctx.fresh_temp();
    let mut get_args: Vec<(String, String)> = Vec::new();
    get_args.push((common::make_string("i64"), clone_string(&ptr_addr)));
    ctx.emit_call(Option::Some(actual_gen.as_str()), "i32", "@blood_get_generation", &get_args);
    let mut panic_args: Vec<(String, String)> = Vec::new();
    panic_args.push((common::make_string("i32"), clone_string(&expected_gen)));
    panic_args.push((common::make_string("i32"), clone_string(&actual_gen)));
    ctx.emit_call(Option::None, "void", "@blood_stale_reference_panic", &panic_args);
    ctx.emit_unreachable();

    // Valid path: continue with dereferenced pointer
    ctx.emit_label(valid_label.as_str());
}

/// For a generic struct field, resolves the concrete LLVM type by matching
/// param/infer fields with the local's type args.
fn resolve_generic_field_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
    layout: &codegen_ctx::StructLayout,
    field_idx: usize,
) -> Option<String> {
    // Get the local's HIR type to find type args
    let hir_type_ref = match ctx.get_local_hir_type(local) {
        Option::Some(ty) => ty,
        Option::None => { return Option::None; }
    };
    // Walk through Ref/Ptr to find the ADT
    let adt_type = unwrap_ref_type(hir_type_ref);
    let type_args = match &adt_type.kind {
        &hir_ty::TypeKind::Adt { def_id: _, ref args } => args,
        _ => { return Option::None; }
    };
    if type_args.len() == 0 {
        return Option::None;
    }
    // Count which param index this field corresponds to
    let mut param_idx: usize = 0;
    let mut fi: usize = 0;
    while fi < layout.fields.len() {
        let is_param = match &layout.fields[fi].hir_type {
            &Option::Some(ref ht) => {
                match &ht.kind {
                    &hir_ty::TypeKind::Param(_) => true,
                    &hir_ty::TypeKind::Infer(_) => true,
                    _ => false,
                }
            }
            &Option::None => false,
        };
        if fi == field_idx {
            if is_param && param_idx < type_args.len() {
                return Option::Some(codegen_types::type_to_llvm(&type_args[param_idx]));
            }
            return Option::None;
        }
        if is_param {
            param_idx = param_idx + 1;
        }
        fi = fi + 1;
    }
    Option::None
}

/// Resolves the LLVM base type for a MIR local.
/// Returns the ADT's LLVM type if the local is a struct/enum, or a fallback type.
fn resolve_local_base_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> String {
    match ctx.get_local_hir_type(local) {
        Option::Some(hir_type) => {
            let result = resolve_base_type_from_hir(ctx, hir_type);
            // If resolve returned "ptr" (fallback for unknown ADT), the local might
            // be a builtin generic (Option<T>, Result<T,E>) not in the ADT registry.
            // Fall back to the alloca type which was computed correctly.
            let rb = result.as_bytes();
            if rb.len() == 3 && rb[0] == 112 && rb[1] == 116 && rb[2] == 114 {
                let alloca_type = ctx.get_local_type(local);
                if is_struct_or_array_type(&alloca_type) {
                    return alloca_type;
                }
            }
            // For generic ADTs (e.g., Wrapper<i32>), the registry returns the
            // unsubstituted layout (e.g., { i64 }), but the alloca was correctly
            // computed with concrete types (e.g., { i32 }). Prefer the alloca type
            // when they differ and the alloca is a struct type.
            let is_generic_adt = match &hir_type.kind {
                &hir_ty::TypeKind::Adt { def_id: _, ref args } => args.len() > 0,
                &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                    match &inner.as_ref().kind {
                        &hir_ty::TypeKind::Adt { def_id: _, ref args } => args.len() > 0,
                        _ => false,
                    }
                }
                _ => false,
            };
            if is_generic_adt {
                let alloca_type = ctx.get_local_type(local);
                if is_struct_or_array_type(&alloca_type) {
                    return alloca_type;
                }
            }
            result
        }
        Option::None => common::make_string("{ i64 }"),
    }
}

/// Resolves the LLVM base type for a given HIR type, looking through references.
fn resolve_base_type_from_hir(
    ctx: &mut codegen_ctx::CodegenCtx,
    hir_type: &hir_ty::Type,
) -> String {
    match &hir_type.kind {
        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
            ctx.adt_llvm_type(def_id.index)
        }
        &hir_ty::TypeKind::Tuple(ref _elems) => {
            ctx.type_to_llvm_with_ctx(hir_type)
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            // Look through reference to get the pointed-to type
            resolve_base_type_from_hir(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            resolve_base_type_from_hir(ctx, inner.as_ref())
        }
        _ => {
            ctx.type_to_llvm_with_ctx(hir_type)
        }
    }
}

/// Resolves the ADT def_id for a MIR local, if it's an ADT type.
fn resolve_local_adt_def_id(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> Option<u32> {
    match ctx.get_local_hir_type(local) {
        Option::Some(hir_type) => {
            resolve_adt_def_id_from_hir(hir_type)
        }
        Option::None => Option::None,
    }
}

/// Returns true if the local's HIR type is a reference (Ref or Ptr).
fn is_local_ref_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> bool {
    match ctx.get_local_hir_type(local) {
        Option::Some(hir_type) => {
            match &hir_type.kind {
                &hir_ty::TypeKind::Ref { inner: _, mutable: _ } => true,
                &hir_ty::TypeKind::Ptr { inner: _, mutable: _ } => true,
                _ => false,
            }
        }
        Option::None => false,
    }
}

/// Extracts the ADT def_id from an HIR type, looking through references.
fn resolve_adt_def_id_from_hir(hir_type: &hir_ty::Type) -> Option<u32> {
    match &hir_type.kind {
        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
            Option::Some(def_id.index)
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            resolve_adt_def_id_from_hir(inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            resolve_adt_def_id_from_hir(inner.as_ref())
        }
        _ => Option::None,
    }
}

/// Unwraps a reference type to get the inner type. Returns a copy of the type.
fn unwrap_ref_type(hir_type: &hir_ty::Type) -> hir_ty::Type {
    match &hir_type.kind {
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            hir_ty::copy_type(inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            hir_ty::copy_type(inner.as_ref())
        }
        _ => hir_ty::copy_type(hir_type),
    }
}

/// Applies a Deref projection to an HIR type, returning the inner type.
fn apply_deref_to_type(hir_type: &hir_ty::Type) -> Option<hir_ty::Type> {
    match &hir_type.kind {
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            Option::Some(hir_ty::copy_type(inner.as_ref()))
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            Option::Some(hir_ty::copy_type(inner.as_ref()))
        }
        &hir_ty::TypeKind::Adt { def_id: _, ref args } => {
            // Box<T> deref: *Box<T> -> T
            // Box-like ADTs have exactly 1 type argument and are pointer-sized.
            if args.len() == 1 {
                Option::Some(hir_ty::copy_type(&args[0]))
            } else {
                Option::None
            }
        }
        _ => Option::None,
    }
}

/// Resolves the ADT def_id for a deref'd local (Ref<Adt>).
fn resolve_deref_adt_def_id(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
    deref_depth: usize,
) -> Option<u32> {
    match ctx.get_local_hir_type(local) {
        Option::Some(hir_type) => {
            // Walk through Ref types
            let mut ty = hir_type;
            let mut depth: usize = 0;
            while depth <= deref_depth {
                match &ty.kind {
                    &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                        ty = inner.as_ref();
                        depth = depth + 1;
                    }
                    &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
                        ty = inner.as_ref();
                        depth = depth + 1;
                    }
                    _ => {
                        return Option::None;
                    }
                }
            }
            // Now check if the dereferenced type is an ADT
            match &ty.kind {
                &hir_ty::TypeKind::Adt { def_id, args: _ } => {
                    Option::Some(def_id.index)
                }
                _ => Option::None,
            }
        }
        Option::None => Option::None,
    }
}

/// Resolves the LLVM type for a variant's payload.
fn resolve_variant_payload_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    adt_def_id: &Option<u32>,
    variant_idx: u32,
) -> String {
    match adt_def_id {
        &Option::Some(def_id) => {
            match ctx.lookup_enum(def_id) {
                Option::Some(enum_layout) => {
                    // Find the variant layout
                    let mut i: usize = 0;
                    while i < enum_layout.variants.len() {
                        if enum_layout.variants[i].variant_idx == variant_idx {
                            return clone_string(&enum_layout.variants[i].payload_llvm_type);
                        }
                        i = i + 1;
                    }
                    // Variant not found in registry, fallback
                    common::make_string("{ i64 }")
                }
                Option::None => common::make_string("{ i64 }"),
            }
        }
        &Option::None => common::make_string("{ i64 }"),
    }
}

/// Returns the size of the element type if known, or 8 (pointer size) as default.
fn get_indexing_element_size(
    ctx: &mut codegen_ctx::CodegenCtx,
    local: mir_def::MirLocalId,
) -> u64 {
    match ctx.get_local_hir_type(local) {
        Option::Some(hir_type) => {
            get_element_size_from_hir(ctx, hir_type)
        }
        Option::None => 8, // Default to pointer size
    }
}

/// Extracts the element size from an HIR type that can be indexed.
fn get_element_size_from_hir(ctx: &mut codegen_ctx::CodegenCtx, hir_type: &hir_ty::Type) -> u64 {
    match &hir_type.kind {
        &hir_ty::TypeKind::Array { ref element, size: _ } => {
            codegen_size::type_size_with_ctx(ctx, element.as_ref())
        }
        &hir_ty::TypeKind::Slice { ref element } => {
            codegen_size::type_size_with_ctx(ctx, element.as_ref())
        }
        &hir_ty::TypeKind::Adt { def_id: _, ref args } => {
            // Vec<T> has T as first type argument
            if args.len() > 0 {
                codegen_size::type_size_with_ctx(ctx, &args[0])
            } else {
                8 // Default to pointer size
            }
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            // Look through reference
            get_element_size_from_hir(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            // Look through pointer
            get_element_size_from_hir(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Primitive(hir_ty::PrimitiveTy::Str) => {
            // &str indexing accesses individual bytes
            1
        }
        _ => 8, // Default to pointer size
    }
}

/// Returns true if the given place is an Index projection into a &str type.
/// Used to determine when byte→char zero-extension is needed after loading.
fn is_str_index_place(ctx: &mut codegen_ctx::CodegenCtx, place: &mir_types::Place) -> bool {
    // Check if any projection is an Index
    let mut has_index = false;
    let mut pi: usize = 0;
    while pi < place.projection.len() {
        match &place.projection[pi] {
            &mir_types::PlaceElem::Index(_) => { has_index = true; }
            _ => {}
        }
        pi = pi + 1;
    }
    if !has_index { return false; }
    // Check if the local's HIR type is &str or str
    match ctx.get_local_hir_type(place.local) {
        Option::Some(hir_type) => is_str_hir_type(hir_type),
        Option::None => false,
    }
}

/// Returns true if the HIR type is &str or str (looking through references).
fn is_str_hir_type(ty: &hir_ty::Type) -> bool {
    match &ty.kind {
        &hir_ty::TypeKind::Primitive(hir_ty::PrimitiveTy::Str) => true,
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => is_str_hir_type(inner.as_ref()),
        _ => false,
    }
}

/// Resolves the LLVM element type for an indexing operation on a container HIR type.
/// For Vec<T>, returns the LLVM type of T. For Array/Slice, returns element type.
fn resolve_index_element_type(ctx: &mut codegen_ctx::CodegenCtx, container_ty: &hir_ty::Type) -> String {
    match &container_ty.kind {
        &hir_ty::TypeKind::Array { ref element, size: _ } => {
            codegen_size::type_to_llvm_with_ctx(ctx, element.as_ref())
        }
        &hir_ty::TypeKind::Slice { ref element } => {
            codegen_size::type_to_llvm_with_ctx(ctx, element.as_ref())
        }
        &hir_ty::TypeKind::Adt { def_id: _, ref args } => {
            // Vec<T> has T as first type argument
            if args.len() > 0 {
                codegen_size::type_to_llvm_with_ctx(ctx, &args[0])
            } else {
                common::make_string("i64")
            }
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            resolve_index_element_type(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Ptr { ref inner, mutable: _ } => {
            resolve_index_element_type(ctx, inner.as_ref())
        }
        &hir_ty::TypeKind::Primitive(hir_ty::PrimitiveTy::Str) => {
            // &str indexing accesses individual bytes (i8)
            common::make_string("i8")
        }
        _ => common::make_string("i64"),
    }
}

// ============================================================
// Rvalue Codegen
// ============================================================

/// Generates LLVM IR for an rvalue, storing result at dest.
pub fn emit_rvalue(
    ctx: &mut codegen_ctx::CodegenCtx,
    dest: &str,
    rvalue: &mir_types::Rvalue,
) {
    match rvalue {
        &mir_types::Rvalue::Use(ref operand) => {
            let (val, ty) = emit_operand_typed(ctx, operand);
            // Skip store for unit type {} — it has zero size in LLVM
            if !str_eq(ty.as_str(), "{}") {
                ctx.emit_store(ty.as_str(), val.as_str(), dest);
            }
        }
        &mir_types::Rvalue::Ref { ref place, mutable: _ } => {
            let addr = emit_place_data_ptr(ctx, place);
            ctx.emit_store("ptr", addr.as_str(), dest);
        }
        &mir_types::Rvalue::BinaryOp { op: ref bin_op, ref left, ref right } => {
            // Get typed operands
            let (left_val, left_ty) = emit_operand_typed(ctx, left);
            let (right_val, right_ty) = emit_operand_typed(ctx, right);
            // Determine signedness from the left operand's type
            let is_signed = operand_is_signed(ctx, left);
            // Coerce right operand to match left type if they differ
            let coerced_right = if !string_eq_str(left_ty.as_str(), right_ty.as_str()) {
                let left_w = llvm_int_bit_width(left_ty.as_str());
                let right_w = llvm_int_bit_width(right_ty.as_str());
                if left_w > 0 && right_w > 0 {
                    // Both are integer types - truncate or extend
                    let cast = ctx.fresh_temp();
                    if right_w > left_w {
                        ctx.emit_cast(cast.as_str(), "trunc", right_ty.as_str(), right_val.as_str(), left_ty.as_str());
                    } else {
                        if is_signed {
                            ctx.emit_cast(cast.as_str(), "sext", right_ty.as_str(), right_val.as_str(), left_ty.as_str());
                        } else {
                            ctx.emit_cast(cast.as_str(), "zext", right_ty.as_str(), right_val.as_str(), left_ty.as_str());
                        }
                    }
                    cast
                } else {
                    right_val
                }
            } else {
                right_val
            };
            // Use the left operand's type for the binary operation
            let result = emit_binop_typed(ctx, bin_op, &left_val, &coerced_right, left_ty.as_str(), is_signed);
            // For comparison operations, result is i1 (bool)
            if bin_op.is_comparison() {
                ctx.emit_store("i1", result.as_str(), dest);
            } else {
                ctx.emit_store(left_ty.as_str(), result.as_str(), dest);
            }
        }
        &mir_types::Rvalue::UnaryOp { op: ref un_op, ref operand } => {
            let (val, ty) = emit_operand_typed(ctx, operand);
            let result = emit_unop_typed(ctx, un_op, &val, ty.as_str());
            ctx.emit_store(ty.as_str(), result.as_str(), dest);
        }
        &mir_types::Rvalue::AddressOf { ref place, mutable: _ } => {
            let addr = emit_place_data_ptr(ctx, place);
            ctx.emit_store("ptr", addr.as_str(), dest);
        }
        &mir_types::Rvalue::ArrayToSlice { ref array_ref, array_len } => {
            // Convert array ref to fat pointer (ptr + len).
            // Slices are represented as { ptr, i64 } in LLVM IR.
            let arr_val = emit_operand(ctx, array_ref);

            // Store pointer at offset 0 of the fat pointer
            let ptr_field = ctx.fresh_temp();
            let mut ptr_indices: Vec<String> = Vec::new();
            ptr_indices.push(common::make_string("0"));
            ptr_indices.push(common::make_string("0"));
            ctx.emit_gep(ptr_field.as_str(), "{ ptr, i64 }", dest, &ptr_indices);
            ctx.emit_store("ptr", arr_val.as_str(), ptr_field.as_str());

            // Store length at offset 1 of the fat pointer
            let len_field = ctx.fresh_temp();
            let mut len_indices: Vec<String> = Vec::new();
            len_indices.push(common::make_string("0"));
            len_indices.push(common::make_string("1"));
            ctx.emit_gep(len_field.as_str(), "{ ptr, i64 }", dest, &len_indices);
            let len_val = codegen_types::format_u64(array_len);
            ctx.emit_store("i64", len_val.as_str(), len_field.as_str());
        }
        &mir_types::Rvalue::ZeroInit(ref ty) => {
            // Zero-initialize the destination
            let llvm_ty = ctx.type_to_llvm_with_ctx(ty);
            // Skip store for unit type {} — it has zero size in LLVM
            if !str_eq(llvm_ty.as_str(), "{}") {
                let zero = get_zero_value(llvm_ty.as_str());
                ctx.emit_store(llvm_ty.as_str(), zero.as_str(), dest);
            }
        }
        &mir_types::Rvalue::Cast { ref operand, ref target_ty } => {
            // Get source type from operand
            let (val, src_ty) = emit_operand_typed(ctx, operand);
            let tgt_llvm = ctx.type_to_llvm_with_ctx(target_ty);
            // Use the type-aware cast if we have source type info.
            // For Copy/Move operands, look up the local's HIR type so we get
            // correct sign-awareness (zext for unsigned, sext for signed).
            let src_ty_opt = match operand {
                &mir_types::Operand::Constant(ref constant) => Option::Some(hir_ty::copy_type(&constant.ty)),
                &mir_types::Operand::Copy(ref place) => {
                    match ctx.get_local_hir_type(place.local) {
                        Option::Some(hir_type) => Option::Some(hir_ty::copy_type(hir_type)),
                        Option::None => Option::None,
                    }
                }
                &mir_types::Operand::Move(ref place) => {
                    match ctx.get_local_hir_type(place.local) {
                        Option::Some(hir_type) => Option::Some(hir_ty::copy_type(hir_type)),
                        Option::None => Option::None,
                    }
                }
            };
            let result = match src_ty_opt {
                Option::Some(ref src_type) => emit_cast_with_types(ctx, &val, src_type, target_ty),
                Option::None => {
                    // Fallback: construct approximate source type from LLVM type
                    emit_cast_from_llvm_types(ctx, &val, src_ty.as_str(), tgt_llvm.as_str())
                }
            };
            ctx.emit_store(tgt_llvm.as_str(), result.as_str(), dest);
        }
        &mir_types::Rvalue::Aggregate { ref kind, ref operands } => {
            emit_aggregate(ctx, dest, kind, operands);
        }
        &mir_types::Rvalue::Len(ref place) => {
            // For slices - load the length field
            let mut ptr = emit_place_data_ptr(ctx, place);
            // Auto-deref for Ref-typed locals: the alloca (or heap slot) holds a pointer
            // to the actual data, not the data itself. Load through the pointer first.
            if place.projection.len() == 0 {
                match ctx.get_local_hir_type(place.local) {
                    Option::Some(hir_type) => {
                        match &hir_type.kind {
                            &hir_ty::TypeKind::Ref { inner: _, mutable: _ } => {
                                let deref = ctx.fresh_temp();
                                ctx.emit_load(deref.as_str(), "ptr", ptr.as_str());
                                ptr = deref;
                            }
                            _ => {}
                        }
                    }
                    Option::None => {}
                }
            }
            let len_ptr = ctx.fresh_temp();
            let mut indices: Vec<String> = Vec::new();
            indices.push(common::make_string("0"));
            indices.push(common::make_string("1"));
            ctx.emit_gep(len_ptr.as_str(), "{ ptr, i64 }", ptr.as_str(), &indices);
            let len_val = ctx.fresh_temp();
            ctx.emit_load(len_val.as_str(), "i64", len_ptr.as_str());
            ctx.emit_store("i64", len_val.as_str(), dest);
        }
        &mir_types::Rvalue::Discriminant(ref place) => {
            // Load discriminant field of enum
            let mut ptr = emit_place_data_ptr(ctx, place);
            // Auto-deref for Ref-typed locals: the alloca (or heap slot) holds a pointer
            // to the actual enum data, not the enum itself. Load through the pointer first.
            if place.projection.len() == 0 {
                match ctx.get_local_hir_type(place.local) {
                    Option::Some(hir_type) => {
                        match &hir_type.kind {
                            &hir_ty::TypeKind::Ref { inner: _, mutable: _ } => {
                                let deref = ctx.fresh_temp();
                                ctx.emit_load(deref.as_str(), "ptr", ptr.as_str());
                                ptr = deref;
                            }
                            _ => {}
                        }
                    }
                    Option::None => {}
                }
            }

            // Try to look up enum layout for correct discriminant type
            let mut discr_ty = common::make_string("i64");
            let mut enum_llvm_ty = common::make_string("{ i64, i64 }");
            let mut found_enum = false;

            match ctx.get_local_hir_type(place.local) {
                Option::Some(hir_type) => {
                    // Extract the enum DefId, unwrapping through Ref/Ptr.
                    // When matching on `&Enum`, the local's type is Ref { inner: Adt },
                    // not Adt directly.
                    let enum_def = extract_adt_def_id(hir_type);
                    match enum_def {
                        Option::Some(def_id) => {
                            match ctx.lookup_enum(def_id.index) {
                                Option::Some(layout) => {
                                    discr_ty = clone_string(&layout.discriminant_type);
                                    enum_llvm_ty = clone_string(&layout.llvm_type);
                                    found_enum = true;
                                }
                                Option::None => {}
                            }
                        }
                        Option::None => {}
                    }
                }
                Option::None => {}
            }

            if found_enum {
                // GEP to discriminant field (index 0) of the enum type
                let discr_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                indices.push(common::make_string("0"));
                ctx.emit_gep(discr_ptr.as_str(), enum_llvm_ty.as_str(), ptr.as_str(), &indices);
                let discr_val = ctx.fresh_temp();
                ctx.emit_load(discr_val.as_str(), discr_ty.as_str(), discr_ptr.as_str());
                // Extend discriminant to destination type if needed (dest is typically i64)
                if string_eq_str(discr_ty.as_str(), "i64") {
                    ctx.emit_store(discr_ty.as_str(), discr_val.as_str(), dest);
                } else {
                    // Zero-extend discriminant to i64 for use in switch
                    let extended = ctx.fresh_temp();
                    ctx.emit_cast(extended.as_str(), "zext", discr_ty.as_str(), discr_val.as_str(), "i64");
                    ctx.emit_store("i64", extended.as_str(), dest);
                }
            } else {
                // Fallback for builtin generic enums (Option<T>, Result<T,E>)
                // not in the ADT registry: load i8 discriminant and zero-extend.
                // All Blood enums have ≤256 variants → i8 discriminant.
                let discr_val = ctx.fresh_temp();
                ctx.emit_load(discr_val.as_str(), "i8", ptr.as_str());
                let extended = ctx.fresh_temp();
                ctx.emit_cast(extended.as_str(), "zext", "i8", discr_val.as_str(), "i64");
                ctx.emit_store("i64", extended.as_str(), dest);
            }
        }
    }
}

/// Extracts the Adt DefId from a type, unwrapping through Ref and Ptr layers.
/// Returns None if the underlying type is not an Adt.
fn extract_adt_def_id(ty: &hir_ty::Type) -> Option<hir_def::DefId> {
    match &ty.kind {
        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
            Option::Some(hir_def::DefId::new(def_id.index))
        }
        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
            extract_adt_def_id(inner.as_ref())
        }
        _ => Option::None,
    }
}

/// Gets the zero value for an LLVM type.
fn get_zero_value(llvm_ty: &str) -> String {
    if string_starts_with(llvm_ty, "float") {
        common::make_string("0.0")
    } else if string_starts_with(llvm_ty, "double") {
        common::make_string("0.0")
    } else if string_starts_with(llvm_ty, "ptr") {
        common::make_string("null")
    } else if string_starts_with(llvm_ty, "{") {
        common::make_string("zeroinitializer")
    } else if string_starts_with(llvm_ty, "[") {
        common::make_string("zeroinitializer")
    } else {
        common::make_string("0")
    }
}

/// Emits a cast based only on LLVM type strings.
fn emit_cast_from_llvm_types(
    ctx: &mut codegen_ctx::CodegenCtx,
    val: &String,
    src_ty: &str,
    tgt_ty: &str,
) -> String {
    let result = ctx.fresh_temp();

    // Quick check: if same type, just return value
    if string_eq_str(src_ty, tgt_ty) {
        return clone_string(val);
    }

    let src_is_float = string_starts_with(src_ty, "float") || string_starts_with(src_ty, "double");
    let tgt_is_float = string_starts_with(tgt_ty, "float") || string_starts_with(tgt_ty, "double");
    let src_is_ptr = string_starts_with(src_ty, "ptr");
    let tgt_is_ptr = string_starts_with(tgt_ty, "ptr");
    // Fat pointers (structs like { ptr, i64 }) should also be treated as ptr-like
    let src_is_fat_ptr = string_starts_with(src_ty, "{");

    if src_is_float && tgt_is_float {
        // Float to float
        let src_size = if string_starts_with(src_ty, "float") { 4u64 } else { 8u64 };
        let tgt_size = if string_starts_with(tgt_ty, "float") { 4u64 } else { 8u64 };
        if tgt_size < src_size {
            ctx.emit_cast(result.as_str(), "fptrunc", src_ty, val.as_str(), tgt_ty);
        } else if tgt_size > src_size {
            ctx.emit_cast(result.as_str(), "fpext", src_ty, val.as_str(), tgt_ty);
        } else {
            return clone_string(val);
        }
    } else if !src_is_float && tgt_is_float {
        // Int to float (default signed)
        ctx.emit_cast(result.as_str(), "sitofp", src_ty, val.as_str(), tgt_ty);
    } else if src_is_float && !tgt_is_float {
        // Float to int (default signed)
        ctx.emit_cast(result.as_str(), "fptosi", src_ty, val.as_str(), tgt_ty);
    } else if src_is_fat_ptr && tgt_is_ptr {
        // Fat pointer to thin pointer: extract the data pointer (field 0)
        ctx.write_indent();
        ctx.write_string(&result);
        ctx.write(" = extractvalue ");
        ctx.write(src_ty);
        ctx.write(" ");
        ctx.write_string(val);
        ctx.write(", 0\n");
    } else if src_is_fat_ptr && !tgt_is_ptr {
        // Fat pointer to int: extract ptr, then ptrtoint
        let extracted = ctx.fresh_temp();
        ctx.write_indent();
        ctx.write_string(&extracted);
        ctx.write(" = extractvalue ");
        ctx.write(src_ty);
        ctx.write(" ");
        ctx.write_string(val);
        ctx.write(", 0\n");
        ctx.emit_cast(result.as_str(), "ptrtoint", "ptr", extracted.as_str(), tgt_ty);
    } else if src_is_ptr && !tgt_is_ptr {
        // Pointer to int
        ctx.emit_cast(result.as_str(), "ptrtoint", src_ty, val.as_str(), tgt_ty);
    } else if !src_is_ptr && !src_is_fat_ptr && tgt_is_ptr {
        // Int to pointer (but not fat pointer source)
        ctx.emit_cast(result.as_str(), "inttoptr", src_ty, val.as_str(), tgt_ty);
    } else if src_is_ptr && tgt_is_ptr {
        // Pointer to pointer - bitcast
        ctx.emit_cast(result.as_str(), "bitcast", src_ty, val.as_str(), tgt_ty);
    } else {
        // Int to int - determine by size
        let src_size = get_int_type_size(src_ty);
        let tgt_size = get_int_type_size(tgt_ty);
        if tgt_size < src_size {
            ctx.emit_cast(result.as_str(), "trunc", src_ty, val.as_str(), tgt_ty);
        } else if tgt_size > src_size {
            // Default to sign extend
            ctx.emit_cast(result.as_str(), "sext", src_ty, val.as_str(), tgt_ty);
        } else {
            return clone_string(val);
        }
    }

    result
}

/// Gets the size in bits of an LLVM integer type (e.g., "i32" -> 32).
fn get_int_type_size(llvm_ty: &str) -> u64 {
    let bytes = llvm_ty.as_bytes();
    if bytes.len() < 2 {
        return 64; // Default
    }
    if bytes[0] != 105 {
        return 64; // Not 'i'
    }
    // Parse number after 'i'
    let mut n: u64 = 0;
    let mut i: usize = 1;
    while i < bytes.len() {
        let b = bytes[i];
        if b >= 48 && b <= 57 {
            n = n * 10 + ((b - 48) as u64);
        } else {
            break;
        }
        i = i + 1;
    }
    if n == 0 { 64 } else { n }
}

/// Returns the bit width for an LLVM integer type string (e.g., "i32" -> 32).
/// Checks if an LLVM type string is a struct or array type (starts with '{' or '[').
fn is_struct_or_array_type(ty: &String) -> bool {
    let bytes = ty.as_bytes();
    if bytes.len() > 0 {
        bytes[0] == 123 || bytes[0] == 91 // '{' or '['
    } else {
        false
    }
}

/// Returns true if the LLVM type looks like a Vec/container type whose first
/// field is a data pointer. These types have layout { ptr, ... } and require
/// loading the data pointer before indexing into the heap-allocated array.
fn is_vec_like_type(ty: &String) -> bool {
    // Check for "{ ptr" at the start — this matches Vec<T> = { ptr, i64, i64 }
    // and similar container types where field 0 is the heap data pointer.
    let bytes = ty.as_bytes();
    if bytes.len() >= 5 {
        bytes[0] == 123 && bytes[1] == 32 && bytes[2] == 112 && bytes[3] == 116 && bytes[4] == 114
        // '{' ' ' 'p' 't' 'r'
    } else {
        false
    }
}

/// Returns 0 for non-integer types.
fn llvm_int_bit_width(ty: &str) -> u32 {
    let bytes = ty.as_bytes();
    if bytes.len() < 2 {
        return 0;
    }
    if bytes[0] != 105 { // 'i'
        return 0;
    }
    // Parse the number after 'i'
    let mut val: u32 = 0;
    let mut idx: usize = 1;
    while idx < bytes.len() {
        let b = bytes[idx];
        if b >= 48 && b <= 57 {
            val = val * 10 + ((b - 48) as u32);
        } else {
            return 0; // Non-digit character means not a simple integer type
        }
        idx = idx + 1;
    }
    val
}

/// Extracts the first field type from a struct type string.
/// E.g., "{ i8 }" -> "i8", "{ i64, ptr }" -> "i64".
/// Returns "i64" as fallback if parsing fails.
fn extract_first_field_type(struct_ty: &str) -> String {
    let bytes = struct_ty.as_bytes();
    // Find start: skip "{ " (or just past '{')
    let mut start: usize = 0;
    let mut i: usize = 0;
    while i < bytes.len() {
        if bytes[i] == 123 {
            // '{'
            start = i + 1;
            // Skip whitespace
            while start < bytes.len() && bytes[start] == 32 {
                start = start + 1;
            }
            break;
        }
        i = i + 1;
    }
    // Find end: first ',', ' }', or '}'
    let mut end: usize = start;
    while end < bytes.len() {
        if bytes[end] == 44 || bytes[end] == 125 {
            // ',' or '}'
            break;
        }
        end = end + 1;
    }
    // Trim trailing whitespace
    while end > start && bytes[end - 1] == 32 {
        end = end - 1;
    }
    if end > start {
        let mut result = String::new();
        let mut j: usize = start;
        while j < end {
            result.push(bytes[j] as char);
            j = j + 1;
        }
        result
    } else {
        common::make_string("i64")
    }
}

/// Counts the number of top-level fields in a struct type string.
/// E.g., "{ i8 }" -> 1, "{ i64, ptr }" -> 2, "{ i8, [17 x i8] }" -> 2.
/// Returns 0 for non-struct types.
fn count_struct_fields(ty: &String) -> u32 {
    let bytes = ty.as_bytes();
    if bytes.len() < 2 || bytes[0] != 123 {
        return 0;
    }
    // Count commas at nesting depth 0 (inside the outermost braces)
    let mut count: u32 = 1; // At least 1 field if it's a struct
    let mut depth: u32 = 0;
    let mut i: usize = 1; // Skip opening '{'
    while i < bytes.len() {
        let b = bytes[i];
        if b == 123 || b == 91 {
            // '{' or '['
            depth = depth + 1;
        } else if b == 125 || b == 93 {
            // '}' or ']'
            if depth > 0 {
                depth = depth - 1;
            } else {
                break; // End of outermost struct
            }
        } else if b == 44 && depth == 0 {
            // ',' at top level
            count = count + 1;
        }
        i = i + 1;
    }
    // Handle empty struct "{}"
    if bytes.len() == 2 && bytes[0] == 123 && bytes[1] == 125 {
        return 0;
    }
    count
}

/// Compares string with &str.
fn string_eq_str(s: &str, other: &str) -> bool {
    let s_bytes = s.as_bytes();
    let other_bytes = other.as_bytes();
    if s_bytes.len() != other_bytes.len() {
        return false;
    }
    let mut i: usize = 0;
    while i < s_bytes.len() {
        if s_bytes[i] != other_bytes[i] {
            return false;
        }
        i = i + 1;
    }
    true
}

/// Emits a binary operation, returning the result value.
/// Uses i64 as the default type and assumes signed (legacy behavior).
fn emit_binop(
    ctx: &mut codegen_ctx::CodegenCtx,
    bin_op: &mir_types::MirBinOp,
    left: &String,
    right: &String,
) -> String {
    emit_binop_typed(ctx, bin_op, left, right, "i64", true)
}

/// Emits a binary operation with explicit type, returning the result value.
/// Handles both integer and floating-point operations based on the type.
/// The `signed` parameter indicates whether the operands are signed integers
/// (used for choosing sdiv vs udiv, srem vs urem, slt vs ult, etc.).
pub fn emit_binop_typed(
    ctx: &mut codegen_ctx::CodegenCtx,
    bin_op: &mir_types::MirBinOp,
    left: &String,
    right: &String,
    llvm_ty: &str,
    signed: bool,
) -> String {
    // If the type is an aggregate (struct), extract the first field for comparison.
    // LLVM icmp/binops don't work on aggregate types.
    let ty_bytes = llvm_ty.as_bytes();
    if ty_bytes.len() > 0 && ty_bytes[0] == 123 {
        // Aggregate type - extract first element and compare as that type
        let inner_ty = extract_first_field_type(llvm_ty);
        let left_elem = ctx.fresh_temp();
        ctx.write_indent();
        ctx.write_string(&left_elem);
        ctx.write(" = extractvalue ");
        ctx.write(llvm_ty);
        ctx.write(" ");
        ctx.write_string(left);
        ctx.write(", 0\n");
        let right_elem = ctx.fresh_temp();
        ctx.write_indent();
        ctx.write_string(&right_elem);
        ctx.write(" = extractvalue ");
        ctx.write(llvm_ty);
        ctx.write(" ");
        ctx.write_string(right);
        ctx.write(", 0\n");
        return emit_binop_typed(ctx, bin_op, &left_elem, &right_elem, inner_ty.as_str(), signed);
    }

    let result = ctx.fresh_temp();
    let l = left.as_str();
    let r = right.as_str();
    let res = result.as_str();

    // Check if this is a floating-point type
    let is_float = string_starts_with(llvm_ty, "float") || string_starts_with(llvm_ty, "double");

    if is_float {
        // Floating-point operations
        match bin_op {
            &mir_types::MirBinOp::Add => ctx.emit_binop(res, "fadd", llvm_ty, l, r),
            &mir_types::MirBinOp::Sub => ctx.emit_binop(res, "fsub", llvm_ty, l, r),
            &mir_types::MirBinOp::Mul => ctx.emit_binop(res, "fmul", llvm_ty, l, r),
            &mir_types::MirBinOp::Div => ctx.emit_binop(res, "fdiv", llvm_ty, l, r),
            &mir_types::MirBinOp::Rem => ctx.emit_binop(res, "frem", llvm_ty, l, r),
            // Floating-point comparisons use ordered comparisons (NaN returns false)
            &mir_types::MirBinOp::Eq => ctx.emit_fcmp(res, "oeq", llvm_ty, l, r),
            &mir_types::MirBinOp::Ne => ctx.emit_fcmp(res, "one", llvm_ty, l, r),
            &mir_types::MirBinOp::Lt => ctx.emit_fcmp(res, "olt", llvm_ty, l, r),
            &mir_types::MirBinOp::Le => ctx.emit_fcmp(res, "ole", llvm_ty, l, r),
            &mir_types::MirBinOp::Gt => ctx.emit_fcmp(res, "ogt", llvm_ty, l, r),
            &mir_types::MirBinOp::Ge => ctx.emit_fcmp(res, "oge", llvm_ty, l, r),
            // Bitwise operations don't apply to floats - emit error comment
            &mir_types::MirBinOp::BitAnd => {
                ctx.write("    ; ERROR: bitwise AND on float\n");
                ctx.emit_binop(res, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::BitOr => {
                ctx.write("    ; ERROR: bitwise OR on float\n");
                ctx.emit_binop(res, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::BitXor => {
                ctx.write("    ; ERROR: bitwise XOR on float\n");
                ctx.emit_binop(res, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::Shl => {
                ctx.write("    ; ERROR: shift left on float\n");
                ctx.emit_binop(res, "fadd", llvm_ty, l, "0.0");
            }
            &mir_types::MirBinOp::Shr => {
                ctx.write("    ; ERROR: shift right on float\n");
                ctx.emit_binop(res, "fadd", llvm_ty, l, "0.0");
            }
            // Checked operations - floats don't have overflow, treat as unchecked
            &mir_types::MirBinOp::AddChecked => ctx.emit_binop(res, "fadd", llvm_ty, l, r),
            &mir_types::MirBinOp::SubChecked => ctx.emit_binop(res, "fsub", llvm_ty, l, r),
            &mir_types::MirBinOp::MulChecked => ctx.emit_binop(res, "fmul", llvm_ty, l, r),
        }
    } else {
        // Integer operations with correct signedness
        let is_unsigned = !signed;

        match bin_op {
            &mir_types::MirBinOp::Add => ctx.emit_binop(res, "add", llvm_ty, l, r),
            &mir_types::MirBinOp::Sub => ctx.emit_binop(res, "sub", llvm_ty, l, r),
            &mir_types::MirBinOp::Mul => ctx.emit_binop(res, "mul", llvm_ty, l, r),
            &mir_types::MirBinOp::Div => {
                if is_unsigned {
                    ctx.emit_binop(res, "udiv", llvm_ty, l, r);
                } else {
                    ctx.emit_binop(res, "sdiv", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Rem => {
                if is_unsigned {
                    ctx.emit_binop(res, "urem", llvm_ty, l, r);
                } else {
                    ctx.emit_binop(res, "srem", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::BitAnd => ctx.emit_binop(res, "and", llvm_ty, l, r),
            &mir_types::MirBinOp::BitOr => ctx.emit_binop(res, "or", llvm_ty, l, r),
            &mir_types::MirBinOp::BitXor => ctx.emit_binop(res, "xor", llvm_ty, l, r),
            &mir_types::MirBinOp::Shl => ctx.emit_binop(res, "shl", llvm_ty, l, r),
            &mir_types::MirBinOp::Shr => {
                if is_unsigned {
                    ctx.emit_binop(res, "lshr", llvm_ty, l, r);
                } else {
                    ctx.emit_binop(res, "ashr", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Eq => ctx.emit_icmp(res, "eq", llvm_ty, l, r),
            &mir_types::MirBinOp::Ne => ctx.emit_icmp(res, "ne", llvm_ty, l, r),
            &mir_types::MirBinOp::Lt => {
                if is_unsigned {
                    ctx.emit_icmp(res, "ult", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp(res, "slt", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Le => {
                if is_unsigned {
                    ctx.emit_icmp(res, "ule", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp(res, "sle", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Gt => {
                if is_unsigned {
                    ctx.emit_icmp(res, "ugt", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp(res, "sgt", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::Ge => {
                if is_unsigned {
                    ctx.emit_icmp(res, "uge", llvm_ty, l, r);
                } else {
                    ctx.emit_icmp(res, "sge", llvm_ty, l, r);
                }
            }
            // Checked operations - use LLVM overflow intrinsics and trap on overflow
            &mir_types::MirBinOp::AddChecked => {
                if is_unsigned {
                    emit_checked_binop(ctx, res, "uadd", llvm_ty, l, r);
                } else {
                    emit_checked_binop(ctx, res, "sadd", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::SubChecked => {
                if is_unsigned {
                    emit_checked_binop(ctx, res, "usub", llvm_ty, l, r);
                } else {
                    emit_checked_binop(ctx, res, "ssub", llvm_ty, l, r);
                }
            }
            &mir_types::MirBinOp::MulChecked => {
                if is_unsigned {
                    emit_checked_binop(ctx, res, "umul", llvm_ty, l, r);
                } else {
                    emit_checked_binop(ctx, res, "smul", llvm_ty, l, r);
                }
            }
        }
    }

    result
}

/// Emits a checked binary operation using LLVM overflow intrinsics.
/// On overflow, traps with @llvm.trap().
///
/// Uses intrinsics like @llvm.sadd.with.overflow.i64, @llvm.ssub.with.overflow.i64, etc.
/// These return { iN, i1 } where the second element is the overflow flag.
fn emit_checked_binop(
    ctx: &mut codegen_ctx::CodegenCtx,
    result: &str,
    intrinsic_base: &str,
    llvm_ty: &str,
    left: &str,
    right: &str,
) {
    // Build the intrinsic name: @llvm.sadd.with.overflow.i64
    let mut intrinsic_name = common::make_string("@llvm.");
    intrinsic_name.push_str(intrinsic_base);
    intrinsic_name.push_str(".with.overflow.");
    intrinsic_name.push_str(llvm_ty);

    // Build the return type: { i64, i1 }
    let mut ret_ty = common::make_string("{ ");
    ret_ty.push_str(llvm_ty);
    ret_ty.push_str(", i1 }");

    // Call the intrinsic
    let overflow_result = ctx.fresh_temp();
    ctx.write_indent();
    ctx.write_string(&overflow_result);
    ctx.write(" = call ");
    ctx.write_string(&ret_ty);
    ctx.write(" ");
    ctx.write_string(&intrinsic_name);
    ctx.write("(");
    ctx.write(llvm_ty);
    ctx.write(" ");
    ctx.write(left);
    ctx.write(", ");
    ctx.write(llvm_ty);
    ctx.write(" ");
    ctx.write(right);
    ctx.write(")\n");

    // Extract the result value
    ctx.write_indent();
    ctx.write(result);
    ctx.write(" = extractvalue ");
    ctx.write_string(&ret_ty);
    ctx.write(" ");
    ctx.write_string(&overflow_result);
    ctx.write(", 0\n");

    // Extract the overflow flag
    let overflow_flag = ctx.fresh_temp();
    ctx.write_indent();
    ctx.write_string(&overflow_flag);
    ctx.write(" = extractvalue ");
    ctx.write_string(&ret_ty);
    ctx.write(" ");
    ctx.write_string(&overflow_result);
    ctx.write(", 1\n");

    // Emit conditional trap on overflow using basic blocks
    let trap_label = ctx.fresh_label();
    let continue_label = ctx.fresh_label();

    ctx.emit_cond_br(overflow_flag.as_str(), trap_label.as_str(), continue_label.as_str());

    // Trap block
    ctx.emit_label(trap_label.as_str());
    ctx.indent();
    ctx.write("    call void @llvm.trap()\n");
    ctx.emit_unreachable();
    ctx.dedent();

    // Continue block
    ctx.emit_label(continue_label.as_str());
}

/// Checks if a string starts with a prefix.
fn string_starts_with(s: &str, prefix: &str) -> bool {
    let s_bytes = s.as_bytes();
    let prefix_bytes = prefix.as_bytes();
    if prefix_bytes.len() > s_bytes.len() {
        return false;
    }
    let mut i: usize = 0;
    while i < prefix_bytes.len() {
        if s_bytes[i] != prefix_bytes[i] {
            return false;
        }
        i = i + 1;
    }
    true
}

/// Determines whether an operand is signed, using local signedness tracking
/// for Copy/Move operands and HIR type info for constants.
fn operand_is_signed(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> bool {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            ctx.is_local_signed(place.local)
        }
        &mir_types::Operand::Move(ref place) => {
            ctx.is_local_signed(place.local)
        }
        &mir_types::Operand::Constant(ref constant) => {
            codegen_types::is_signed(&constant.ty)
        }
    }
}

/// Emits a unary operation, returning the result value.
fn emit_unop(
    ctx: &mut codegen_ctx::CodegenCtx,
    un_op: &mir_types::MirUnOp,
    operand: &String,
) -> String {
    emit_unop_typed(ctx, un_op, operand, "i64")
}

/// Emits a unary operation with explicit type, returning the result value.
/// Handles both integer and floating-point operations.
fn emit_unop_typed(
    ctx: &mut codegen_ctx::CodegenCtx,
    un_op: &mir_types::MirUnOp,
    operand: &String,
    llvm_ty: &str,
) -> String {
    let result = ctx.fresh_temp();
    let v = operand.as_str();
    let res = result.as_str();

    // Check if this is a floating-point type
    let is_float = string_starts_with(llvm_ty, "float") || string_starts_with(llvm_ty, "double");

    match un_op {
        &mir_types::MirUnOp::Neg => {
            if is_float {
                // fneg is a unary op: %res = fneg <ty> <val>
                ctx.write_indent();
                ctx.write(res);
                ctx.write(" = fneg ");
                ctx.write(llvm_ty);
                ctx.write(" ");
                ctx.write(v);
                ctx.write("\n");
            } else {
                ctx.emit_binop(res, "sub", llvm_ty, "0", v);
            }
        }
        &mir_types::MirUnOp::Not => {
            if is_float {
                // Not doesn't make sense for floats - emit error
                ctx.write("    ; ERROR: bitwise NOT on float\n");
                ctx.emit_binop(res, "fadd", llvm_ty, v, "0.0");
            } else {
                ctx.emit_binop(res, "xor", llvm_ty, v, "-1");
            }
        }
    }

    result
}

/// Emits a cast operation, returning the result value.
/// Takes the source type and target type to determine the correct cast instruction.
fn emit_cast_with_types(
    ctx: &mut codegen_ctx::CodegenCtx,
    val: &String,
    source_ty: &hir_ty::Type,
    target_ty: &hir_ty::Type,
) -> String {
    let src_llvm = ctx.type_to_llvm_with_ctx(source_ty);
    let tgt_llvm = ctx.type_to_llvm_with_ctx(target_ty);
    let result = ctx.fresh_temp();

    // Determine the cast instruction based on types
    let src_is_int = codegen_types::is_integer(source_ty);
    let tgt_is_int = codegen_types::is_integer(target_ty);
    let src_is_float = codegen_types::is_float(source_ty);
    let tgt_is_float = codegen_types::is_float(target_ty);
    let src_is_signed = codegen_types::is_signed(source_ty);
    let src_is_ptr = codegen_types::is_pointer_like(source_ty);
    let tgt_is_ptr = codegen_types::is_pointer_like(target_ty);

    let src_size = codegen_size::type_size_with_ctx(ctx, source_ty);
    let tgt_size = codegen_size::type_size_with_ctx(ctx, target_ty);

    if src_is_int && tgt_is_int {
        // Integer to integer cast
        if tgt_size < src_size {
            ctx.emit_cast(result.as_str(), "trunc", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else if tgt_size > src_size {
            if src_is_signed {
                ctx.emit_cast(result.as_str(), "sext", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
            } else {
                ctx.emit_cast(result.as_str(), "zext", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
            }
        } else {
            // Same size - bitcast or just copy
            return clone_string(val);
        }
    } else if src_is_float && tgt_is_float {
        // Float to float cast
        if tgt_size < src_size {
            ctx.emit_cast(result.as_str(), "fptrunc", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else if tgt_size > src_size {
            ctx.emit_cast(result.as_str(), "fpext", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else {
            return clone_string(val);
        }
    } else if src_is_int && tgt_is_float {
        // Integer to float
        if src_is_signed {
            ctx.emit_cast(result.as_str(), "sitofp", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else {
            ctx.emit_cast(result.as_str(), "uitofp", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        }
    } else if src_is_float && tgt_is_int {
        // Float to integer
        let tgt_is_signed = codegen_types::is_signed(target_ty);
        if tgt_is_signed {
            ctx.emit_cast(result.as_str(), "fptosi", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        } else {
            ctx.emit_cast(result.as_str(), "fptoui", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
        }
    } else if src_is_ptr && tgt_is_int {
        // Pointer to integer
        ctx.emit_cast(result.as_str(), "ptrtoint", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
    } else if src_is_int && tgt_is_ptr {
        // Integer to pointer
        ctx.emit_cast(result.as_str(), "inttoptr", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
    } else if src_is_ptr && tgt_is_ptr {
        // Pointer to pointer
        // Check if source is a fat pointer (struct) being cast to thin pointer
        let src_bytes = src_llvm.as_bytes();
        let tgt_bytes = tgt_llvm.as_bytes();
        let src_is_fat = src_bytes.len() > 0 && src_bytes[0] == 123;  // '{'
        let tgt_is_thin = tgt_bytes.len() > 0 && tgt_bytes[0] == 112; // 'p' for "ptr"
        if src_is_fat && tgt_is_thin {
            // Fat pointer to thin pointer: extract the data pointer (field 0)
            ctx.write_indent();
            ctx.write_string(&result);
            ctx.write(" = extractvalue ");
            ctx.write_string(&src_llvm);
            ctx.write(" ");
            ctx.write_string(val);
            ctx.write(", 0\n");
        } else if src_is_fat {
            // Fat pointer to fat pointer: just copy
            return clone_string(val);
        } else {
            // Thin pointer to pointer: bitcast or just copy if same
            if string_eq_str(src_llvm.as_str(), tgt_llvm.as_str()) {
                return clone_string(val);
            } else {
                ctx.emit_cast(result.as_str(), "bitcast", src_llvm.as_str(), val.as_str(), tgt_llvm.as_str());
            }
        }
    } else {
        // Fallback: delegate to LLVM-type-based cast logic which correctly
        // handles int-to-int (trunc/sext), fat pointer extraction, etc.
        // This path is reached when HIR types are Infer/Param (unresolved).
        return emit_cast_from_llvm_types(ctx, val, src_llvm.as_str(), tgt_llvm.as_str());
    }

    result
}

/// Gets the LLVM type string for an operand without emitting any IR.
fn operand_llvm_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    operand: &mir_types::Operand,
) -> String {
    match operand {
        &mir_types::Operand::Copy(ref place) => {
            ctx.get_local_type(place.local)
        }
        &mir_types::Operand::Move(ref place) => {
            ctx.get_local_type(place.local)
        }
        &mir_types::Operand::Constant(ref constant) => {
            ctx.type_to_llvm_with_ctx(&constant.ty)
        }
    }
}

/// Builds an LLVM struct type string from operand types (for tuples, records, closures).
/// Returns e.g. "{ i32, i64, ptr }".
fn build_tuple_llvm_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    operands: &Vec<mir_types::Operand>,
) -> String {
    let mut result = common::make_string("{ ");
    let mut i: usize = 0;
    while i < operands.len() {
        if i > 0 {
            result.push_str(", ");
        }
        let ty = operand_llvm_type(ctx, &operands[i]);
        result.push_str(ty.as_str());
        i = i + 1;
    }
    result.push_str(" }");
    result
}

/// Emits an ADT aggregate (struct or enum variant) using the ADT registry.
fn emit_aggregate_adt(
    ctx: &mut codegen_ctx::CodegenCtx,
    dest: &str,
    def_id: u32,
    variant_idx: u32,
    operands: &Vec<mir_types::Operand>,
    type_args: &Vec<hir_ty::Type>,
) {
    // Try struct first
    match ctx.lookup_struct(def_id) {
        Option::Some(layout) => {
            // Check if any field has an unresolved Param/Infer HIR type
            let has_params = layout_has_param_fields(layout);
            // Collect base field types from registry
            let mut field_types: Vec<String> = Vec::new();
            let mut fi: usize = 0;
            while fi < layout.fields.len() {
                field_types.push(clone_string(&layout.fields[fi].llvm_type));
                fi = fi + 1;
            }
            let struct_ty = clone_string(&layout.llvm_type);
            // If the struct has param/infer fields and concrete type args are available,
            // compute concrete field types by substituting type args for param fields.
            if has_params && type_args.len() > 0 {
                let mut param_idx: usize = 0;
                let mut fj: usize = 0;
                while fj < layout.fields.len() {
                    let is_param = match &layout.fields[fj].hir_type {
                        &Option::Some(ref hir_ty) => {
                            match &hir_ty.kind {
                                &hir_ty::TypeKind::Param(_) => true,
                                &hir_ty::TypeKind::Infer(_) => true,
                                _ => false,
                            }
                        }
                        &Option::None => false,
                    };
                    if is_param && param_idx < type_args.len() {
                        field_types[fj] = codegen_types::type_to_llvm(&type_args[param_idx]);
                        param_idx = param_idx + 1;
                    }
                    fj = fj + 1;
                }
            }
            // Rebuild struct_ty from field_types if params were substituted
            let struct_ty = if has_params && type_args.len() > 0 {
                let mut s = common::make_string("{ ");
                let mut si: usize = 0;
                while si < field_types.len() {
                    if si > 0 {
                        s.push_str(", ");
                    }
                    s.push_str(field_types[si].as_str());
                    si = si + 1;
                }
                s.push_str(" }");
                s
            } else {
                struct_ty
            };
            // Store each field using actual types from the struct layout.
            // If the operand type differs from the field type (e.g., i64 vs i32),
            // emit a trunc or zext to match the target field width.
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let operand_val = typed.0;
                let operand_ty = typed.1;
                let field_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                indices.push(codegen_types::format_u64(i as u64));
                ctx.emit_gep(field_ptr.as_str(), struct_ty.as_str(), dest, &indices);
                // Use actual field type if available, fallback to i64
                let field_ty_str = if i < field_types.len() {
                    field_types[i].as_str()
                } else {
                    "i64"
                };
                // Check if operand type matches field type
                if string_eq_str(operand_ty.as_str(), field_ty_str) {
                    ctx.emit_store(field_ty_str, operand_val.as_str(), field_ptr.as_str());
                } else {
                    let src_w = llvm_int_bit_width(operand_ty.as_str());
                    let dst_w = llvm_int_bit_width(field_ty_str);
                    if src_w > dst_w && dst_w > 0 {
                        // Wider to narrower: truncate
                        let cast_tmp = ctx.fresh_temp();
                        ctx.emit_cast(cast_tmp.as_str(), "trunc", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                        ctx.emit_store(field_ty_str, cast_tmp.as_str(), field_ptr.as_str());
                    } else if src_w < dst_w && src_w > 0 {
                        // Narrower to wider: zero-extend
                        let cast_tmp = ctx.fresh_temp();
                        ctx.emit_cast(cast_tmp.as_str(), "zext", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                        ctx.emit_store(field_ty_str, cast_tmp.as_str(), field_ptr.as_str());
                    } else if src_w > 0 && string_eq_str(field_ty_str, "ptr") {
                        // Integer to pointer: inttoptr
                        let cast_tmp = ctx.fresh_temp();
                        ctx.emit_cast(cast_tmp.as_str(), "inttoptr", operand_ty.as_str(), operand_val.as_str(), "ptr");
                        ctx.emit_store("ptr", cast_tmp.as_str(), field_ptr.as_str());
                    } else if dst_w > 0 && string_eq_str(operand_ty.as_str(), "ptr") {
                        // Pointer to integer: ptrtoint
                        let cast_tmp = ctx.fresh_temp();
                        ctx.emit_cast(cast_tmp.as_str(), "ptrtoint", "ptr", operand_val.as_str(), field_ty_str);
                        ctx.emit_store(field_ty_str, cast_tmp.as_str(), field_ptr.as_str());
                    } else {
                        // Other mismatch (e.g., i64 vs struct type from unresolved inference).
                        // Store with the operand's own type so the IR is valid.
                        ctx.emit_store(operand_ty.as_str(), operand_val.as_str(), field_ptr.as_str());
                    }
                }
                i = i + 1;
            }
            return;
        }
        Option::None => {}
    }
    // Try enum
    match ctx.lookup_enum(def_id) {
        Option::Some(layout) => {
            let enum_ty = clone_string(&layout.llvm_type);
            let discr_ty = clone_string(&layout.discriminant_type);
            // Find the variant's payload type and field types
            let mut payload_ty = common::make_string("{}");
            let mut variant_field_types: Vec<String> = Vec::new();
            let mut vi: usize = 0;
            while vi < layout.variants.len() {
                if layout.variants[vi].variant_idx == variant_idx {
                    payload_ty = clone_string(&layout.variants[vi].payload_llvm_type);
                    let mut vfi: usize = 0;
                    while vfi < layout.variants[vi].fields.len() {
                        variant_field_types.push(clone_string(&layout.variants[vi].fields[vfi].llvm_type));
                        vfi = vfi + 1;
                    }
                }
                vi = vi + 1;
            }

            // Store discriminant at field 0 of the enum type
            let discr_ptr = ctx.fresh_temp();
            let mut discr_indices: Vec<String> = Vec::new();
            discr_indices.push(common::make_string("0"));
            discr_indices.push(common::make_string("0"));
            ctx.emit_gep(discr_ptr.as_str(), enum_ty.as_str(), dest, &discr_indices);
            let discr_val = codegen_types::format_u64(variant_idx as u64);
            ctx.emit_store(discr_ty.as_str(), discr_val.as_str(), discr_ptr.as_str());

            // Store payload fields only if there are operands
            if operands.len() > 0 {
                // Get pointer to payload area (field 1 of enum type)
                let data_ptr = ctx.fresh_temp();
                let mut data_indices: Vec<String> = Vec::new();
                data_indices.push(common::make_string("0"));
                data_indices.push(common::make_string("1"));
                ctx.emit_gep(data_ptr.as_str(), enum_ty.as_str(), dest, &data_indices);

                // Store each operand field using the variant's payload type
                let mut i: usize = 0;
                while i < operands.len() {
                    let typed = emit_operand_typed(ctx, &operands[i]);
                    let operand_val = typed.0;
                    let operand_ty = typed.1;
                    let field_ptr = ctx.fresh_temp();
                    let mut field_indices: Vec<String> = Vec::new();
                    field_indices.push(common::make_string("0"));
                    field_indices.push(codegen_types::format_u64(i as u64));
                    ctx.emit_gep(field_ptr.as_str(), payload_ty.as_str(), data_ptr.as_str(), &field_indices);
                    // Use actual field type if available, with type conversion if needed
                    let field_ty_str = if i < variant_field_types.len() {
                        variant_field_types[i].as_str()
                    } else {
                        "i64"
                    };
                    // Check if operand type matches field type
                    if string_eq_str(operand_ty.as_str(), field_ty_str) {
                        ctx.emit_store(field_ty_str, operand_val.as_str(), field_ptr.as_str());
                    } else {
                        let src_w = llvm_int_bit_width(operand_ty.as_str());
                        let dst_w = llvm_int_bit_width(field_ty_str);
                        if src_w > dst_w && dst_w > 0 {
                            // Wider to narrower: truncate
                            let cast_tmp = ctx.fresh_temp();
                            ctx.emit_cast(cast_tmp.as_str(), "trunc", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                            ctx.emit_store(field_ty_str, cast_tmp.as_str(), field_ptr.as_str());
                        } else if src_w < dst_w && src_w > 0 {
                            // Narrower to wider: zero-extend
                            let cast_tmp = ctx.fresh_temp();
                            ctx.emit_cast(cast_tmp.as_str(), "zext", operand_ty.as_str(), operand_val.as_str(), field_ty_str);
                            ctx.emit_store(field_ty_str, cast_tmp.as_str(), field_ptr.as_str());
                        } else if src_w > 0 && string_eq_str(field_ty_str, "ptr") {
                            // Integer to pointer: inttoptr
                            let cast_tmp = ctx.fresh_temp();
                            ctx.emit_cast(cast_tmp.as_str(), "inttoptr", operand_ty.as_str(), operand_val.as_str(), "ptr");
                            ctx.emit_store("ptr", cast_tmp.as_str(), field_ptr.as_str());
                        } else if dst_w > 0 && string_eq_str(operand_ty.as_str(), "ptr") {
                            // Pointer to integer: ptrtoint
                            let cast_tmp = ctx.fresh_temp();
                            ctx.emit_cast(cast_tmp.as_str(), "ptrtoint", "ptr", operand_val.as_str(), field_ty_str);
                            ctx.emit_store(field_ty_str, cast_tmp.as_str(), field_ptr.as_str());
                        } else {
                            // Other mismatch (e.g., aggregate type from nested enum).
                            // Store with the operand's own type so the IR is valid.
                            ctx.emit_store(operand_ty.as_str(), operand_val.as_str(), field_ptr.as_str());
                        }
                    }
                    i = i + 1;
                }
            }
            return;
        }
        Option::None => {}
    }
    // Fallback: ADT not in registry (builtin generic enum like Option<T>, Result<T,E>).
    // Emit as enum: store i8 discriminant at byte 0, payload fields starting at byte 1.
    let mut vals: Vec<String> = Vec::new();
    let mut tys: Vec<String> = Vec::new();
    let mut k: usize = 0;
    while k < operands.len() {
        let typed = emit_operand_typed(ctx, &operands[k]);
        vals.push(typed.0);
        tys.push(typed.1);
        k = k + 1;
    }

    // Store i8 discriminant at byte 0
    ctx.emit_store("i8", codegen_types::format_u64(variant_idx as u64).as_str(), dest);

    // Store payload fields at byte offset 1 (after i8 discriminant)
    if vals.len() > 0 {
        let payload_ptr = ctx.fresh_temp();
        let mut off_indices: Vec<String> = Vec::new();
        off_indices.push(common::make_string("1"));
        ctx.emit_gep(payload_ptr.as_str(), "i8", dest, &off_indices);

        // Build payload struct type from operand types
        let mut payload_ty = common::make_string("{ ");
        let mut pi: usize = 0;
        while pi < tys.len() {
            if pi > 0 {
                payload_ty.push_str(", ");
            }
            payload_ty.push_str(tys[pi].as_str());
            pi = pi + 1;
        }
        payload_ty.push_str(" }");

        // Store each field in the payload
        let mut i: usize = 0;
        while i < vals.len() {
            let field_ptr = ctx.fresh_temp();
            let mut field_indices: Vec<String> = Vec::new();
            field_indices.push(common::make_string("0"));
            field_indices.push(codegen_types::format_u64(i as u64));
            ctx.emit_gep(field_ptr.as_str(), payload_ty.as_str(), payload_ptr.as_str(), &field_indices);
            ctx.emit_store(tys[i].as_str(), vals[i].as_str(), field_ptr.as_str());
            i = i + 1;
        }
    }
}

/// Checks if any field in a struct layout has a Param or Infer HIR type.
fn layout_has_param_fields(layout: &codegen_ctx::StructLayout) -> bool {
    let mut i: usize = 0;
    while i < layout.fields.len() {
        match &layout.fields[i].hir_type {
            &Option::Some(ref hir_ty) => {
                match &hir_ty.kind {
                    &hir_ty::TypeKind::Param(_) => { return true; }
                    &hir_ty::TypeKind::Infer(_) => { return true; }
                    _ => {}
                }
            }
            &Option::None => {}
        }
        i = i + 1;
    }
    false
}

/// Emits an aggregate construction.
fn emit_aggregate(
    ctx: &mut codegen_ctx::CodegenCtx,
    dest: &str,
    kind: &mir_types::AggregateKind,
    operands: &Vec<mir_types::Operand>,
) {
    match kind {
        &mir_types::AggregateKind::Tuple => {
            // Build the tuple LLVM type from operand types
            let tuple_llvm = build_tuple_llvm_type(ctx, operands);
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let field_val = typed.0;
                let field_ty = typed.1;
                let field_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                indices.push(codegen_types::format_u64(i as u64));
                ctx.emit_gep(field_ptr.as_str(), tuple_llvm.as_str(), dest, &indices);
                ctx.emit_store(field_ty.as_str(), field_val.as_str(), field_ptr.as_str());
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Array(ref elem_ty) => {
            let mut elem_llvm = ctx.type_to_llvm_with_ctx(elem_ty);
            // If the element type is unresolved (Infer → i64 fallback), use
            // the actual type from the first operand instead.
            if operands.len() > 0 {
                let (first_val, first_ty) = emit_operand_typed(ctx, &operands[0]);
                if !str_eq(first_ty.as_str(), elem_llvm.as_str()) {
                    elem_llvm = clone_string(&first_ty);
                }
                let elem_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                ctx.emit_gep(elem_ptr.as_str(), elem_llvm.as_str(), dest, &indices);
                ctx.emit_store(elem_llvm.as_str(), first_val.as_str(), elem_ptr.as_str());
            }
            let mut i: usize = 1;
            while i < operands.len() {
                let elem_val = emit_operand(ctx, &operands[i]);
                let elem_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(codegen_types::format_u64(i as u64));
                ctx.emit_gep(elem_ptr.as_str(), elem_llvm.as_str(), dest, &indices);
                ctx.emit_store(elem_llvm.as_str(), elem_val.as_str(), elem_ptr.as_str());
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Adt { ref def_id, variant_idx, ref type_args } => {
            // Look up the ADT in the registry to determine if it's a struct or enum
            emit_aggregate_adt(ctx, dest, def_id.index, variant_idx, operands, type_args);
        }
        &mir_types::AggregateKind::Record => {
            // Extensible records - store fields with actual types
            let record_llvm = build_tuple_llvm_type(ctx, operands);
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let field_val = typed.0;
                let field_ty = typed.1;
                let field_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                indices.push(codegen_types::format_u64(i as u64));
                ctx.emit_gep(field_ptr.as_str(), record_llvm.as_str(), dest, &indices);
                ctx.emit_store(field_ty.as_str(), field_val.as_str(), field_ptr.as_str());
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Closure { def_id: _ } => {
            // Closures: store captures with actual types
            let closure_llvm = build_tuple_llvm_type(ctx, operands);
            let mut i: usize = 0;
            while i < operands.len() {
                let typed = emit_operand_typed(ctx, &operands[i]);
                let cap_val = typed.0;
                let cap_ty = typed.1;
                let cap_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                indices.push(codegen_types::format_u64(i as u64));
                ctx.emit_gep(cap_ptr.as_str(), closure_llvm.as_str(), dest, &indices);
                ctx.emit_store(cap_ty.as_str(), cap_val.as_str(), cap_ptr.as_str());
                i = i + 1;
            }
        }
        &mir_types::AggregateKind::Range { ref element, inclusive: _ } => {
            // Ranges: store start and end with element type
            let elem_llvm = ctx.type_to_llvm_with_ctx(element);
            // Range struct is { elem_type, elem_type } (start, end)
            let mut range_llvm = common::make_string("{ ");
            let mut fi: usize = 0;
            while fi < operands.len() {
                if fi > 0 {
                    range_llvm.push_str(", ");
                }
                range_llvm.push_str(elem_llvm.as_str());
                fi = fi + 1;
            }
            range_llvm.push_str(" }");

            let mut i: usize = 0;
            while i < operands.len() {
                let val = emit_operand(ctx, &operands[i]);
                let ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                indices.push(codegen_types::format_u64(i as u64));
                ctx.emit_gep(ptr.as_str(), range_llvm.as_str(), dest, &indices);
                ctx.emit_store(elem_llvm.as_str(), val.as_str(), ptr.as_str());
                i = i + 1;
            }
        }
    }
}

// ============================================================
// String Helpers
// ============================================================

/// Clones a String.
fn clone_string(s: &String) -> String {
    let mut result = String::new();
    result.push_str(s.as_str());
    result
}
