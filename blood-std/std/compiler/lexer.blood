// Blood Self-Hosted Compiler - Lexer
//
// This module tokenizes Blood source code into a stream of tokens.
// Written to be compiled by blood-rust (commit 1148f02).

/// Span in source code with byte offsets and line/column info
pub struct Span {
    /// Start byte offset (inclusive)
    pub start: usize,
    /// End byte offset (exclusive)
    pub end: usize,
    /// Line number (1-based)
    pub line: u32,
    /// Column number (1-based)
    pub column: u32,
}

impl Span {
    /// Creates a new span
    pub fn new(start: usize, end: usize, line: u32, column: u32) -> Span {
        Span { start, end, line, column }
    }

    /// Creates a dummy span for synthetic tokens
    pub fn dummy() -> Span {
        Span { start: 0, end: 0, line: 0, column: 0 }
    }
}

/// Token kinds for the Blood lexer
pub enum TokenKind {
    // Keywords
    As,
    Async,
    Await,
    Break,
    Const,
    Continue,
    Crate,
    Deep,
    Dyn,
    Effect,
    Else,
    Enum,
    Extends,
    Extern,
    False,
    Fn,
    For,
    Forall,
    Handler,
    If,
    Impl,
    In,
    Let,
    Linear,
    Loop,
    Match,
    Mod,
    Module,
    Move,
    Mut,
    Op,
    Perform,
    Pub,
    Pure,
    Ref,
    Region,
    Resume,
    Return,
    SelfLower,
    SelfUpper,
    Shallow,
    Static,
    Struct,
    Super,
    Trait,
    True,
    Type,
    Use,
    Where,
    While,
    With,
    Handle,
    Affine,
    Bridge,
    Try,
    Unsafe,
    Default,

    // Reserved keywords
    Abstract,
    Become,
    Box,
    Do,
    Final,
    Macro,
    Override,
    Priv,
    Typeof,
    Unsized,
    Virtual,
    Yield,
    Catch,
    Finally,
    Throw,
    Union,

    // Literals
    IntLit,
    FloatLit,
    StringLit,
    ByteStringLit,
    RawStringLit,
    CharLit,

    // Identifiers
    Ident,
    TypeIdent,
    Lifetime,

    // Operators
    Plus,
    Minus,
    Star,
    Slash,
    Percent,
    EqEq,
    NotEq,
    Lt,
    Gt,
    LtEq,
    GtEq,
    AndAnd,
    OrOr,
    Not,
    And,
    Or,
    Caret,
    Shl,
    Shr,
    Eq,
    PlusEq,
    MinusEq,
    StarEq,
    SlashEq,
    PercentEq,
    AndEq,
    OrEq,
    CaretEq,
    ShlEq,
    ShrEq,

    // Punctuation
    LParen,
    RParen,
    LBrace,
    RBrace,
    LBracket,
    RBracket,
    Comma,
    Semi,
    Colon,
    ColonColon,
    Dot,
    DotDot,
    DotDotEq,
    Arrow,
    FatArrow,
    Pipe,
    At,
    Hash,
    Question,
    Dollar,

    // Special
    AtUnsafe,
    AtHeap,
    AtStack,
    DocComment,
    Eof,
    Error,
}

impl TokenKind {
    /// Returns true if this token kind carries text
    pub fn has_text(self: &Self) -> bool {
        match self {
            TokenKind::IntLit => true,
            TokenKind::FloatLit => true,
            TokenKind::StringLit => true,
            TokenKind::ByteStringLit => true,
            TokenKind::RawStringLit => true,
            TokenKind::CharLit => true,
            TokenKind::Ident => true,
            TokenKind::TypeIdent => true,
            TokenKind::Lifetime => true,
            TokenKind::DocComment => true,
            TokenKind::As => false,
            TokenKind::Async => false,
            TokenKind::Await => false,
            TokenKind::Break => false,
            TokenKind::Const => false,
            TokenKind::Continue => false,
            TokenKind::Crate => false,
            TokenKind::Deep => false,
            TokenKind::Dyn => false,
            TokenKind::Effect => false,
            TokenKind::Else => false,
            TokenKind::Enum => false,
            TokenKind::Extends => false,
            TokenKind::Extern => false,
            TokenKind::False => false,
            TokenKind::Fn => false,
            TokenKind::For => false,
            TokenKind::Forall => false,
            TokenKind::Handler => false,
            TokenKind::If => false,
            TokenKind::Impl => false,
            TokenKind::In => false,
            TokenKind::Let => false,
            TokenKind::Linear => false,
            TokenKind::Loop => false,
            TokenKind::Match => false,
            TokenKind::Mod => false,
            TokenKind::Module => false,
            TokenKind::Move => false,
            TokenKind::Mut => false,
            TokenKind::Op => false,
            TokenKind::Perform => false,
            TokenKind::Pub => false,
            TokenKind::Pure => false,
            TokenKind::Ref => false,
            TokenKind::Region => false,
            TokenKind::Resume => false,
            TokenKind::Return => false,
            TokenKind::SelfLower => false,
            TokenKind::SelfUpper => false,
            TokenKind::Shallow => false,
            TokenKind::Static => false,
            TokenKind::Struct => false,
            TokenKind::Super => false,
            TokenKind::Trait => false,
            TokenKind::True => false,
            TokenKind::Type => false,
            TokenKind::Use => false,
            TokenKind::Where => false,
            TokenKind::While => false,
            TokenKind::With => false,
            TokenKind::Handle => false,
            TokenKind::Affine => false,
            TokenKind::Bridge => false,
            TokenKind::Try => false,
            TokenKind::Unsafe => false,
            TokenKind::Default => false,
            TokenKind::Abstract => false,
            TokenKind::Become => false,
            TokenKind::Box => false,
            TokenKind::Do => false,
            TokenKind::Final => false,
            TokenKind::Macro => false,
            TokenKind::Override => false,
            TokenKind::Priv => false,
            TokenKind::Typeof => false,
            TokenKind::Unsized => false,
            TokenKind::Virtual => false,
            TokenKind::Yield => false,
            TokenKind::Catch => false,
            TokenKind::Finally => false,
            TokenKind::Throw => false,
            TokenKind::Union => false,
            TokenKind::Plus => false,
            TokenKind::Minus => false,
            TokenKind::Star => false,
            TokenKind::Slash => false,
            TokenKind::Percent => false,
            TokenKind::EqEq => false,
            TokenKind::NotEq => false,
            TokenKind::Lt => false,
            TokenKind::Gt => false,
            TokenKind::LtEq => false,
            TokenKind::GtEq => false,
            TokenKind::AndAnd => false,
            TokenKind::OrOr => false,
            TokenKind::Not => false,
            TokenKind::And => false,
            TokenKind::Or => false,
            TokenKind::Caret => false,
            TokenKind::Shl => false,
            TokenKind::Shr => false,
            TokenKind::Eq => false,
            TokenKind::PlusEq => false,
            TokenKind::MinusEq => false,
            TokenKind::StarEq => false,
            TokenKind::SlashEq => false,
            TokenKind::PercentEq => false,
            TokenKind::AndEq => false,
            TokenKind::OrEq => false,
            TokenKind::CaretEq => false,
            TokenKind::ShlEq => false,
            TokenKind::ShrEq => false,
            TokenKind::LParen => false,
            TokenKind::RParen => false,
            TokenKind::LBrace => false,
            TokenKind::RBrace => false,
            TokenKind::LBracket => false,
            TokenKind::RBracket => false,
            TokenKind::Comma => false,
            TokenKind::Semi => false,
            TokenKind::Colon => false,
            TokenKind::ColonColon => false,
            TokenKind::Dot => false,
            TokenKind::DotDot => false,
            TokenKind::DotDotEq => false,
            TokenKind::Arrow => false,
            TokenKind::FatArrow => false,
            TokenKind::Pipe => false,
            TokenKind::At => false,
            TokenKind::Hash => false,
            TokenKind::Question => false,
            TokenKind::Dollar => false,
            TokenKind::AtUnsafe => false,
            TokenKind::AtHeap => false,
            TokenKind::AtStack => false,
            TokenKind::Eof => false,
            TokenKind::Error => false
        }
    }
}

/// A token with its kind and source span
pub struct Token {
    pub kind: TokenKind,
    pub span: Span,
}

impl Token {
    pub fn new(kind: TokenKind, span: Span) -> Token {
        Token { kind, span }
    }

    pub fn dummy(kind: TokenKind) -> Token {
        Token { kind, span: Span::dummy() }
    }
}

/// The lexer for Blood source code
pub struct Lexer<'src> {
    /// Source text
    source: &'src str,
    /// Current position in source (byte offset)
    pos: usize,
    /// Current line (1-based)
    line: u32,
    /// Current column (1-based)
    column: u32,
    /// Start position of current token
    token_start: usize,
    /// Start line of current token
    token_line: u32,
    /// Start column of current token
    token_column: u32,
}

impl<'src> Lexer<'src> {
    /// Create a new lexer for the given source
    pub fn new(source: &'src str) -> Lexer<'src> {
        Lexer {
            source,
            pos: 0,
            line: 1,
            column: 1,
            token_start: 0,
            token_line: 1,
            token_column: 1,
        }
    }

    /// Check if we're at the end of input
    fn at_end(self: &Self) -> bool {
        self.pos >= self.source.len()
    }

    /// Get byte at position (returns 0 if out of bounds)
    fn byte_at(self: &Self, pos: usize) -> u8 {
        if pos >= self.source.len() {
            0
        } else {
            let ptr = @unsafe { self.source as *const u8 };
            let offset_ptr = @unsafe { (ptr as usize + pos) as *const u8 };
            @unsafe { *offset_ptr }
        }
    }

    /// Get current byte (or 0 if at end)
    fn current(self: &Self) -> u8 {
        self.byte_at(self.pos)
    }

    /// Peek at the next byte (or 0 if at end)
    fn peek(self: &Self) -> u8 {
        self.byte_at(self.pos + 1)
    }

    /// Peek at byte at offset from current (or 0 if out of bounds)
    fn peek_at(self: &Self, offset: usize) -> u8 {
        self.byte_at(self.pos + offset)
    }

    /// Advance by one byte
    fn advance(self: &mut Self) {
        if !self.at_end() {
            let c = self.current();
            self.pos = self.pos + 1;
            if c == 10 {
                // newline
                self.line = self.line + 1;
                self.column = 1;
            } else {
                self.column = self.column + 1;
            }
        }
    }

    /// Mark the start of a token
    fn start_token(self: &mut Self) {
        self.token_start = self.pos;
        self.token_line = self.line;
        self.token_column = self.column;
    }

    /// Create a token with the current span
    fn make_token(self: &Self, kind: TokenKind) -> Token {
        Token {
            kind,
            span: Span {
                start: self.token_start,
                end: self.pos,
                line: self.token_line,
                column: self.token_column,
            },
        }
    }

    /// Skip whitespace and comments
    fn skip_whitespace(self: &mut Self) {
        loop {
            let c = self.current();
            if c == 32 || c == 9 || c == 13 || c == 10 {
                // space, tab, CR, LF
                self.advance();
            } else if c == 47 && self.peek() == 47 {
                // // line comment
                if self.peek_at(2) == 47 && self.peek_at(3) != 47 {
                    // /// doc comment - don't skip
                    break;
                }
                // Regular line comment - skip to end of line
                while self.current() != 0 && self.current() != 10 {
                    self.advance();
                }
            } else if c == 47 && self.peek() == 42 {
                // /* block comment */
                self.advance(); // skip /
                self.advance(); // skip *
                let mut depth: i32 = 1;
                while depth > 0 && self.current() != 0 {
                    if self.current() == 47 && self.peek() == 42 {
                        self.advance();
                        self.advance();
                        depth = depth + 1;
                    } else if self.current() == 42 && self.peek() == 47 {
                        self.advance();
                        self.advance();
                        depth = depth - 1;
                    } else {
                        self.advance();
                    }
                }
            } else {
                break;
            }
        }
    }

    /// Check if byte is a digit
    fn is_digit(c: u8) -> bool {
        c >= 48 && c <= 57
    }

    /// Check if byte is alphabetic
    fn is_alpha(c: u8) -> bool {
        (c >= 65 && c <= 90) || (c >= 97 && c <= 122)
    }

    /// Check if byte is alphanumeric or underscore
    fn is_alnum_underscore(c: u8) -> bool {
        Lexer::is_alpha(c) || Lexer::is_digit(c) || c == 95
    }

    /// Check if byte is uppercase
    fn is_upper(c: u8) -> bool {
        c >= 65 && c <= 90
    }

    /// Get the next token
    pub fn next_token(self: &mut Self) -> Token {
        self.skip_whitespace();
        self.start_token();

        if self.at_end() {
            return self.make_token(TokenKind::Eof);
        }

        let c = self.current();

        // Single-character tokens
        if c == 40 { self.advance(); return self.make_token(TokenKind::LParen); }
        if c == 41 { self.advance(); return self.make_token(TokenKind::RParen); }
        if c == 123 { self.advance(); return self.make_token(TokenKind::LBrace); }
        if c == 125 { self.advance(); return self.make_token(TokenKind::RBrace); }
        if c == 91 { self.advance(); return self.make_token(TokenKind::LBracket); }
        if c == 93 { self.advance(); return self.make_token(TokenKind::RBracket); }
        if c == 44 { self.advance(); return self.make_token(TokenKind::Comma); }
        if c == 59 { self.advance(); return self.make_token(TokenKind::Semi); }
        if c == 63 { self.advance(); return self.make_token(TokenKind::Question); }
        if c == 35 { self.advance(); return self.make_token(TokenKind::Hash); }
        if c == 36 { self.advance(); return self.make_token(TokenKind::Dollar); }

        // Multi-character operators
        if c == 58 {
            // : or ::
            self.advance();
            if self.current() == 58 {
                self.advance();
                return self.make_token(TokenKind::ColonColon);
            }
            return self.make_token(TokenKind::Colon);
        }

        if c == 46 {
            // . or .. or ..=
            self.advance();
            if self.current() == 46 {
                self.advance();
                if self.current() == 61 {
                    self.advance();
                    return self.make_token(TokenKind::DotDotEq);
                }
                return self.make_token(TokenKind::DotDot);
            }
            return self.make_token(TokenKind::Dot);
        }

        if c == 61 {
            // = or == or =>
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::EqEq);
            }
            if self.current() == 62 {
                self.advance();
                return self.make_token(TokenKind::FatArrow);
            }
            return self.make_token(TokenKind::Eq);
        }

        if c == 33 {
            // ! or !=
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::NotEq);
            }
            return self.make_token(TokenKind::Not);
        }

        if c == 60 {
            // < or <= or << or <<=
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::LtEq);
            }
            if self.current() == 60 {
                self.advance();
                if self.current() == 61 {
                    self.advance();
                    return self.make_token(TokenKind::ShlEq);
                }
                return self.make_token(TokenKind::Shl);
            }
            return self.make_token(TokenKind::Lt);
        }

        if c == 62 {
            // > or >= or >> or >>=
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::GtEq);
            }
            if self.current() == 62 {
                self.advance();
                if self.current() == 61 {
                    self.advance();
                    return self.make_token(TokenKind::ShrEq);
                }
                return self.make_token(TokenKind::Shr);
            }
            return self.make_token(TokenKind::Gt);
        }

        if c == 43 {
            // + or +=
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::PlusEq);
            }
            return self.make_token(TokenKind::Plus);
        }

        if c == 45 {
            // - or -= or ->
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::MinusEq);
            }
            if self.current() == 62 {
                self.advance();
                return self.make_token(TokenKind::Arrow);
            }
            return self.make_token(TokenKind::Minus);
        }

        if c == 42 {
            // * or *=
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::StarEq);
            }
            return self.make_token(TokenKind::Star);
        }

        if c == 47 {
            // / or /= (doc comment handled in skip_whitespace)
            // Check for doc comment first
            if self.peek() == 47 && self.peek_at(2) == 47 && self.peek_at(3) != 47 {
                return self.lex_doc_comment();
            }
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::SlashEq);
            }
            return self.make_token(TokenKind::Slash);
        }

        if c == 37 {
            // % or %=
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::PercentEq);
            }
            return self.make_token(TokenKind::Percent);
        }

        if c == 38 {
            // & or && or &=
            self.advance();
            if self.current() == 38 {
                self.advance();
                return self.make_token(TokenKind::AndAnd);
            }
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::AndEq);
            }
            return self.make_token(TokenKind::And);
        }

        if c == 124 {
            // | or || or |= or |>
            self.advance();
            if self.current() == 124 {
                self.advance();
                return self.make_token(TokenKind::OrOr);
            }
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::OrEq);
            }
            if self.current() == 62 {
                self.advance();
                return self.make_token(TokenKind::Pipe);
            }
            return self.make_token(TokenKind::Or);
        }

        if c == 94 {
            // ^ or ^=
            self.advance();
            if self.current() == 61 {
                self.advance();
                return self.make_token(TokenKind::CaretEq);
            }
            return self.make_token(TokenKind::Caret);
        }

        if c == 64 {
            // @ or @unsafe or @heap or @stack
            return self.lex_at_token();
        }

        // Numbers
        if Lexer::is_digit(c) {
            return self.lex_number();
        }

        // Identifiers and keywords
        if Lexer::is_alpha(c) || c == 95 {
            // Check for byte string literal b"..."
            if c == 98 && self.peek() == 34 {
                return self.lex_byte_string();
            }
            // Check for raw string literal r"..." or r#"..."#
            if c == 114 && (self.peek() == 34 || self.peek() == 35) {
                return self.lex_raw_string();
            }
            return self.lex_identifier();
        }

        // String literal
        if c == 34 {
            return self.lex_string();
        }

        // Character literal or lifetime
        if c == 39 {
            let next = self.peek();
            if Lexer::is_alpha(next) || next == 95 {
                return self.lex_lifetime();
            }
            return self.lex_char();
        }

        // Unknown character - return error token
        self.advance();
        self.make_token(TokenKind::Error)
    }

    /// Lex a doc comment (///)
    fn lex_doc_comment(self: &mut Self) -> Token {
        // Skip ///
        self.advance();
        self.advance();
        self.advance();
        // Read to end of line
        while self.current() != 0 && self.current() != 10 {
            self.advance();
        }
        self.make_token(TokenKind::DocComment)
    }

    /// Lex @ tokens (@unsafe, @heap, @stack, or plain @)
    fn lex_at_token(self: &mut Self) -> Token {
        self.advance(); // skip @
        // Check for @unsafe (6 chars)
        if self.match_keyword_bytes(0, 6, 117, 110, 115, 97, 102, 101) {
            // u n s a f e
            self.pos = self.pos + 6;
            return self.make_token(TokenKind::AtUnsafe);
        }
        // Check for @heap (4 chars)
        if self.match_keyword_bytes(0, 4, 104, 101, 97, 112, 0, 0) {
            // h e a p
            self.pos = self.pos + 4;
            return self.make_token(TokenKind::AtHeap);
        }
        // Check for @stack (5 chars)
        if self.match_keyword_bytes(0, 5, 115, 116, 97, 99, 107, 0) {
            // s t a c k
            self.pos = self.pos + 5;
            return self.make_token(TokenKind::AtStack);
        }
        self.make_token(TokenKind::At)
    }

    /// Match bytes at current position
    fn match_keyword_bytes(self: &Self, offset: usize, len: usize, b0: u8, b1: u8, b2: u8, b3: u8, b4: u8, b5: u8) -> bool {
        if len >= 1 && self.byte_at(self.pos + offset) != b0 { return false; }
        if len >= 2 && self.byte_at(self.pos + offset + 1) != b1 { return false; }
        if len >= 3 && self.byte_at(self.pos + offset + 2) != b2 { return false; }
        if len >= 4 && self.byte_at(self.pos + offset + 3) != b3 { return false; }
        if len >= 5 && self.byte_at(self.pos + offset + 4) != b4 { return false; }
        if len >= 6 && self.byte_at(self.pos + offset + 5) != b5 { return false; }
        true
    }

    /// Lex a number
    fn lex_number(self: &mut Self) -> Token {
        // Check for hex, octal, binary
        if self.current() == 48 {
            let next = self.peek();
            if next == 120 || next == 88 {
                // 0x or 0X - hex
                self.advance();
                self.advance();
                while Lexer::is_hex_digit(self.current()) || self.current() == 95 {
                    self.advance();
                }
                self.lex_int_suffix();
                return self.make_token(TokenKind::IntLit);
            }
            if next == 111 || next == 79 {
                // 0o or 0O - octal
                self.advance();
                self.advance();
                while (self.current() >= 48 && self.current() <= 55) || self.current() == 95 {
                    self.advance();
                }
                self.lex_int_suffix();
                return self.make_token(TokenKind::IntLit);
            }
            if next == 98 || next == 66 {
                // 0b or 0B - binary
                self.advance();
                self.advance();
                while self.current() == 48 || self.current() == 49 || self.current() == 95 {
                    self.advance();
                }
                self.lex_int_suffix();
                return self.make_token(TokenKind::IntLit);
            }
        }

        // Decimal number
        while Lexer::is_digit(self.current()) || self.current() == 95 {
            self.advance();
        }

        // Check for float
        if self.current() == 46 && Lexer::is_digit(self.peek()) {
            self.advance(); // skip .
            while Lexer::is_digit(self.current()) || self.current() == 95 {
                self.advance();
            }
            // Exponent
            if self.current() == 101 || self.current() == 69 {
                self.advance();
                if self.current() == 43 || self.current() == 45 {
                    self.advance();
                }
                while Lexer::is_digit(self.current()) || self.current() == 95 {
                    self.advance();
                }
            }
            // Float suffix f32/f64
            if self.current() == 102 {
                self.advance();
                if self.current() == 51 && self.peek() == 50 {
                    self.advance();
                    self.advance();
                } else if self.current() == 54 && self.peek() == 52 {
                    self.advance();
                    self.advance();
                }
            }
            return self.make_token(TokenKind::FloatLit);
        }

        self.lex_int_suffix();
        self.make_token(TokenKind::IntLit)
    }

    /// Check if byte is hex digit
    fn is_hex_digit(c: u8) -> bool {
        (c >= 48 && c <= 57) || (c >= 65 && c <= 70) || (c >= 97 && c <= 102)
    }

    /// Lex integer type suffix
    fn lex_int_suffix(self: &mut Self) {
        let c = self.current();
        if c == 105 || c == 117 {
            // i or u
            let start = self.pos;
            self.advance();
            // Check for isize/usize
            if self.current() == 115 {
                // s for size
                if self.peek() == 105 && self.byte_at(self.pos + 2) == 122 && self.byte_at(self.pos + 3) == 101 {
                    // size
                    self.pos = self.pos + 4;
                    return;
                }
            }
            // Check for numeric suffix
            if Lexer::is_digit(self.current()) {
                while Lexer::is_digit(self.current()) {
                    self.advance();
                }
            } else {
                // Invalid suffix, restore position
                self.pos = start;
            }
        }
    }

    /// Lex a string literal
    fn lex_string(self: &mut Self) -> Token {
        self.advance(); // skip opening "
        while self.current() != 0 && self.current() != 34 {
            if self.current() == 92 {
                // backslash escape
                self.advance();
                if self.current() != 0 {
                    self.advance();
                }
            } else {
                self.advance();
            }
        }
        if self.current() == 34 {
            self.advance(); // skip closing "
        }
        self.make_token(TokenKind::StringLit)
    }

    /// Lex a character literal
    fn lex_char(self: &mut Self) -> Token {
        self.advance(); // skip opening '
        if self.current() == 92 {
            // backslash escape
            self.advance();
            if self.current() != 0 {
                self.advance();
            }
        } else if self.current() != 39 && self.current() != 0 {
            self.advance();
        }
        if self.current() == 39 {
            self.advance(); // skip closing '
        }
        self.make_token(TokenKind::CharLit)
    }

    /// Lex a byte string literal
    fn lex_byte_string(self: &mut Self) -> Token {
        self.advance(); // skip b
        self.advance(); // skip opening "
        while self.current() != 0 && self.current() != 34 {
            if self.current() == 92 {
                self.advance();
                if self.current() != 0 {
                    self.advance();
                }
            } else {
                self.advance();
            }
        }
        if self.current() == 34 {
            self.advance();
        }
        self.make_token(TokenKind::ByteStringLit)
    }

    /// Lex a raw string literal
    fn lex_raw_string(self: &mut Self) -> Token {
        self.advance(); // skip r
        let mut hash_count: i32 = 0;
        while self.current() == 35 {
            hash_count = hash_count + 1;
            self.advance();
        }
        if self.current() != 34 {
            return self.make_token(TokenKind::Error);
        }
        self.advance(); // skip opening "

        loop {
            if self.current() == 0 {
                break;
            }
            if self.current() == 34 {
                self.advance();
                let mut matching: i32 = 0;
                while matching < hash_count && self.current() == 35 {
                    matching = matching + 1;
                    self.advance();
                }
                if matching == hash_count {
                    break;
                }
            } else {
                self.advance();
            }
        }
        self.make_token(TokenKind::RawStringLit)
    }

    /// Lex a lifetime
    fn lex_lifetime(self: &mut Self) -> Token {
        self.advance(); // skip '
        while Lexer::is_alnum_underscore(self.current()) {
            self.advance();
        }
        self.make_token(TokenKind::Lifetime)
    }

    /// Lex an identifier or keyword
    fn lex_identifier(self: &mut Self) -> Token {
        let start = self.pos;
        while Lexer::is_alnum_underscore(self.current()) {
            self.advance();
        }
        let len = self.pos - start;

        // Match keywords - we need to compare bytes
        let kind = self.match_keyword(start, len);
        self.make_token(kind)
    }

    /// Match identifier against keywords
    fn match_keyword(self: &Self, start: usize, len: usize) -> TokenKind {
        let first = self.byte_at(start);

        // Check by first character
        if first == 97 {
            // 'a'
            if len == 2 && self.byte_at(start + 1) == 115 { return TokenKind::As; }
            if len == 5 && self.match_bytes(start, 97, 115, 121, 110, 99) { return TokenKind::Async; }
            if len == 5 && self.match_bytes(start, 97, 119, 97, 105, 116) { return TokenKind::Await; }
            if len == 6 && self.match_bytes6(start, 97, 102, 102, 105, 110, 101) { return TokenKind::Affine; }
            if len == 8 && self.match_bytes8(start, 97, 98, 115, 116, 114, 97, 99, 116) { return TokenKind::Abstract; }
        }
        if first == 98 {
            // 'b'
            if len == 5 && self.match_bytes(start, 98, 114, 101, 97, 107) { return TokenKind::Break; }
            if len == 6 && self.match_bytes6(start, 98, 114, 105, 100, 103, 101) { return TokenKind::Bridge; }
            if len == 6 && self.match_bytes6(start, 98, 101, 99, 111, 109, 101) { return TokenKind::Become; }
            if len == 3 && self.match_bytes3(start, 98, 111, 120) { return TokenKind::Box; }
        }
        if first == 99 {
            // 'c'
            if len == 5 && self.match_bytes(start, 99, 111, 110, 115, 116) { return TokenKind::Const; }
            if len == 8 && self.match_bytes8(start, 99, 111, 110, 116, 105, 110, 117, 101) { return TokenKind::Continue; }
            if len == 5 && self.match_bytes(start, 99, 114, 97, 116, 101) { return TokenKind::Crate; }
            if len == 5 && self.match_bytes(start, 99, 97, 116, 99, 104) { return TokenKind::Catch; }
        }
        if first == 100 {
            // 'd'
            if len == 4 && self.match_bytes4(start, 100, 101, 101, 112) { return TokenKind::Deep; }
            if len == 3 && self.match_bytes3(start, 100, 121, 110) { return TokenKind::Dyn; }
            if len == 7 && self.match_bytes7(start, 100, 101, 102, 97, 117, 108, 116) { return TokenKind::Default; }
            if len == 2 && self.byte_at(start + 1) == 111 { return TokenKind::Do; }
        }
        if first == 101 {
            // 'e'
            if len == 6 && self.match_bytes6(start, 101, 102, 102, 101, 99, 116) { return TokenKind::Effect; }
            if len == 4 && self.match_bytes4(start, 101, 108, 115, 101) { return TokenKind::Else; }
            if len == 4 && self.match_bytes4(start, 101, 110, 117, 109) { return TokenKind::Enum; }
            if len == 7 && self.match_bytes7(start, 101, 120, 116, 101, 110, 100, 115) { return TokenKind::Extends; }
            if len == 6 && self.match_bytes6(start, 101, 120, 116, 101, 114, 110) { return TokenKind::Extern; }
        }
        if first == 102 {
            // 'f'
            if len == 5 && self.match_bytes(start, 102, 97, 108, 115, 101) { return TokenKind::False; }
            if len == 2 && self.byte_at(start + 1) == 110 { return TokenKind::Fn; }
            if len == 3 && self.match_bytes3(start, 102, 111, 114) { return TokenKind::For; }
            if len == 6 && self.match_bytes6(start, 102, 111, 114, 97, 108, 108) { return TokenKind::Forall; }
            if len == 5 && self.match_bytes(start, 102, 105, 110, 97, 108) { return TokenKind::Final; }
            if len == 7 && self.match_bytes7(start, 102, 105, 110, 97, 108, 108, 121) { return TokenKind::Finally; }
        }
        if first == 104 {
            // 'h'
            if len == 7 && self.match_bytes7(start, 104, 97, 110, 100, 108, 101, 114) { return TokenKind::Handler; }
            if len == 6 && self.match_bytes6(start, 104, 97, 110, 100, 108, 101) { return TokenKind::Handle; }
        }
        if first == 105 {
            // 'i'
            if len == 2 && self.byte_at(start + 1) == 102 { return TokenKind::If; }
            if len == 4 && self.match_bytes4(start, 105, 109, 112, 108) { return TokenKind::Impl; }
            if len == 2 && self.byte_at(start + 1) == 110 { return TokenKind::In; }
        }
        if first == 108 {
            // 'l'
            if len == 3 && self.match_bytes3(start, 108, 101, 116) { return TokenKind::Let; }
            if len == 6 && self.match_bytes6(start, 108, 105, 110, 101, 97, 114) { return TokenKind::Linear; }
            if len == 4 && self.match_bytes4(start, 108, 111, 111, 112) { return TokenKind::Loop; }
        }
        if first == 109 {
            // 'm'
            if len == 5 && self.match_bytes(start, 109, 97, 116, 99, 104) { return TokenKind::Match; }
            if len == 3 && self.match_bytes3(start, 109, 111, 100) { return TokenKind::Mod; }
            if len == 6 && self.match_bytes6(start, 109, 111, 100, 117, 108, 101) { return TokenKind::Module; }
            if len == 4 && self.match_bytes4(start, 109, 111, 118, 101) { return TokenKind::Move; }
            if len == 3 && self.match_bytes3(start, 109, 117, 116) { return TokenKind::Mut; }
            if len == 5 && self.match_bytes(start, 109, 97, 99, 114, 111) { return TokenKind::Macro; }
        }
        if first == 111 {
            // 'o'
            if len == 2 && self.byte_at(start + 1) == 112 { return TokenKind::Op; }
            if len == 8 && self.match_bytes8(start, 111, 118, 101, 114, 114, 105, 100, 101) { return TokenKind::Override; }
        }
        if first == 112 {
            // 'p'
            if len == 7 && self.match_bytes7(start, 112, 101, 114, 102, 111, 114, 109) { return TokenKind::Perform; }
            if len == 3 && self.match_bytes3(start, 112, 117, 98) { return TokenKind::Pub; }
            if len == 4 && self.match_bytes4(start, 112, 117, 114, 101) { return TokenKind::Pure; }
            if len == 4 && self.match_bytes4(start, 112, 114, 105, 118) { return TokenKind::Priv; }
        }
        if first == 114 {
            // 'r'
            if len == 3 && self.match_bytes3(start, 114, 101, 102) { return TokenKind::Ref; }
            if len == 6 && self.match_bytes6(start, 114, 101, 103, 105, 111, 110) { return TokenKind::Region; }
            if len == 6 && self.match_bytes6(start, 114, 101, 115, 117, 109, 101) { return TokenKind::Resume; }
            if len == 6 && self.match_bytes6(start, 114, 101, 116, 117, 114, 110) { return TokenKind::Return; }
        }
        if first == 115 {
            // 's'
            if len == 4 && self.match_bytes4(start, 115, 101, 108, 102) { return TokenKind::SelfLower; }
            if len == 7 && self.match_bytes7(start, 115, 104, 97, 108, 108, 111, 119) { return TokenKind::Shallow; }
            if len == 6 && self.match_bytes6(start, 115, 116, 97, 116, 105, 99) { return TokenKind::Static; }
            if len == 6 && self.match_bytes6(start, 115, 116, 114, 117, 99, 116) { return TokenKind::Struct; }
            if len == 5 && self.match_bytes(start, 115, 117, 112, 101, 114) { return TokenKind::Super; }
        }
        if first == 83 {
            // 'S'
            if len == 4 && self.match_bytes4(start, 83, 101, 108, 102) { return TokenKind::SelfUpper; }
        }
        if first == 116 {
            // 't'
            if len == 5 && self.match_bytes(start, 116, 114, 97, 105, 116) { return TokenKind::Trait; }
            if len == 4 && self.match_bytes4(start, 116, 114, 117, 101) { return TokenKind::True; }
            if len == 4 && self.match_bytes4(start, 116, 121, 112, 101) { return TokenKind::Type; }
            if len == 3 && self.match_bytes3(start, 116, 114, 121) { return TokenKind::Try; }
            if len == 6 && self.match_bytes6(start, 116, 121, 112, 101, 111, 102) { return TokenKind::Typeof; }
            if len == 5 && self.match_bytes(start, 116, 104, 114, 111, 119) { return TokenKind::Throw; }
        }
        if first == 117 {
            // 'u'
            if len == 3 && self.match_bytes3(start, 117, 115, 101) { return TokenKind::Use; }
            if len == 6 && self.match_bytes6(start, 117, 110, 115, 97, 102, 101) { return TokenKind::Unsafe; }
            if len == 7 && self.match_bytes7(start, 117, 110, 115, 105, 122, 101, 100) { return TokenKind::Unsized; }
            if len == 5 && self.match_bytes(start, 117, 110, 105, 111, 110) { return TokenKind::Union; }
        }
        if first == 118 {
            // 'v'
            if len == 7 && self.match_bytes7(start, 118, 105, 114, 116, 117, 97, 108) { return TokenKind::Virtual; }
        }
        if first == 119 {
            // 'w'
            if len == 5 && self.match_bytes(start, 119, 104, 101, 114, 101) { return TokenKind::Where; }
            if len == 5 && self.match_bytes(start, 119, 104, 105, 108, 101) { return TokenKind::While; }
            if len == 4 && self.match_bytes4(start, 119, 105, 116, 104) { return TokenKind::With; }
        }
        if first == 121 {
            // 'y'
            if len == 5 && self.match_bytes(start, 121, 105, 101, 108, 100) { return TokenKind::Yield; }
        }

        // Not a keyword - determine if TypeIdent or Ident
        if Lexer::is_upper(first) {
            TokenKind::TypeIdent
        } else {
            TokenKind::Ident
        }
    }

    // Helper functions to match byte sequences
    fn match_bytes(self: &Self, start: usize, b0: u8, b1: u8, b2: u8, b3: u8, b4: u8) -> bool {
        self.byte_at(start) == b0 && self.byte_at(start + 1) == b1 && self.byte_at(start + 2) == b2 &&
        self.byte_at(start + 3) == b3 && self.byte_at(start + 4) == b4
    }

    fn match_bytes3(self: &Self, start: usize, b0: u8, b1: u8, b2: u8) -> bool {
        self.byte_at(start) == b0 && self.byte_at(start + 1) == b1 && self.byte_at(start + 2) == b2
    }

    fn match_bytes4(self: &Self, start: usize, b0: u8, b1: u8, b2: u8, b3: u8) -> bool {
        self.byte_at(start) == b0 && self.byte_at(start + 1) == b1 && self.byte_at(start + 2) == b2 &&
        self.byte_at(start + 3) == b3
    }

    fn match_bytes6(self: &Self, start: usize, b0: u8, b1: u8, b2: u8, b3: u8, b4: u8, b5: u8) -> bool {
        self.byte_at(start) == b0 && self.byte_at(start + 1) == b1 && self.byte_at(start + 2) == b2 &&
        self.byte_at(start + 3) == b3 && self.byte_at(start + 4) == b4 && self.byte_at(start + 5) == b5
    }

    fn match_bytes7(self: &Self, start: usize, b0: u8, b1: u8, b2: u8, b3: u8, b4: u8, b5: u8, b6: u8) -> bool {
        self.byte_at(start) == b0 && self.byte_at(start + 1) == b1 && self.byte_at(start + 2) == b2 &&
        self.byte_at(start + 3) == b3 && self.byte_at(start + 4) == b4 && self.byte_at(start + 5) == b5 &&
        self.byte_at(start + 6) == b6
    }

    fn match_bytes8(self: &Self, start: usize, b0: u8, b1: u8, b2: u8, b3: u8, b4: u8, b5: u8, b6: u8, b7: u8) -> bool {
        self.byte_at(start) == b0 && self.byte_at(start + 1) == b1 && self.byte_at(start + 2) == b2 &&
        self.byte_at(start + 3) == b3 && self.byte_at(start + 4) == b4 && self.byte_at(start + 5) == b5 &&
        self.byte_at(start + 6) == b6 && self.byte_at(start + 7) == b7
    }
}
