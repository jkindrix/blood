// Blood Self-Hosted Compiler - Codegen Statements
//
// This module handles generating LLVM IR for MIR statements.

mod common;
mod hir_def;
mod hir_ty;
mod mir_def;
mod mir_types;
mod mir_stmt;
mod mir_term;
mod mir_body;
mod codegen_types;
mod codegen_ctx;
mod codegen_expr;
mod codegen_size;
mod mir_escape;
mod dump_mir;
mod type_intern;

// ============================================================
// Statement Codegen
// ============================================================

/// Generates LLVM IR for a statement.
pub fn emit_statement(
    ctx: &mut codegen_ctx::CodegenCtx,
    stmt: &mir_stmt::Statement,
) {
    if ctx.trace_codegen {
        let trace = dump_mir::format_statement(stmt);
        ctx.write("    ; MIR: ");
        ctx.write_string(&trace);
        ctx.newline();
    }
    match &stmt.kind {
        &mir_stmt::StatementKind::Assign { ref place, ref rvalue } => {
            let dest = codegen_expr::emit_place_data_ptr(ctx, place);
            codegen_expr::emit_rvalue(ctx, dest.as_str(), rvalue);
        }
        &mir_stmt::StatementKind::StorageLive(ref local) => {
            // In LLVM IR, storage is typically handled by alloca placement
            // For now, emit as a comment/no-op
            let name = ctx.local_alloca_name(*local);
            ctx.write("    ; storage live ");
            ctx.write_string(&name);
            ctx.newline();
        }
        &mir_stmt::StatementKind::StorageDead(ref local) => {
            let name = ctx.local_alloca_name(*local);
            if ctx.is_region_allocated(*local) {
                // Region-allocated local: free the heap allocation and unregister
                // from the generation tracking system.
                ctx.write("    ; storage dead (region free) ");
                ctx.write_string(&name);
                ctx.newline();
                let loaded_ptr = ctx.fresh_temp_cg();
                ctx.emit_load_cg(&loaded_ptr, "ptr", name.as_str());
                let addr_val = ctx.fresh_temp_cg();
                ctx.emit_cast_cg2(&addr_val, "ptrtoint", "ptr", &loaded_ptr, "i64");
                ctx.begin_call(Option::None, "void", "@blood_unregister_allocation");
                ctx.call_arg_cg(true, "i64", &addr_val);
                ctx.end_call();
            } else if ctx.is_persistent_allocated(*local) {
                // Persistent-allocated local: decrement reference count
                ctx.write("    ; storage dead (persistent) ");
                ctx.write_string(&name);
                ctx.newline();
                let slot_val = ctx.fresh_temp_cg();
                ctx.emit_load_cg(&slot_val, "i64", name.as_str());
                // Only decrement if slot_id != 0 (0 means uninitialized)
                let cmp_val = ctx.fresh_temp_cg();
                ctx.emit_icmp_cg2(&cmp_val, "ne", "i64", &slot_val, "0");
                let then_label = ctx.fresh_label_cg();
                let end_label = ctx.fresh_label_cg();
                ctx.emit_cond_br_cg(&cmp_val, &then_label, &end_label);
                ctx.emit_label_cg(&then_label);
                ctx.begin_call(Option::None, "void", "@blood_persistent_decrement");
                ctx.call_arg_cg(true, "i64", &slot_val);
                ctx.end_call();
                ctx.emit_br_cg(&end_label);
                ctx.emit_label_cg(&end_label);
            } else {
                // Stack-allocated local: no cleanup needed
                ctx.write("    ; storage dead ");
                ctx.write_string(&name);
                ctx.newline();
            }
        }
        &mir_stmt::StatementKind::Drop(ref place) => {
            // Check if this is a ref type pointing to a region-allocated value
            let mut is_ref_region = false;
            let mut drop_size: u64 = 0;
            match ctx.get_local_hir_type(place.local) {
                Option::Some(ty_id) => {
                    match type_intern::get_ref_inner(ty_id) {
                        Option::Some(inner_id) => {
                            if ctx.is_region_allocated(place.local) {
                                is_ref_region = true;
                                drop_size = codegen_size::type_size_with_ctx_id(ctx, inner_id);
                            }
                        }
                        Option::None => {}
                    }
                }
                Option::None => {}
            }
            if is_ref_region {
                // Region-allocated reference: free the pointed-to memory
                let ptr = codegen_expr::emit_place_addr(ctx, place);
                ctx.write("    ; drop (region free)\n");
                let addr_val = ctx.fresh_temp_cg();
                ctx.emit_load_cg2(&addr_val, "ptr", &ptr);
                let int_val = ctx.fresh_temp_cg();
                ctx.emit_cast_cg2(&int_val, "ptrtoint", "ptr", &addr_val, "i64");
                let size_str = codegen_types::format_u64(drop_size);
                ctx.begin_call(Option::None, "void", "@blood_free");
                ctx.call_arg_cg(true, "i64", &int_val);
                ctx.call_arg_str(false, "i64", size_str.as_str());
                ctx.end_call();
            } else {
                let _ptr = codegen_expr::emit_place_addr(ctx, place);
                ctx.write("    ; drop (no-op)\n");
            }
        }
        &mir_stmt::StatementKind::Deinit(ref place) => {
            // Deinit - mark as uninitialized (no-op in simple codegen)
            let _ptr = codegen_expr::emit_place_addr(ctx, place);
            ctx.write("    ; deinit\n");
        }
        &mir_stmt::StatementKind::SetDiscriminant { ref place, variant_idx } => {
            // Set the discriminant field of an enum
            let ptr = codegen_expr::emit_place_data_ptr(ctx, place);
            let discr_val = codegen_types::format_u64(variant_idx as u64);

            // Try to look up enum layout for correct discriminant type
            let mut discr_ty = common::make_string("i64");
            let mut enum_llvm_ty = common::make_string("{ i64, i64 }");
            let mut found_enum = false;

            match ctx.get_local_hir_type(place.local) {
                Option::Some(ty_id) => {
                    match type_intern::get_adt_def_id(ty_id) {
                        Option::Some(def_id) => {
                            match ctx.lookup_enum(def_id.index) {
                                Option::Some(layout) => {
                                    discr_ty = clone_string(&layout.discriminant_type);
                                    enum_llvm_ty = clone_string(&layout.llvm_type);
                                    found_enum = true;
                                }
                                Option::None => {}
                            }
                        }
                        Option::None => {}
                    }
                }
                Option::None => {}
            }

            if found_enum {
                // GEP to discriminant field (index 0) of the enum type
                let discr_ptr = ctx.fresh_temp_cg();
                ctx.begin_gep_str(&discr_ptr, enum_llvm_ty.as_str(), ptr.as_str());
                ctx.gep_ptr_offset(0);
                ctx.gep_field(0);
                ctx.end_gep();
                ctx.emit_store_str_cg(discr_ty.as_str(), discr_val.as_str(), &discr_ptr);
            } else {
                // Fallback for builtin generic enums (Option<T>, Result<T,E>)
                // not in the ADT registry: store i8 discriminant at byte 0.
                // All Blood enums have ≤256 variants → i8 discriminant.
                ctx.emit_store("i8", discr_val.as_str(), ptr.as_str());
            }
        }
        &mir_stmt::StatementKind::CopyNonOverlapping { ref src, ref dst, ref count } => {
            // Emit memcpy intrinsic
            let src_val = codegen_expr::emit_operand(ctx, src);
            let dst_val = codegen_expr::emit_operand(ctx, dst);
            let count_val = codegen_expr::emit_operand(ctx, count);
            emit_memcpy(ctx, &dst_val, &src_val, &count_val);
        }
        &mir_stmt::StatementKind::Nop => {
            // No operation - do nothing
        }
        &mir_stmt::StatementKind::PushHandler { handler_id, ref state_place, ref state_kind } => {
            // Effect handler push via evidence API.
            // Look up the effect_id for this handler.
            let effect_id_val = match ctx.lookup_handler_effect(handler_id.index) {
                Option::Some(eid) => codegen_types::format_u64(eid as u64),
                Option::None => codegen_types::format_u64(handler_id.index as u64),
            };

            // Get state pointer
            let state_void_ptr = codegen_expr::emit_place_addr(ctx, state_place);

            // Get or create evidence vector (using alloca to avoid phi predecessor issue)
            let ev_alloca = ctx.fresh_temp_cg();
            ctx.emit_alloca_cg(&ev_alloca, "ptr");

            let ev_cur = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&ev_cur);
            ctx.write(" = call ptr @blood_evidence_current()\n");

            ctx.emit_store_cg2("ptr", &ev_cur, &ev_alloca);

            let ev_is_null = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&ev_is_null);
            ctx.write(" = icmp eq ptr ");
            ctx.write_cgname(&ev_cur);
            ctx.write(", null\n");

            let create_label = ctx.fresh_label_cg();
            let merge_label = ctx.fresh_label_cg();

            ctx.emit_cond_br_cg(&ev_is_null, &create_label, &merge_label);

            // Create evidence block
            ctx.emit_label_cg(&create_label);
            let new_ev = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&new_ev);
            ctx.write(" = call ptr @blood_evidence_create()\n");
            ctx.write_indent();
            ctx.write("call void @blood_evidence_set_current(ptr ");
            ctx.write_cgname(&new_ev);
            ctx.write(")\n");
            ctx.emit_store_cg2("ptr", &new_ev, &ev_alloca);
            ctx.emit_br_cg(&merge_label);

            // Merge block - load evidence from alloca
            ctx.emit_label_cg(&merge_label);
            let evidence = ctx.fresh_temp_cg();
            ctx.emit_load_cg2(&evidence, "ptr", &ev_alloca);

            // Push handler with state.
            // For stateful handlers, create a state shadow alloca that points
            // directly to the state value (skipping the handler struct discriminant).
            // Handler op wrappers receive this pointer and can read/write state through it.
            let push_state_ptr = if !state_kind.is_stateless() {
                // Create a state shadow: alloca i64 on the stack.
                // Load initial state from handler struct (heap_ptr + 1, after discriminant).
                let shadow = ctx.fresh_temp_cg();
                ctx.emit_alloca_cg(&shadow, "i64");

                let heap_ptr_s = ctx.fresh_temp_cg();
                ctx.emit_load_cg2(&heap_ptr_s, "ptr", &state_void_ptr);

                let field_ptr = ctx.fresh_temp_cg();
                ctx.write_indent();
                ctx.write_cgname(&field_ptr);
                ctx.write(" = getelementptr i8, ptr ");
                ctx.write_cgname(&heap_ptr_s);
                ctx.write(", i64 1\n");

                let init_val = ctx.fresh_temp_cg();
                ctx.emit_load_cg2(&init_val, "i64", &field_ptr);

                ctx.emit_store_cg2("i64", &init_val, &shadow);

                // Save state shadow alloca name for CallReturnClause to use
                ctx.set_handler_state_shadow(handler_id.index, cgname_to_string(&shadow));
                cgname_to_string(&shadow)
            } else {
                cgname_to_string(&state_void_ptr)
            };

            ctx.write_indent();
            ctx.write("call void @blood_evidence_push_with_state(ptr ");
            ctx.write_cgname(&evidence);
            ctx.write(", i64 ");
            ctx.write_string(&effect_id_val);
            ctx.write(", ptr ");
            ctx.write_string(&push_state_ptr);
            ctx.write(")\n");

            // Mark as inline handler
            ctx.write_indent();
            ctx.write("call void @blood_evidence_set_inline(i64 ");
            ctx.write_string(&effect_id_val);
            ctx.write(")\n");
        }
        &mir_stmt::StatementKind::PopHandler => {
            // Effect handler pop via evidence API
            let ev_cur = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&ev_cur);
            ctx.write(" = call ptr @blood_evidence_current()\n");

            let pop_result = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&pop_result);
            ctx.write(" = call i64 @blood_evidence_pop(ptr ");
            ctx.write_cgname(&ev_cur);
            ctx.write(")\n");

            ctx.write_indent();
            ctx.write("call void @blood_evidence_clear_inline()\n");
        }
        &mir_stmt::StatementKind::PushInlineHandler { effect_id, operations: _ } => {
            // Inline effect handler push via evidence API
            let effect_id_val = codegen_types::format_u64(effect_id.index as u64);

            // Generate a unique stub function name for this inline handler op
            let stub_id = ctx.inline_stub_count;
            ctx.inline_stub_count = ctx.inline_stub_count + 1;
            let mut stub_name = common::make_string("__inline_stub_");
            let stub_id_str = codegen_types::format_u64(stub_id as u64);
            stub_name.push_str(stub_id_str.as_str());

            // Add the stub function definition (emitted at module level after all bodies)
            let mut stub_def = common::make_string("define internal i64 @");
            stub_def.push_str(stub_name.as_str());
            stub_def.push_str("(ptr %state, ptr %args, i64 %arg_count, i64 %cont) {\nentry:\n  ret i64 0\n}\n\n");
            ctx.inline_stubs.push(stub_def);

            // Get or create evidence vector (using alloca to avoid phi predecessor issue)
            let ev_alloca = ctx.fresh_temp_cg();
            ctx.emit_alloca_cg(&ev_alloca, "ptr");

            let ev_cur = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&ev_cur);
            ctx.write(" = call ptr @blood_evidence_current()\n");

            ctx.emit_store_cg2("ptr", &ev_cur, &ev_alloca);

            let ev_is_null = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&ev_is_null);
            ctx.write(" = icmp eq ptr ");
            ctx.write_cgname(&ev_cur);
            ctx.write(", null\n");

            let create_label = ctx.fresh_label_cg();
            let merge_label = ctx.fresh_label_cg();

            ctx.emit_cond_br_cg(&ev_is_null, &create_label, &merge_label);

            // Create evidence block
            ctx.emit_label_cg(&create_label);
            let new_ev = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&new_ev);
            ctx.write(" = call ptr @blood_evidence_create()\n");
            ctx.write_indent();
            ctx.write("call void @blood_evidence_set_current(ptr ");
            ctx.write_cgname(&new_ev);
            ctx.write(")\n");
            ctx.emit_store_cg2("ptr", &new_ev, &ev_alloca);
            ctx.emit_br_cg(&merge_label);

            // Merge block - load evidence from alloca
            ctx.emit_label_cg(&merge_label);
            let evidence = ctx.fresh_temp_cg();
            ctx.emit_load_cg2(&evidence, "ptr", &ev_alloca);

            // Register stub handler op with the evidence API
            // Build ops array with one stub function pointer (op_index=0)
            let ops_alloca = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&ops_alloca);
            ctx.write(" = alloca [1 x ptr]\n");
            ctx.write_indent();
            ctx.write("store ptr @");
            ctx.write_string(&stub_name);
            ctx.write(", ptr ");
            ctx.write_cgname(&ops_alloca);
            ctx.write("\n");
            ctx.write_indent();
            ctx.write("call void @blood_evidence_register(ptr ");
            ctx.write_cgname(&evidence);
            ctx.write(", i64 ");
            ctx.write_string(&effect_id_val);
            ctx.write(", ptr ");
            ctx.write_cgname(&ops_alloca);
            ctx.write(", i64 1)\n");

            // Push with null state for inline handlers
            ctx.write_indent();
            ctx.write("call void @blood_evidence_push_with_state(ptr ");
            ctx.write_cgname(&evidence);
            ctx.write(", i64 ");
            ctx.write_string(&effect_id_val);
            ctx.write(", ptr null)\n");

            // Mark as inline
            ctx.write_indent();
            ctx.write("call void @blood_evidence_set_inline(i64 ");
            ctx.write_string(&effect_id_val);
            ctx.write(")\n");
        }
        &mir_stmt::StatementKind::CallReturnClause {
            handler_id,
            handler_name: _,
            ref body_result,
            ref state_place,
            ref destination,
        } => {
            // Call the return clause wrapper: handler{N}_return(i64 body_result, ptr state) -> i64
            let (result_val, result_ty) = codegen_expr::emit_operand_typed(ctx, body_result);
            // Use the state shadow alloca (set during PushHandler) instead of state_place.
            // Handler ops mutate through the shadow pointer, so it has the correct state.
            let state_ptr = match ctx.get_handler_state_shadow(handler_id.index) {
                Option::Some(shadow) => clone_string(shadow),
                Option::None => {
                    let addr = codegen_expr::emit_place_addr(ctx, state_place);
                    cgname_to_string(&addr)
                }
            };
            let dest_ptr = {
                let addr = codegen_expr::emit_place_addr(ctx, destination);
                cgname_to_string(&addr)
            };

            // Widen body result to i64
            let widened_result = if strs_equal(result_ty.as_str(), "i64") {
                clone_string(&result_val)
            } else {
                let tmp = ctx.fresh_temp_cg();
                ctx.write_indent();
                ctx.write_cgname(&tmp);
                ctx.write(" = sext ");
                ctx.write_string(&result_ty);
                ctx.write(" ");
                ctx.write_string(&result_val);
                ctx.write(" to i64\n");
                cgname_to_string(&tmp)
            };

            // Build return clause function name: handler{N}_return
            let mut return_fn = common::make_string("handler");
            let id_str = codegen_types::format_u64(handler_id.index as u64);
            return_fn.push_str(id_str.as_str());
            return_fn.push_str("_return");

            // Call: %ret = call i64 @handler{N}_return(i64 %result, ptr %state)
            let ret_val = ctx.fresh_temp_cg();
            ctx.write_indent();
            ctx.write_cgname(&ret_val);
            ctx.write(" = call i64 @");
            ctx.write_string(&return_fn);
            ctx.write("(i64 ");
            ctx.write_string(&widened_result);
            ctx.write(", ptr ");
            ctx.write_string(&state_ptr);
            ctx.write(")\n");

            // Narrow result to destination type (use body result type as proxy)
            if strs_equal(result_ty.as_str(), "i64") {
                ctx.emit_store_cg("i64", &ret_val, dest_ptr.as_str());
            } else {
                let narrowed = ctx.fresh_temp_cg();
                ctx.write_indent();
                ctx.write_cgname(&narrowed);
                ctx.write(" = trunc i64 ");
                ctx.write_cgname(&ret_val);
                ctx.write(" to ");
                ctx.write_string(&result_ty);
                ctx.write("\n");
                ctx.emit_store_cg(result_ty.as_str(), &narrowed, dest_ptr.as_str());
            }
        }
    }
}

/// Emits a sequence of statements.
pub fn emit_statements(
    ctx: &mut codegen_ctx::CodegenCtx,
    stmts: &Vec<mir_stmt::Statement>,
) {
    let mut i: usize = 0;
    while i < stmts.len() {
        emit_statement(ctx, &stmts[i]);
        i = i + 1;
    }
}

// ============================================================
// Memory Operations
// ============================================================

/// Emits a memcpy call.
fn emit_memcpy(
    ctx: &mut codegen_ctx::CodegenCtx,
    dst: &String,
    src: &String,
    count: &String,
) {
    // Calculate bytes: count * 8 (assuming 64-bit values)
    let bytes = ctx.fresh_temp_cg();
    ctx.emit_binop_cg(&bytes, "mul", "i64", count.as_str(), "8");

    // Call llvm.memcpy
    ctx.write_indent();
    ctx.write("call void @llvm.memcpy.p0.p0.i64(ptr ");
    ctx.write_string(dst);
    ctx.write(", ptr ");
    ctx.write_string(src);
    ctx.write(", i64 ");
    ctx.write_cgname(&bytes);
    ctx.write(", i1 false)\n");
}

/// Emits a memset call (for zeroing memory).
pub fn emit_memset_zero(
    ctx: &mut codegen_ctx::CodegenCtx,
    ptr: &String,
    size: u64,
) {
    let size_str = codegen_types::format_u64(size);
    ctx.write_indent();
    ctx.write("call void @llvm.memset.p0.i64(ptr ");
    ctx.write_string(ptr);
    ctx.write(", i8 0, i64 ");
    ctx.write_string(&size_str);
    ctx.write(", i1 false)\n");
}

// ============================================================
// Helper Functions for Locals
// ============================================================

/// Converts a type to LLVM IR, using the ADT registry for struct/enum types.
/// Falls back to `codegen_types::type_to_llvm` for non-ADT types.
pub fn type_to_llvm_with_ctx(
    ctx: &mut codegen_ctx::CodegenCtx,
    ty: &hir_ty::Type,
) -> String {
    match &ty.kind {
        &hir_ty::TypeKind::Adt { def_id, ref args } => {
            let result = ctx.adt_llvm_type(def_id.index);
            // Generic builtin enum not in registry (Option<T>, Result<T,E>)?
            // adt_llvm_type returns "ptr" (3 bytes) as fallback for unknown ADTs.
            // Only expand when the ADT is truly unregistered. Registered ADTs
            // like Box<T> that return "ptr" should NOT be expanded.
            if result.as_bytes().len() == 3
                && result.as_bytes()[0] == 112
                && result.as_bytes()[1] == 116
                && result.as_bytes()[2] == 114
                && args.len() > 0
                && !is_adt_registered(ctx, def_id.index)
            {
                let mut payload_size: u64 = 0;
                let mut ai: usize = 0;
                while ai < args.len() {
                    payload_size = payload_size + type_size_with_ctx(ctx, &args[ai]);
                    ai = ai + 1;
                }
                if payload_size > 0 {
                    let mut s = common::make_string("{ i8, [");
                    let size_str = codegen_types::format_u64(payload_size);
                    s.push_str(size_str.as_str());
                    s.push_str(" x i8] }");
                    return s;
                }
            }
            // For registered structs with type args, rebuild with concrete types.
            // This handles user-defined generic structs like Wrapper<i32>.
            if args.len() > 0 {
                // First check if struct has param fields (borrowing ctx briefly)
                let needs_rebuild = match ctx.lookup_struct(def_id.index) {
                    Option::Some(layout) => struct_has_param_fields(layout),
                    Option::None => false,
                };
                if needs_rebuild {
                    // Collect field info to avoid holding reference into ctx
                    let field_info = collect_struct_field_info(ctx, def_id.index);
                    return rebuild_struct_from_info(ctx, &field_info, args);
                }
            }
            result
        }
        _ => codegen_types::type_to_llvm(ty),
    }
}

/// Checks if any field in a struct layout has a Param HIR type.
fn struct_has_param_fields(layout: &codegen_ctx::StructLayout) -> bool {
    let mut i: usize = 0;
    while i < layout.fields.len() {
        match &layout.fields[i].hir_type {
            &Option::Some(ty_id) => {
                if ty_id_contains_param(ty_id) {
                    return true;
                }
            }
            &Option::None => {}
        }
        i = i + 1;
    }
    false
}

/// Checks if a TyId is or contains a Param or Infer type (via interner).
/// Both Param and Infer indicate unresolved type parameters in struct definitions
/// that need substitution with concrete type args.
fn ty_id_contains_param(ty_id: type_intern::TyId) -> bool {
    let kind = type_intern::type_interner().get(ty_id);
    match kind {
        &type_intern::InternedTypeKind::Param(_) => true,
        &type_intern::InternedTypeKind::Infer(_) => true,
        &type_intern::InternedTypeKind::Ref { inner, mutable: _ } => ty_id_contains_param(inner),
        _ => false,
    }
}

/// Info about a struct field for rebuild. Collected to avoid holding ctx reference.
struct FieldBuildInfo {
    /// The HIR type of the field, if known (interned).
    hir_type: Option<type_intern::TyId>,
    /// The LLVM type string from the registry.
    llvm_type: String,
}

/// Collects field info from a struct layout to avoid borrow conflicts.
fn collect_struct_field_info(ctx: &mut codegen_ctx::CodegenCtx, def_id: u32) -> Vec<FieldBuildInfo> {
    let mut info: Vec<FieldBuildInfo> = Vec::new();
    match ctx.lookup_struct(def_id) {
        Option::Some(layout) => {
            let mut i: usize = 0;
            while i < layout.fields.len() {
                info.push(FieldBuildInfo {
                    hir_type: layout.fields[i].hir_type,
                    llvm_type: clone_string(&layout.fields[i].llvm_type),
                });
                i = i + 1;
            }
        }
        Option::None => {}
    }
    info
}

/// Rebuilds a struct's LLVM type with concrete type args substituted for Param fields.
fn rebuild_struct_from_info(
    ctx: &mut codegen_ctx::CodegenCtx,
    fields: &Vec<FieldBuildInfo>,
    args: &Vec<hir_ty::Type>,
) -> String {
    let mut result = common::make_string("{ ");
    let mut param_idx: usize = 0;
    let mut fi: usize = 0;
    while fi < fields.len() {
        if fi > 0 {
            result.push_str(", ");
        }
        let field_ty = match &fields[fi].hir_type {
            &Option::Some(ty_id) => {
                let field_hir_ty = type_intern::ty_id_to_type(ty_id);
                substitute_param_type(ctx, &field_hir_ty, args, &mut param_idx)
            }
            &Option::None => {
                clone_string(&fields[fi].llvm_type)
            }
        };
        result.push_str(field_ty.as_str());
        fi = fi + 1;
    }
    result.push_str(" }");
    result
}

/// Substitutes Param/Infer types with concrete args, tracking the param index.
fn substitute_param_type(
    ctx: &mut codegen_ctx::CodegenCtx,
    ty: &hir_ty::Type,
    args: &Vec<hir_ty::Type>,
    param_idx: &mut usize,
) -> String {
    match &ty.kind {
        &hir_ty::TypeKind::Param(_) => {
            // Use the next available arg for this param
            let idx = *param_idx;
            if idx < args.len() {
                *param_idx = idx + 1;
                type_to_llvm_with_ctx(ctx, &args[idx])
            } else {
                common::make_string("ptr")
            }
        }
        &hir_ty::TypeKind::Infer(_) => {
            // Infer types in struct definitions are unresolved type parameters
            let idx = *param_idx;
            if idx < args.len() {
                *param_idx = idx + 1;
                type_to_llvm_with_ctx(ctx, &args[idx])
            } else {
                common::make_string("ptr")
            }
        }
        _ => type_to_llvm_with_ctx(ctx, ty),
    }
}

/// Gets the size of a type in bytes, using the ADT registry for struct/enum types.
/// This is context-aware and returns correct sizes for user-defined ADTs.
pub fn type_size_with_ctx(ctx: &mut codegen_ctx::CodegenCtx, ty: &hir_ty::Type) -> u64 {
    match &ty.kind {
        &hir_ty::TypeKind::Adt { def_id, ref args } => {
            let base = adt_size_bytes(ctx, def_id.index);
            // Generic builtin enum not in registry (Option<T>, Result<T,E>)?
            // Only expand when the ADT is truly unregistered (not found in struct,
            // enum, or builtin ADT registries). Registered ADTs like Box<T> that
            // happen to be 8 bytes should NOT be expanded.
            if base == 8 && args.len() > 0 && !is_adt_registered(ctx, def_id.index) {
                let mut payload_size: u64 = 0;
                let mut ai: usize = 0;
                while ai < args.len() {
                    payload_size = payload_size + type_size_with_ctx(ctx, &args[ai]);
                    ai = ai + 1;
                }
                if payload_size > 8 {
                    let tag_size: u64 = 1;
                    return tag_size + payload_size;
                }
            }
            // For registered structs with type args, compute size from rebuilt type
            if args.len() > 0 {
                let needs_rebuild = match ctx.lookup_struct(def_id.index) {
                    Option::Some(layout) => struct_has_param_fields(layout),
                    Option::None => false,
                };
                if needs_rebuild {
                    let field_info = collect_struct_field_info(ctx, def_id.index);
                    let rebuilt = rebuild_struct_from_info(ctx, &field_info, args);
                    return llvm_type_size(rebuilt.as_str());
                }
            }
            base
        }
        _ => codegen_types::type_size_bytes(ty),
    }
}

/// Gets the size of an ADT type from the registry.
/// Computes size from the LLVM type structure.
/// Checks whether an ADT is registered in the struct/enum registry or is a known
/// builtin ADT (Vec, String, HashMap, Box). Returns true if the ADT has an explicit
/// layout, false if it would fall through to the generic "ptr"/8-byte default.
fn is_adt_registered(ctx: &mut codegen_ctx::CodegenCtx, def_id: u32) -> bool {
    // Check struct registry
    match ctx.lookup_struct(def_id) {
        Option::Some(_) => { return true; }
        Option::None => {}
    }
    // Check enum registry
    match ctx.lookup_enum(def_id) {
        Option::Some(_) => { return true; }
        Option::None => {}
    }
    // Check builtin names (Vec, String, HashMap, Box)
    match ctx.lookup_def_name(def_id) {
        Option::Some(name) => {
            let nb = name.as_bytes();
            // Vec
            if nb.len() == 3 && nb[0] == 86 && nb[1] == 101 && nb[2] == 99 {
                return true;
            }
            // String
            if nb.len() == 6 && nb[0] == 83 && nb[1] == 116 && nb[2] == 114 {
                return true;
            }
            // HashMap
            if nb.len() == 7 && nb[0] == 72 && nb[1] == 97 && nb[2] == 115 && nb[3] == 104 {
                return true;
            }
            // Box
            if nb.len() == 3 && nb[0] == 66 && nb[1] == 111 && nb[2] == 120 {
                return true;
            }
            false
        }
        Option::None => false,
    }
}

fn adt_size_bytes(ctx: &mut codegen_ctx::CodegenCtx, def_id: u32) -> u64 {
    // Try to look up struct layout first
    match ctx.lookup_struct(def_id) {
        Option::Some(layout) => {
            return compute_struct_size(layout);
        }
        Option::None => {}
    }
    // Try enum layout
    match ctx.lookup_enum(def_id) {
        Option::Some(layout) => {
            return compute_enum_size(layout);
        }
        Option::None => {}
    }
    // Fallback: compute size from the LLVM type string (handles builtins)
    let llvm_ty = ctx.adt_llvm_type(def_id);
    llvm_type_size(llvm_ty.as_str())
}

/// Computes size of a struct from its layout, using proper field alignment.
fn compute_struct_size(layout: &codegen_ctx::StructLayout) -> u64 {
    let mut size: u64 = 0;
    let mut max_align: u64 = 1;
    let mut i: usize = 0;
    while i < layout.fields.len() {
        let field = &layout.fields[i];
        let field_size = llvm_type_size(field.llvm_type.as_str());
        let field_align = codegen_size::llvm_type_alignment(field.llvm_type.as_str());
        if field_align > max_align {
            max_align = field_align;
        }
        // Align current offset to field's natural alignment
        let padding = (field_align - (size % field_align)) % field_align;
        size = size + padding + field_size;
        i = i + 1;
    }
    // If no fields enumerated, use the llvm_type string to compute size.
    // This handles builtin types (Vec, String, HashMap) registered with empty fields.
    if size == 0 {
        let from_type = llvm_type_size(layout.llvm_type.as_str());
        if from_type > 0 {
            return from_type;
        }
        return 8;
    }
    // Final padding to struct alignment (max of all field alignments)
    let final_padding = (max_align - (size % max_align)) % max_align;
    size + final_padding
}

/// Computes size of an enum from its layout.
/// Enum LLVM type is { discriminant_type, [max_payload_size x i8] }.
/// Alignment is max(discriminant_alignment, 1) = discriminant_alignment.
fn compute_enum_size(layout: &codegen_ctx::EnumLayout) -> u64 {
    let discrim_size = llvm_type_size(layout.discriminant_type.as_str());
    let discrim_align = codegen_size::llvm_type_alignment(layout.discriminant_type.as_str());
    let payload_size = layout.max_payload_size;
    // [N x i8] has alignment 1, so no padding between discriminant and payload
    let total = discrim_size + payload_size;
    // Struct alignment = max(discrim_align, 1) = discrim_align
    let final_padding = (discrim_align - (total % discrim_align)) % discrim_align;
    total + final_padding
}

/// Estimates the size of an LLVM type from its string representation.
fn llvm_type_size(ty: &str) -> u64 {
    let bytes = ty.as_bytes();
    if bytes.len() == 0 {
        return 8;
    }
    // i1, i8 -> 1 byte (but aligned to 8)
    if bytes.len() == 2 && bytes[0] == 105 && bytes[1] == 49 {
        return 1;
    }
    if bytes.len() == 2 && bytes[0] == 105 && bytes[1] == 56 {
        return 1;
    }
    // i16 -> 2 bytes
    if bytes.len() == 3 && bytes[0] == 105 && bytes[1] == 49 && bytes[2] == 54 {
        return 2;
    }
    // i32 -> 4 bytes
    if bytes.len() == 3 && bytes[0] == 105 && bytes[1] == 51 && bytes[2] == 50 {
        return 4;
    }
    // i64 -> 8 bytes
    if bytes.len() == 3 && bytes[0] == 105 && bytes[1] == 54 && bytes[2] == 52 {
        return 8;
    }
    // i128 -> 16 bytes
    if bytes.len() == 4 && bytes[0] == 105 && bytes[1] == 49 && bytes[2] == 50 && bytes[3] == 56 {
        return 16;
    }
    // ptr -> 8 bytes
    if bytes.len() == 3 && bytes[0] == 112 && bytes[1] == 116 && bytes[2] == 114 {
        return 8;
    }
    // float -> 4 bytes
    if bytes.len() == 5 && bytes[0] == 102 && bytes[1] == 108 {
        return 4;
    }
    // double -> 8 bytes
    if bytes.len() == 6 && bytes[0] == 100 && bytes[1] == 111 {
        return 8;
    }
    // Struct { ... } - parse and sum fields
    if bytes[0] == 123 {
        return parse_struct_size(ty);
    }
    // Array [N x T] - parse count and element type, return N * sizeof(T)
    if bytes[0] == 91 {
        // '[' - parse array type
        return parse_array_size(ty);
    }
    // Default: 8 bytes
    8
}

/// Parses a struct type string and computes its size using proper alignment.
/// Each field is aligned to its natural alignment, and the struct is padded
/// to a multiple of the max field alignment.
fn parse_struct_size(ty: &str) -> u64 {
    let bytes = ty.as_bytes();
    let mut offset: u64 = 0;
    let mut max_align: u64 = 1;
    let mut i: usize = 0;
    let mut depth: i32 = 0;
    let mut field_start: usize = 0;
    let mut field_count: u64 = 0;

    while i < bytes.len() {
        let c = bytes[i];
        if c == 123 {
            depth = depth + 1;
            if depth == 1 {
                field_start = i + 1;
            }
        } else if c == 125 {
            if depth == 1 && field_start < i {
                let field_ty = substring(ty, field_start, i);
                let trimmed = trim_whitespace(field_ty.as_str());
                if trimmed.len() > 0 {
                    let field_size = llvm_type_size(trimmed.as_str());
                    let field_align = codegen_size::llvm_type_alignment(trimmed.as_str());
                    if field_align > max_align {
                        max_align = field_align;
                    }
                    let padding = (field_align - (offset % field_align)) % field_align;
                    offset = offset + padding + field_size;
                    field_count = field_count + 1;
                }
            }
            depth = depth - 1;
        } else if c == 44 && depth == 1 {
            let field_ty = substring(ty, field_start, i);
            let trimmed = trim_whitespace(field_ty.as_str());
            if trimmed.len() > 0 {
                let field_size = llvm_type_size(trimmed.as_str());
                let field_align = codegen_size::llvm_type_alignment(trimmed.as_str());
                if field_align > max_align {
                    max_align = field_align;
                }
                let padding = (field_align - (offset % field_align)) % field_align;
                offset = offset + padding + field_size;
                field_count = field_count + 1;
            }
            field_start = i + 1;
        }
        i = i + 1;
    }

    if field_count == 0 {
        return 8;
    }
    // Final padding to struct alignment (max of all field alignments)
    let final_padding = (max_align - (offset % max_align)) % max_align;
    offset + final_padding
}

/// Parses an array type string `[N x T]` and returns N * sizeof(T).
fn parse_array_size(ty: &str) -> u64 {
    let bytes = ty.as_bytes();
    // Skip leading '['
    let mut i: usize = 1;
    // Skip whitespace
    while i < bytes.len() && bytes[i] == 32 {
        i = i + 1;
    }
    // Parse the count N
    let mut count: u64 = 0;
    while i < bytes.len() && bytes[i] >= 48 && bytes[i] <= 57 {
        count = count * 10 + ((bytes[i] - 48) as u64);
        i = i + 1;
    }
    // Skip " x "
    while i < bytes.len() && (bytes[i] == 32 || bytes[i] == 120) {
        i = i + 1;
    }
    // The rest up to ']' is the element type
    let elem_start = i;
    let mut elem_end = bytes.len();
    // Find the closing ']'
    let mut j: usize = bytes.len();
    while j > elem_start {
        j = j - 1;
        if bytes[j] == 93 {
            elem_end = j;
            break;
        }
    }
    let elem_ty = substring(ty, elem_start, elem_end);
    let trimmed = trim_whitespace(elem_ty.as_str());
    let elem_size = llvm_type_size(trimmed.as_str());
    count * elem_size
}

/// Extracts a substring.
fn substring(s: &str, start: usize, end: usize) -> String {
    let bytes = s.as_bytes();
    let mut result = String::new();
    let mut i = start;
    while i < end && i < bytes.len() {
        result.push(bytes[i] as char);
        i = i + 1;
    }
    result
}

/// Trims leading and trailing whitespace.
fn trim_whitespace(s: &str) -> String {
    let bytes = s.as_bytes();
    let mut start: usize = 0;
    let mut end: usize = bytes.len();

    // Skip leading whitespace
    while start < bytes.len() && (bytes[start] == 32 || bytes[start] == 9) {
        start = start + 1;
    }
    // Skip trailing whitespace
    while end > start && (bytes[end - 1] == 32 || bytes[end - 1] == 9) {
        end = end - 1;
    }

    substring(s, start, end)
}

/// Emits alloca instructions for all locals in a function.
pub fn emit_allocas(
    ctx: &mut codegen_ctx::CodegenCtx,
    body: &mir_body::MirBody,
) {
    ctx.indent();
    let mut i: usize = 0;
    while i < body.locals.len() {
        let local = &body.locals[i];
        let local_id = mir_def::MirLocalId::new(i as u32);
        let name_cg = ctx.local_cg(local_id);
        // Use context-aware type resolution for correct ADT alloca sizes
        let ty = codegen_size::type_to_llvm_with_ctx_id(ctx, local.ty);
        // Normalize void to {} for allocas (LLVM allows alloca {} but not alloca void)
        if is_void_or_empty_type(ty.as_str()) {
            ctx.emit_alloca_cg(&name_cg, "{}");
        } else {
            ctx.emit_alloca_cg(&name_cg, ty.as_str());
        }
        let name = ctx.local_alloca_name(local_id);
        ctx.register_local(local_id, clone_string(&name));
        // Also register the type and signedness for this local
        ctx.register_local_type(local_id, clone_string(&ty));
        let local_hir_ty = type_intern::ty_id_to_type(local.ty);
        ctx.register_local_signedness(local_id, codegen_types::is_signed(&local_hir_ty));
        // Register HIR type for ADT layout lookups during projection codegen
        ctx.register_local_hir_type(local_id, local.ty);
        i = i + 1;
    }
    ctx.dedent();
}

/// Emits allocas with escape-aware allocation decisions.
/// NoEscape locals use stack (alloca), ArgEscape use region, GlobalEscape use persistent.
pub fn emit_allocas_with_escapes(
    ctx: &mut codegen_ctx::CodegenCtx,
    body: &mir_body::MirBody,
    escapes: &mir_escape::EscapeAnalysis,
) {
    ctx.indent();
    let mut i: usize = 0;
    while i < body.locals.len() {
        let local = &body.locals[i];
        let local_id = mir_def::MirLocalId::new(i as u32);
        let name_cg = ctx.local_cg(local_id);
        let ty_str = codegen_size::type_to_llvm_with_ctx_id(ctx, local.ty);
        let local_hir_ty = type_intern::ty_id_to_type(local.ty);

        // Get recommended tier from escape analysis
        // Copy types always use stack regardless of escape state
        let tier = if is_copy_type(&local_hir_ty) {
            mir_escape::MemoryTier::Stack
        } else {
            escapes.recommended_tier(local_id)
        };

        // Handler op state local: alloca is `ptr` (holds state pointer from wrapper)
        if ctx.is_handler_state_ptr(local_id) {
            let ptr_ty = common::make_string("ptr");
            emit_stack_local(ctx, &name_cg, &ptr_ty);
        } else {
            match &tier {
                &mir_escape::MemoryTier::Stack => {
                    // Stack allocation (default path)
                    emit_stack_local(ctx, &name_cg, &ty_str);
                }
                &mir_escape::MemoryTier::Region => {
                    // Region allocation with generation tracking
                    let name = ctx.local_alloca_name(local_id);
                    emit_region_local(ctx, &local_hir_ty, &name, local_id);
                    ctx.mark_region_allocated(local_id);
                }
                &mir_escape::MemoryTier::Persistent => {
                    // Persistent allocation
                    let name = ctx.local_alloca_name(local_id);
                    emit_persistent_local(ctx, &local_hir_ty, &name);
                    ctx.mark_persistent_allocated(local_id);
                }
            }
        }

        // Register local metadata (same for all tiers)
        // For handler state locals, register the VALUE type (not ptr) so loads use correct type.
        let name = ctx.local_alloca_name(local_id);
        ctx.register_local(local_id, common::make_string(name.as_str()));
        ctx.register_local_type(local_id, common::make_string(ty_str.as_str()));
        ctx.register_local_signedness(local_id, codegen_types::is_signed(&local_hir_ty));
        ctx.register_local_hir_type(local_id, local.ty);
        i = i + 1;
    }
    ctx.dedent();
}

/// Emits a stack-allocated local (alloca).
fn emit_stack_local(
    ctx: &mut codegen_ctx::CodegenCtx,
    name_cg: &codegen_ctx::CgName,
    ty_str: &String,
) {
    if is_void_or_empty_type(ty_str.as_str()) {
        ctx.emit_alloca_cg(name_cg, "{}");
    } else {
        ctx.emit_alloca_cg(name_cg, ty_str.as_str());
    }
}

/// Emits a region-allocated local with generation tracking.
fn emit_region_local(
    ctx: &mut codegen_ctx::CodegenCtx,
    ty: &hir_ty::Type,
    name: &String,
    local_id: mir_def::MirLocalId,
) {
    // Allocate pointer slot on stack
    let name_cg = ctx.local_cg(local_id);
    ctx.emit_alloca_cg(&name_cg, "ptr");

    // Allocate generation slot on stack (i32)
    let mut gen_name = clone_string(name);
    gen_name.push_str("_gen");
    let gen_name_cg = codegen_ctx::CgName::Str(clone_string(&gen_name));
    ctx.emit_alloca_cg(&gen_name_cg, "i32");

    // Use blood_alloc_or_abort(size, gen_ptr) for heap allocation with
    // generation tracking. The generation value is written to the out-pointer.
    let size = type_size_with_ctx(ctx, ty);
    let size_str = codegen_types::format_u64(size);
    let result_tmp = ctx.fresh_temp_cg();
    ctx.begin_call(Option::Some(&result_tmp), "i64", "@blood_alloc_or_abort");
    ctx.call_arg_str(true, "i64", size_str.as_str());
    ctx.call_arg_str(false, "ptr", gen_name.as_str());
    ctx.end_call();

    // Convert i64 to ptr and store
    let ptr_tmp = ctx.fresh_temp_cg();
    ctx.emit_cast_cg2(&ptr_tmp, "inttoptr", "i64", &result_tmp, "ptr");
    ctx.emit_store_cg("ptr", &ptr_tmp, name.as_str());

    // Record the generation alloca name for this local
    ctx.set_local_generation(local_id, gen_name);
}

/// Emits a persistent-allocated local.
fn emit_persistent_local(
    ctx: &mut codegen_ctx::CodegenCtx,
    ty: &hir_ty::Type,
    name: &String,
) {
    // Allocate pointer slot on stack for the result
    let name_cg = codegen_ctx::CgName::Str(clone_string(name));
    ctx.emit_alloca_cg(&name_cg, "ptr");

    // Allocate a stack slot for the out_id parameter (i64)
    // blood_persistent_alloc writes the slot ID to this address
    let slot_id_tmp = ctx.fresh_temp_cg();
    ctx.emit_alloca_cg(&slot_id_tmp, "i64");

    // Call @blood_persistent_alloc(size, align, type_fp, out_id)
    // Use context-aware size for ADT types
    let size = type_size_with_ctx(ctx, ty);
    let size_str = codegen_types::format_u64(size);
    let result_tmp = ctx.fresh_temp_cg();
    ctx.begin_call(Option::Some(&result_tmp), "ptr", "@blood_persistent_alloc");
    ctx.call_arg_str(true, "i64", size_str.as_str());
    ctx.call_arg_str(false, "i64", "8");
    ctx.call_arg_str(false, "i32", "1");
    ctx.call_arg_cg(false, "ptr", &slot_id_tmp);
    ctx.end_call();

    // Store returned pointer
    ctx.emit_store_cg("ptr", &result_tmp, name.as_str());
}

/// Returns true if the type is Copy (can be stack-allocated regardless of escape).
fn is_copy_type(ty: &hir_ty::Type) -> bool {
    match &ty.kind {
        &hir_ty::TypeKind::Primitive(_) => true,
        &hir_ty::TypeKind::Ref { inner: _, mutable: _ } => true,
        &hir_ty::TypeKind::Ptr { inner: _, mutable: _ } => true,
        &hir_ty::TypeKind::Fn { params: _, ret: _, effects: _ } => true,
        &hir_ty::TypeKind::Never => true,
        &hir_ty::TypeKind::Param(_) => true,
        &hir_ty::TypeKind::Infer(_) => true,
        &hir_ty::TypeKind::Tuple(ref elems) => {
            if elems.len() == 0 {
                return true;
            }
            let mut i: usize = 0;
            while i < elems.len() {
                if !is_copy_type(&elems[i]) {
                    return false;
                }
                i = i + 1;
            }
            true
        }
        &hir_ty::TypeKind::Array { ref element, size: _ } => {
            is_copy_type(element.as_ref())
        }
        _ => false,
    }
}

/// Stores function arguments into their allocas.
/// Parameters are locals[1..1+param_count], mapped to LLVM args %arg0, %arg1, etc.
pub fn emit_arg_stores(
    ctx: &mut codegen_ctx::CodegenCtx,
    body: &mir_body::MirBody,
) {
    ctx.indent();
    let mut i: usize = 1;
    let param_end: usize = 1usize + (body.param_count as usize);
    while i < param_end && i < body.locals.len() {
        let local = &body.locals[i];
        let local_id = mir_def::MirLocalId::new(i as u32);
        let alloca_name = ctx.local_alloca_name(local_id);
        let ty = codegen_size::type_to_llvm_with_ctx_id(ctx, local.ty);

        // Argument name is %arg0, %arg1, etc. (i-1 because params start at local index 1)
        let mut arg_name = common::make_string("%arg");
        let idx_str = codegen_types::format_u64((i - 1) as u64);
        arg_name.push_str(idx_str.as_str());

        // Handler op state local: store the pointer (ptr type, not value type)
        if ctx.is_handler_state_ptr(local_id) {
            ctx.emit_store("ptr", arg_name.as_str(), alloca_name.as_str());
        } else {
            // Skip store for unit type {} — it has zero size in LLVM
            if !strs_equal(ty.as_str(), "{}") {
                ctx.emit_store(ty.as_str(), arg_name.as_str(), alloca_name.as_str());
            }
        }
        i = i + 1;
    }
    ctx.dedent();
}

// ============================================================
// String Helpers
// ============================================================

/// Clones a String.
/// Checks if an LLVM type is void or {} (empty struct / unit).
fn is_void_or_empty_type(ty: &str) -> bool {
    let bytes = ty.as_bytes();
    // Check "void"
    if bytes.len() == 4 && bytes[0] == 118 && bytes[1] == 111 && bytes[2] == 105 && bytes[3] == 100 {
        return true;
    }
    // Check "{}"
    if bytes.len() == 2 && bytes[0] == 123 && bytes[1] == 125 {
        return true;
    }
    false
}

pub fn clone_string(s: &String) -> String {
    let mut result = String::new();
    result.push_str(s.as_str());
    result
}

fn strs_equal(a: &str, b: &str) -> bool {
    let a_bytes = a.as_bytes();
    let b_bytes = b.as_bytes();
    if a_bytes.len() != b_bytes.len() {
        return false;
    }
    let mut i: usize = 0;
    while i < a_bytes.len() {
        if a_bytes[i] != b_bytes[i] {
            return false;
        }
        i = i + 1;
    }
    true
}

fn cgname_to_string(name: &codegen_ctx::CgName) -> String {
    match name {
        &codegen_ctx::CgName::Temp(n) => {
            let mut s = common::make_string("%tmp");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Local(n) => {
            let mut s = common::make_string("%_");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Label(n) => {
            let mut s = common::make_string("label");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Block(n) => {
            let mut s = common::make_string("bb");
            let ns = codegen_types::format_u64(n as u64);
            s.push_str(ns.as_str());
            s
        }
        &codegen_ctx::CgName::Str(ref s) => {
            clone_string(s)
        }
    }
}
