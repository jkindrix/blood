// Blood Self-Hosted Compiler - Codegen Statements
//
// This module handles generating LLVM IR for MIR statements.

mod common;
mod hir_def;
mod hir_ty;
mod mir_def;
mod mir_types;
mod mir_stmt;
mod mir_term;
mod mir_body;
mod codegen_types;
mod codegen_ctx;
mod codegen_expr;
mod mir_escape;

// ============================================================
// Statement Codegen
// ============================================================

/// Generates LLVM IR for a statement.
pub fn emit_statement(
    ctx: &mut codegen_ctx::CodegenCtx,
    stmt: &mir_stmt::Statement,
) {
    match &stmt.kind {
        &mir_stmt::StatementKind::Assign { ref place, ref rvalue } => {
            let dest = codegen_expr::emit_place_addr(ctx, place);
            codegen_expr::emit_rvalue(ctx, dest.as_str(), rvalue);
        }
        &mir_stmt::StatementKind::StorageLive(ref local) => {
            // In LLVM IR, storage is typically handled by alloca placement
            // For now, emit as a comment/no-op
            let name = ctx.local_alloca_name(*local);
            ctx.write("    ; storage live ");
            ctx.write_string(&name);
            ctx.newline();
        }
        &mir_stmt::StatementKind::StorageDead(ref local) => {
            let name = ctx.local_alloca_name(*local);
            if ctx.is_region_allocated(*local) {
                // Region-allocated local: unregister from allocation tracker
                ctx.write("    ; storage dead (region) ");
                ctx.write_string(&name);
                ctx.newline();
                let ptr_val = ctx.fresh_temp();
                ctx.emit_load(ptr_val.as_str(), "ptr", name.as_str());
                let int_val = ctx.fresh_temp();
                ctx.emit_cast(int_val.as_str(), "ptrtoint", "ptr", ptr_val.as_str(), "i64");
                let mut args: Vec<(String, String)> = Vec::new();
                args.push((common::make_string("i64"), clone_string(&int_val)));
                ctx.emit_call(Option::None, "void", "@blood_unregister_allocation", &args);
            } else if ctx.is_persistent_allocated(*local) {
                // Persistent-allocated local: decrement reference count
                ctx.write("    ; storage dead (persistent) ");
                ctx.write_string(&name);
                ctx.newline();
                let slot_val = ctx.fresh_temp();
                ctx.emit_load(slot_val.as_str(), "i64", name.as_str());
                // Only decrement if slot_id != 0 (0 means uninitialized)
                let cmp_val = ctx.fresh_temp();
                ctx.emit_icmp(cmp_val.as_str(), "ne", "i64", slot_val.as_str(), "0");
                let then_label = ctx.fresh_label();
                let end_label = ctx.fresh_label();
                ctx.emit_cond_br(cmp_val.as_str(), then_label.as_str(), end_label.as_str());
                ctx.emit_label(then_label.as_str());
                let mut args: Vec<(String, String)> = Vec::new();
                args.push((common::make_string("i64"), clone_string(&slot_val)));
                ctx.emit_call(Option::None, "void", "@blood_persistent_decrement", &args);
                ctx.emit_br(end_label.as_str());
                ctx.emit_label(end_label.as_str());
            } else {
                // Stack-allocated local: no cleanup needed
                ctx.write("    ; storage dead ");
                ctx.write_string(&name);
                ctx.newline();
            }
        }
        &mir_stmt::StatementKind::Drop(ref place) => {
            // Check if this is a ref type pointing to a region-allocated value
            let mut is_ref_region = false;
            let mut drop_size: u64 = 0;
            match ctx.get_local_hir_type(place.local) {
                Option::Some(hir_type) => {
                    match &hir_type.kind {
                        &hir_ty::TypeKind::Ref { ref inner, mutable: _ } => {
                            if ctx.is_region_allocated(place.local) {
                                is_ref_region = true;
                                drop_size = type_size_with_ctx(ctx, inner.as_ref());
                            }
                        }
                        _ => {}
                    }
                }
                Option::None => {}
            }
            if is_ref_region {
                // Region-allocated reference: free the pointed-to memory
                let ptr = codegen_expr::emit_place_addr(ctx, place);
                ctx.write("    ; drop (region free)\n");
                let addr_val = ctx.fresh_temp();
                ctx.emit_load(addr_val.as_str(), "ptr", ptr.as_str());
                let int_val = ctx.fresh_temp();
                ctx.emit_cast(int_val.as_str(), "ptrtoint", "ptr", addr_val.as_str(), "i64");
                let size_str = codegen_types::format_u64(drop_size);
                let mut args: Vec<(String, String)> = Vec::new();
                args.push((common::make_string("i64"), clone_string(&int_val)));
                args.push((common::make_string("i64"), size_str));
                ctx.emit_call(Option::None, "void", "@blood_free", &args);
            } else {
                let _ptr = codegen_expr::emit_place_addr(ctx, place);
                ctx.write("    ; drop (no-op)\n");
            }
        }
        &mir_stmt::StatementKind::Deinit(ref place) => {
            // Deinit - mark as uninitialized (no-op in simple codegen)
            let _ptr = codegen_expr::emit_place_addr(ctx, place);
            ctx.write("    ; deinit\n");
        }
        &mir_stmt::StatementKind::SetDiscriminant { ref place, variant_idx } => {
            // Set the discriminant field of an enum
            let ptr = codegen_expr::emit_place_addr(ctx, place);
            let discr_val = codegen_types::format_u64(variant_idx as u64);

            // Try to look up enum layout for correct discriminant type
            let mut discr_ty = common::make_string("i64");
            let mut enum_llvm_ty = common::make_string("{ i64, i64 }");
            let mut found_enum = false;

            match ctx.get_local_hir_type(place.local) {
                Option::Some(hir_type) => {
                    match &hir_type.kind {
                        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
                            match ctx.lookup_enum(def_id.index) {
                                Option::Some(layout) => {
                                    discr_ty = clone_string(&layout.discriminant_type);
                                    enum_llvm_ty = clone_string(&layout.llvm_type);
                                    found_enum = true;
                                }
                                Option::None => {}
                            }
                        }
                        _ => {}
                    }
                }
                Option::None => {}
            }

            if found_enum {
                // GEP to discriminant field (index 0) of the enum type
                let discr_ptr = ctx.fresh_temp();
                let mut indices: Vec<String> = Vec::new();
                indices.push(common::make_string("0"));
                indices.push(common::make_string("0"));
                ctx.emit_gep(discr_ptr.as_str(), enum_llvm_ty.as_str(), ptr.as_str(), &indices);
                ctx.emit_store(discr_ty.as_str(), discr_val.as_str(), discr_ptr.as_str());
            } else {
                // Fallback: store i64 directly
                ctx.emit_store("i64", discr_val.as_str(), ptr.as_str());
            }
        }
        &mir_stmt::StatementKind::CopyNonOverlapping { ref src, ref dst, ref count } => {
            // Emit memcpy intrinsic
            let src_val = codegen_expr::emit_operand(ctx, src);
            let dst_val = codegen_expr::emit_operand(ctx, dst);
            let count_val = codegen_expr::emit_operand(ctx, count);
            emit_memcpy(ctx, &dst_val, &src_val, &count_val);
        }
        &mir_stmt::StatementKind::Nop => {
            // No operation - do nothing
        }
        &mir_stmt::StatementKind::PushHandler { handler_id, ref state_place, state_kind: _ } => {
            // Effect handler push - call runtime function
            let state_ptr = codegen_expr::emit_place_addr(ctx, state_place);
            let handler_id_val = codegen_types::format_u64(handler_id.index as u64);

            // Call @blood_push_handler(handler_id, state_ptr)
            ctx.write_indent();
            ctx.write("call void @blood_push_handler(i64 ");
            ctx.write_string(&handler_id_val);
            ctx.write(", ptr ");
            ctx.write_string(&state_ptr);
            ctx.write(")\n");
        }
        &mir_stmt::StatementKind::PopHandler => {
            // Effect handler pop - call runtime function
            ctx.write_indent();
            ctx.write("call void @blood_pop_handler()\n");
        }
        &mir_stmt::StatementKind::PushInlineHandler { effect_id, operations: _ } => {
            // Inline effect handler - call runtime function
            let effect_id_val = codegen_types::format_u64(effect_id.index as u64);

            ctx.write_indent();
            ctx.write("call void @blood_push_inline_handler(i64 ");
            ctx.write_string(&effect_id_val);
            ctx.write(")\n");
        }
        &mir_stmt::StatementKind::CallReturnClause {
            handler_id: _,
            handler_name: _,
            ref body_result,
            ref state_place,
            ref destination,
        } => {
            // Return clause - copy result to destination
            let result_val = codegen_expr::emit_operand(ctx, body_result);
            let _state = codegen_expr::emit_place_addr(ctx, state_place);
            let dest_ptr = codegen_expr::emit_place_addr(ctx, destination);
            ctx.emit_store("i64", result_val.as_str(), dest_ptr.as_str());
        }
    }
}

/// Emits a sequence of statements.
pub fn emit_statements(
    ctx: &mut codegen_ctx::CodegenCtx,
    stmts: &Vec<mir_stmt::Statement>,
) {
    let mut i: usize = 0;
    while i < stmts.len() {
        emit_statement(ctx, &stmts[i]);
        i = i + 1;
    }
}

// ============================================================
// Memory Operations
// ============================================================

/// Emits a memcpy call.
fn emit_memcpy(
    ctx: &mut codegen_ctx::CodegenCtx,
    dst: &String,
    src: &String,
    count: &String,
) {
    // Calculate bytes: count * 8 (assuming 64-bit values)
    let bytes = ctx.fresh_temp();
    ctx.emit_binop(bytes.as_str(), "mul", "i64", count.as_str(), "8");

    // Call llvm.memcpy
    ctx.write_indent();
    ctx.write("call void @llvm.memcpy.p0.p0.i64(ptr ");
    ctx.write_string(dst);
    ctx.write(", ptr ");
    ctx.write_string(src);
    ctx.write(", i64 ");
    ctx.write_string(&bytes);
    ctx.write(", i1 false)\n");
}

/// Emits a memset call (for zeroing memory).
pub fn emit_memset_zero(
    ctx: &mut codegen_ctx::CodegenCtx,
    ptr: &String,
    size: u64,
) {
    let size_str = codegen_types::format_u64(size);
    ctx.write_indent();
    ctx.write("call void @llvm.memset.p0.i64(ptr ");
    ctx.write_string(ptr);
    ctx.write(", i8 0, i64 ");
    ctx.write_string(&size_str);
    ctx.write(", i1 false)\n");
}

// ============================================================
// Helper Functions for Locals
// ============================================================

/// Converts a type to LLVM IR, using the ADT registry for struct/enum types.
/// Falls back to `codegen_types::type_to_llvm` for non-ADT types.
pub fn type_to_llvm_with_ctx(
    ctx: &mut codegen_ctx::CodegenCtx,
    ty: &hir_ty::Type,
) -> String {
    match &ty.kind {
        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
            ctx.adt_llvm_type(def_id.index)
        }
        _ => codegen_types::type_to_llvm(ty),
    }
}

/// Gets the size of a type in bytes, using the ADT registry for struct/enum types.
/// This is context-aware and returns correct sizes for user-defined ADTs.
pub fn type_size_with_ctx(ctx: &mut codegen_ctx::CodegenCtx, ty: &hir_ty::Type) -> u64 {
    match &ty.kind {
        &hir_ty::TypeKind::Adt { def_id, args: _ } => {
            adt_size_bytes(ctx, def_id.index)
        }
        _ => codegen_types::type_size_bytes(ty),
    }
}

/// Gets the size of an ADT type from the registry.
/// Computes size from the LLVM type structure.
fn adt_size_bytes(ctx: &mut codegen_ctx::CodegenCtx, def_id: u32) -> u64 {
    // Try to look up struct layout first
    match ctx.lookup_struct(def_id) {
        Option::Some(layout) => {
            return compute_struct_size(layout);
        }
        Option::None => {}
    }
    // Try enum layout
    match ctx.lookup_enum(def_id) {
        Option::Some(layout) => {
            return compute_enum_size(layout);
        }
        Option::None => {}
    }
    // Fallback: compute size from the LLVM type string (handles builtins)
    let llvm_ty = ctx.adt_llvm_type(def_id);
    llvm_type_size(llvm_ty.as_str())
}

/// Computes size of a struct from its layout.
fn compute_struct_size(layout: &codegen_ctx::StructLayout) -> u64 {
    let mut size: u64 = 0;
    let mut i: usize = 0;
    while i < layout.fields.len() {
        let field = &layout.fields[i];
        // Compute field size based on LLVM type
        let field_size = llvm_type_size(field.llvm_type.as_str());
        // Align to 8 bytes (simplification - assume 8-byte alignment)
        let padding = (8u64 - (size % 8u64)) % 8u64;
        size = size + padding + field_size;
        i = i + 1;
    }
    // Minimum size of 8 bytes, and round up to 8-byte alignment
    if size == 0 {
        return 8;
    }
    let final_padding = (8u64 - (size % 8u64)) % 8u64;
    size + final_padding
}

/// Computes size of an enum from its layout.
fn compute_enum_size(layout: &codegen_ctx::EnumLayout) -> u64 {
    // Discriminant size
    let discrim_size = llvm_type_size(layout.discriminant_type.as_str());
    // Max payload size + padding
    let payload_size = layout.max_payload_size;
    // Round up to 8-byte alignment
    let total = discrim_size + payload_size;
    let padding = (8u64 - (total % 8u64)) % 8u64;
    total + padding
}

/// Estimates the size of an LLVM type from its string representation.
fn llvm_type_size(ty: &str) -> u64 {
    let bytes = ty.as_bytes();
    if bytes.len() == 0 {
        return 8;
    }
    // i1, i8 -> 1 byte (but aligned to 8)
    if bytes.len() == 2 && bytes[0] == 105 && bytes[1] == 49 {
        return 1;
    }
    if bytes.len() == 2 && bytes[0] == 105 && bytes[1] == 56 {
        return 1;
    }
    // i16 -> 2 bytes
    if bytes.len() == 3 && bytes[0] == 105 && bytes[1] == 49 && bytes[2] == 54 {
        return 2;
    }
    // i32 -> 4 bytes
    if bytes.len() == 3 && bytes[0] == 105 && bytes[1] == 51 && bytes[2] == 50 {
        return 4;
    }
    // i64 -> 8 bytes
    if bytes.len() == 3 && bytes[0] == 105 && bytes[1] == 54 && bytes[2] == 52 {
        return 8;
    }
    // i128 -> 16 bytes
    if bytes.len() == 4 && bytes[0] == 105 && bytes[1] == 49 && bytes[2] == 50 && bytes[3] == 56 {
        return 16;
    }
    // ptr -> 8 bytes
    if bytes.len() == 3 && bytes[0] == 112 && bytes[1] == 116 && bytes[2] == 114 {
        return 8;
    }
    // float -> 4 bytes
    if bytes.len() == 5 && bytes[0] == 102 && bytes[1] == 108 {
        return 4;
    }
    // double -> 8 bytes
    if bytes.len() == 6 && bytes[0] == 100 && bytes[1] == 111 {
        return 8;
    }
    // Struct { ... } - parse and sum fields
    if bytes[0] == 123 {
        return parse_struct_size(ty);
    }
    // Default: 8 bytes
    8
}

/// Parses a struct type string and computes its size.
fn parse_struct_size(ty: &str) -> u64 {
    let bytes = ty.as_bytes();
    let mut size: u64 = 0;
    let mut i: usize = 0;
    let mut depth: i32 = 0;
    let mut field_start: usize = 0;

    while i < bytes.len() {
        let c = bytes[i];
        if c == 123 {
            // '{'
            depth = depth + 1;
            if depth == 1 {
                field_start = i + 1;
            }
        } else if c == 125 {
            // '}'
            if depth == 1 && field_start < i {
                // End of top-level struct, process last field
                let field_ty = substring(ty, field_start, i);
                let trimmed = trim_whitespace(field_ty.as_str());
                if trimmed.len() > 0 {
                    size = size + llvm_type_size(trimmed.as_str());
                }
            }
            depth = depth - 1;
        } else if c == 44 && depth == 1 {
            // ',' at top level
            let field_ty = substring(ty, field_start, i);
            let trimmed = trim_whitespace(field_ty.as_str());
            if trimmed.len() > 0 {
                size = size + llvm_type_size(trimmed.as_str());
            }
            field_start = i + 1;
        }
        i = i + 1;
    }

    // Round up to 8-byte alignment
    if size == 0 {
        return 8;
    }
    let padding = (8u64 - (size % 8u64)) % 8u64;
    size + padding
}

/// Extracts a substring.
fn substring(s: &str, start: usize, end: usize) -> String {
    let bytes = s.as_bytes();
    let mut result = String::new();
    let mut i = start;
    while i < end && i < bytes.len() {
        result.push(bytes[i] as char);
        i = i + 1;
    }
    result
}

/// Trims leading and trailing whitespace.
fn trim_whitespace(s: &str) -> String {
    let bytes = s.as_bytes();
    let mut start: usize = 0;
    let mut end: usize = bytes.len();

    // Skip leading whitespace
    while start < bytes.len() && (bytes[start] == 32 || bytes[start] == 9) {
        start = start + 1;
    }
    // Skip trailing whitespace
    while end > start && (bytes[end - 1] == 32 || bytes[end - 1] == 9) {
        end = end - 1;
    }

    substring(s, start, end)
}

/// Emits alloca instructions for all locals in a function.
pub fn emit_allocas(
    ctx: &mut codegen_ctx::CodegenCtx,
    body: &mir_body::MirBody,
) {
    ctx.indent();
    let mut i: usize = 0;
    while i < body.locals.len() {
        let local = &body.locals[i];
        let local_id = mir_def::MirLocalId::new(i as u32);
        let name = ctx.local_alloca_name(local_id);
        // Use context-aware type resolution for correct ADT alloca sizes
        let ty = type_to_llvm_with_ctx(ctx, &local.ty);
        // Normalize void to {} for allocas (LLVM allows alloca {} but not alloca void)
        if is_void_or_empty_type(ty.as_str()) {
            ctx.emit_alloca(name.as_str(), "{}");
        } else {
            ctx.emit_alloca(name.as_str(), ty.as_str());
        }
        ctx.register_local(local_id, clone_string(&name));
        // Also register the type and signedness for this local
        ctx.register_local_type(local_id, clone_string(&ty));
        ctx.register_local_signedness(local_id, codegen_types::is_signed(&local.ty));
        // Register HIR type for ADT layout lookups during projection codegen
        ctx.register_local_hir_type(local_id, hir_ty::copy_type(&local.ty));
        i = i + 1;
    }
    ctx.dedent();
}

/// Emits allocas with escape-aware allocation decisions.
/// NoEscape locals use stack (alloca), ArgEscape use region, GlobalEscape use persistent.
pub fn emit_allocas_with_escapes(
    ctx: &mut codegen_ctx::CodegenCtx,
    body: &mir_body::MirBody,
    escapes: &mir_escape::EscapeAnalysis,
) {
    ctx.indent();
    let mut i: usize = 0;
    while i < body.locals.len() {
        let local = &body.locals[i];
        let local_id = mir_def::MirLocalId::new(i as u32);
        let name = ctx.local_alloca_name(local_id);
        let ty_str = type_to_llvm_with_ctx(ctx, &local.ty);

        // Get recommended tier from escape analysis
        // Copy types always use stack regardless of escape state
        let tier = if is_copy_type(&local.ty) {
            mir_escape::MemoryTier::Stack
        } else {
            escapes.recommended_tier(local_id)
        };

        match &tier {
            &mir_escape::MemoryTier::Stack => {
                // Stack allocation (default path)
                emit_stack_local(ctx, &name, &ty_str);
            }
            &mir_escape::MemoryTier::Region => {
                // Region allocation
                emit_region_local(ctx, &local.ty, &name);
                ctx.mark_region_allocated(local_id);
            }
            &mir_escape::MemoryTier::Persistent => {
                // Persistent allocation
                emit_persistent_local(ctx, &local.ty, &name);
                ctx.mark_persistent_allocated(local_id);
            }
        }

        // Register local metadata (same for all tiers)
        ctx.register_local(local_id, common::make_string(name.as_str()));
        ctx.register_local_type(local_id, common::make_string(ty_str.as_str()));
        ctx.register_local_signedness(local_id, codegen_types::is_signed(&local.ty));
        ctx.register_local_hir_type(local_id, hir_ty::copy_type(&local.ty));
        i = i + 1;
    }
    ctx.dedent();
}

/// Emits a stack-allocated local (alloca).
fn emit_stack_local(
    ctx: &mut codegen_ctx::CodegenCtx,
    name: &String,
    ty_str: &String,
) {
    if is_void_or_empty_type(ty_str.as_str()) {
        ctx.emit_alloca(name.as_str(), "{}");
    } else {
        ctx.emit_alloca(name.as_str(), ty_str.as_str());
    }
}

/// Emits a region-allocated local.
fn emit_region_local(
    ctx: &mut codegen_ctx::CodegenCtx,
    ty: &hir_ty::Type,
    name: &String,
) {
    // Allocate pointer slot on stack
    ctx.emit_alloca(name.as_str(), "ptr");

    // Call @blood_region_alloc(region_id=0, size, align)
    // Use context-aware size for ADT types
    let size = type_size_with_ctx(ctx, ty);
    let size_str = codegen_types::format_u64(size);
    let result_tmp = ctx.fresh_temp();
    let mut args: Vec<(String, String)> = Vec::new();
    args.push((common::make_string("i64"), common::make_string("0")));
    args.push((common::make_string("i64"), size_str));
    args.push((common::make_string("i64"), common::make_string("8")));
    ctx.emit_call(Option::Some(result_tmp.as_str()), "i64", "@blood_region_alloc", &args);

    // Convert i64 to ptr and store
    let ptr_tmp = ctx.fresh_temp();
    ctx.emit_cast(ptr_tmp.as_str(), "inttoptr", "i64", result_tmp.as_str(), "ptr");
    ctx.emit_store("ptr", ptr_tmp.as_str(), name.as_str());
}

/// Emits a persistent-allocated local.
fn emit_persistent_local(
    ctx: &mut codegen_ctx::CodegenCtx,
    ty: &hir_ty::Type,
    name: &String,
) {
    // Allocate pointer slot on stack for the result
    ctx.emit_alloca(name.as_str(), "ptr");

    // Allocate a stack slot for the out_id parameter (i64)
    // blood_persistent_alloc writes the slot ID to this address
    let slot_id_tmp = ctx.fresh_temp();
    ctx.emit_alloca(slot_id_tmp.as_str(), "i64");

    // Call @blood_persistent_alloc(size, align, type_fp, out_id)
    // Use context-aware size for ADT types
    let size = type_size_with_ctx(ctx, ty);
    let size_str = codegen_types::format_u64(size);
    let result_tmp = ctx.fresh_temp();
    let mut args: Vec<(String, String)> = Vec::new();
    args.push((common::make_string("i64"), size_str));
    args.push((common::make_string("i64"), common::make_string("8")));
    args.push((common::make_string("i32"), common::make_string("1")));
    args.push((common::make_string("ptr"), slot_id_tmp));
    ctx.emit_call(Option::Some(result_tmp.as_str()), "ptr", "@blood_persistent_alloc", &args);

    // Store returned pointer
    ctx.emit_store("ptr", result_tmp.as_str(), name.as_str());
}

/// Returns true if the type is Copy (can be stack-allocated regardless of escape).
fn is_copy_type(ty: &hir_ty::Type) -> bool {
    match &ty.kind {
        &hir_ty::TypeKind::Primitive(_) => true,
        &hir_ty::TypeKind::Ref { inner: _, mutable: _ } => true,
        &hir_ty::TypeKind::Ptr { inner: _, mutable: _ } => true,
        &hir_ty::TypeKind::Fn { params: _, ret: _, effects: _ } => true,
        &hir_ty::TypeKind::Never => true,
        &hir_ty::TypeKind::Tuple(ref elems) => {
            if elems.len() == 0 {
                return true;
            }
            let mut i: usize = 0;
            while i < elems.len() {
                if !is_copy_type(&elems[i]) {
                    return false;
                }
                i = i + 1;
            }
            true
        }
        &hir_ty::TypeKind::Array { ref element, size: _ } => {
            is_copy_type(element.as_ref())
        }
        _ => false,
    }
}

/// Stores function arguments into their allocas.
/// Parameters are locals[1..1+param_count], mapped to LLVM args %arg0, %arg1, etc.
pub fn emit_arg_stores(
    ctx: &mut codegen_ctx::CodegenCtx,
    body: &mir_body::MirBody,
) {
    ctx.indent();
    let mut i: usize = 1;
    let param_end: usize = 1usize + (body.param_count as usize);
    while i < param_end && i < body.locals.len() {
        let local = &body.locals[i];
        let local_id = mir_def::MirLocalId::new(i as u32);
        let alloca_name = ctx.local_alloca_name(local_id);
        let ty = type_to_llvm_with_ctx(ctx, &local.ty);

        // Argument name is %arg0, %arg1, etc. (i-1 because params start at local index 1)
        let mut arg_name = common::make_string("%arg");
        let idx_str = codegen_types::format_u64((i - 1) as u64);
        arg_name.push_str(idx_str.as_str());

        ctx.emit_store(ty.as_str(), arg_name.as_str(), alloca_name.as_str());
        i = i + 1;
    }
    ctx.dedent();
}

// ============================================================
// String Helpers
// ============================================================

/// Clones a String.
/// Checks if an LLVM type is void or {} (empty struct / unit).
fn is_void_or_empty_type(ty: &str) -> bool {
    let bytes = ty.as_bytes();
    // Check "void"
    if bytes.len() == 4 && bytes[0] == 118 && bytes[1] == 111 && bytes[2] == 105 && bytes[3] == 100 {
        return true;
    }
    // Check "{}"
    if bytes.len() == 2 && bytes[0] == 123 && bytes[1] == 125 {
        return true;
    }
    false
}

pub fn clone_string(s: &String) -> String {
    let mut result = String::new();
    let bytes = s.as_bytes();
    let mut i: usize = 0;
    while i < bytes.len() {
        result.push(bytes[i] as char);
        i = i + 1;
    }
    result
}
