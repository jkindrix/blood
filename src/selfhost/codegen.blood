// Blood Self-Hosted Compiler - Code Generator
//
// This module provides the main entry point for generating LLVM IR from MIR.
// It coordinates the generation of function bodies, declarations, and
// produces complete LLVM modules as text.

mod common;
mod hir_def;
mod hir_ty;
mod hir_item;
mod hir_lower_ctx;
mod mir_def;
mod mir_types;
mod mir_stmt;
mod mir_term;
mod mir_body;
mod codegen_types;
mod codegen_ctx;
mod codegen_expr;
mod codegen_stmt;
mod codegen_term;
mod mir_escape;
mod hashmap;
mod type_intern;
mod codegen_size;

// ============================================================
// Module Generation
// ============================================================

/// Result of code generation for a complete module.
pub struct CodegenResult {
    /// The generated LLVM IR as a string.
    pub llvm_ir: String,
    /// Structured errors collected during codegen.
    pub errors: Vec<codegen_ctx.CodegenError>,
    /// Any warnings generated during codegen.
    pub warnings: Vec<String>,
    /// Whether codegen was successful.
    pub success: bool,
}

impl CodegenResult {
    /// Creates a successful result with no errors.
    pub fn ok(llvm_ir: String) -> CodegenResult {
        CodegenResult {
            llvm_ir: llvm_ir,
            errors: Vec.new(),
            warnings: Vec.new(),
            success: true,
        }
    }

    /// Creates a successful result that carries non-fatal errors/warnings from codegen.
    pub fn ok_with_diagnostics(
        llvm_ir: String,
        errors: Vec<codegen_ctx.CodegenError>,
        warnings: Vec<String>,
    ) -> CodegenResult {
        CodegenResult {
            llvm_ir: llvm_ir,
            errors: errors,
            warnings: warnings,
            success: true,
        }
    }

    /// Creates a failed result with a single error message.
    pub fn error(msg: String) -> CodegenResult {
        let mut errors = Vec.new();
        errors.push(codegen_ctx.CodegenError.new(
            codegen_ctx.CodegenErrorKind.InternalError,
            msg,
        ));
        CodegenResult {
            llvm_ir: String.new(),
            errors: errors,
            warnings: Vec.new(),
            success: false,
        }
    }

    /// Returns true if there are any errors.
    pub fn has_errors(self: &CodegenResult) -> bool {
        self.errors.len() > 0
    }
}

/// Generates LLVM IR for a module with multiple functions.
pub fn generate_module(
    module_name: &str,
    functions: &Vec<(String, mir_body.MirBody)>,
) -> CodegenResult {
    // Empty items list and no remaps for backward compatibility
    let empty_items: Vec<hir_lower_ctx.ItemEntry> = Vec.new();
    let empty_remaps: Vec<common.DefaultMethodRemap> = Vec.new();
    generate_module_with_items(module_name, functions, &empty_items, &empty_remaps)
}

/// Finds call remapping entries for a given default method DefId.
fn find_call_remaps(
    remaps: &Vec<common.DefaultMethodRemap>,
    def_id: u32,
) -> Vec<common.CallRemapEntry> {
    let mut result: Vec<common.CallRemapEntry> = Vec.new();
    for i in 0usize..remaps.len() {
        if remaps[i].body_def_id == def_id {
            for j in 0usize..remaps[i].call_remaps.len() {
                result.push(common.CallRemapEntry.new(
                    remaps[i].call_remaps[j].from_def_id,
                    remaps[i].call_remaps[j].to_def_id,
                ));
            }
            return result;
        }
    }
    result
}

/// Generates LLVM IR for a module with multiple functions and ADT item info.
pub fn generate_module_with_items(
    module_name: &str,
    functions: &Vec<(String, mir_body.MirBody)>,
    items: &Vec<hir_lower_ctx.ItemEntry>,
    default_method_remaps: &Vec<common.DefaultMethodRemap>,
) -> CodegenResult {
    let mut output = String.new();

    // Build the DefId to name mapping for all functions
    let mut def_names: Vec<codegen_ctx.DefNameEntry> = Vec.new();
    for idx in 0usize..functions.len() {
        let (ref name, ref body) = functions[idx];
        def_names.push(codegen_ctx.DefNameEntry.new(
            body.def_id.index,
            clone_string(name),
        ));
    }

    // Create the shared codegen context with def names
    let mut ctx = codegen_ctx.CodegenCtx.new();
    for di in 0usize..def_names.len() {
        ctx.register_def_name(def_names[di].def_id, clone_string(&def_names[di].name));
    }

    // Populate ADT registry from HIR items
    populate_adt_registry(&mut ctx, items);

    // Module header
    output.push_str("; ModuleID = '");
    output.push_str(module_name);
    output.push_str("'\n");
    output.push_str("source_filename = \"");
    output.push_str(module_name);
    output.push_str(".blood\"\n");
    output.push_str("target datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128\"\n");
    output.push_str("target triple = \"x86_64-unknown-linux-gnu\"\n");
    output.push_str("\n");

    // Generate each function using the shared context
    // Skip duplicate function definitions (keep only the first one with each name)
    // This is a workaround for missing proper monomorphization
    let mut generated_set = hashmap.HashMapU64U32.with_capacity(functions.len());
    let mut skip_count: usize = 0;
    for i in 0usize..functions.len() {
        let (ref name, ref body) = functions[i];
        // Check if this function name has already been generated (O(1) hash lookup)
        let name_hash = hashmap::hash_str(name.as_str());
        let already_generated = match generated_set.get(name_hash) {
            Option.Some(_) => true,
            Option.None => false,
        };
        if !already_generated {
            // Set up call remapping for trait default methods
            ctx.call_remaps = find_call_remaps(default_method_remaps, body.def_id.index);
            let fn_ir = generate_function_with_ctx(&mut ctx, body, name.as_str());
            output.push_str(fn_ir.as_str());
            ctx.call_remaps = Vec.new();
            generated_set.insert(name_hash, 1);
        } else {
            skip_count += 1;
            // Emit a comment noting the skipped duplicate
            output.push_str("; DUPLICATE SKIPPED: @");
            output.push_str(name.as_str());
            output.push_str("\n");
        }
    }
    // Debug: emit total skip count as comment
    if skip_count > 0 {
        output.push_str("; TOTAL DUPLICATES SKIPPED: ");
        let skip_str = codegen_types::format_u64(skip_count as u64);
        output.push_str(skip_str.as_str());
        output.push_str("\n");
    }

    // Emit fn pointer wrapper functions collected during codegen
    for wpi in 0usize..ctx.fn_ptr_wrapper_defs.len() {
        output.push_str(ctx.fn_ptr_wrapper_defs[wpi].as_str());
    }

    // Append string constants from the context
    ctx.emit_string_constants();
    output.push_str(ctx.output.as_str());

    // Intrinsic and runtime declarations (consolidated in intrinsic_declarations())
    let decls = intrinsic_declarations();
    output.push_str(decls.as_str());

    // Drain accumulated errors and warnings from the context
    let errors = ctx.take_errors();
    let warnings = ctx.take_warnings();
    if errors.len() > 0 || warnings.len() > 0 {
        CodegenResult.ok_with_diagnostics(output, errors, warnings)
    } else {
        CodegenResult.ok(output)
    }
}

/// Generates LLVM IR for a function with access to def names table.
/// Legacy function for backward compatibility.
pub fn generate_function_with_defs(
    body: &mir_body.MirBody,
    fn_name: &str,
    def_names: &Vec<codegen_ctx.DefNameEntry>,
) -> String {
    let mut ctx = codegen_ctx.CodegenCtx.new();

    // Register all def names in the context
    for i in 0usize..def_names.len() {
        ctx.register_def_name(def_names[i].def_id, clone_string(&def_names[i].name));
    }

    generate_function_with_ctx(&mut ctx, body, fn_name)
}

/// Generates LLVM IR for a single function using a shared codegen context.
pub fn generate_function_with_ctx(
    ctx: &mut codegen_ctx.CodegenCtx,
    body: &mir_body.MirBody,
    fn_name: &str,
) -> String {
    // Reset per-function state but keep global state (def_names, adt_registry, string_table)
    ctx.clear_locals();
    ctx.output = String.new();
    ctx.begin_function(common::make_string(fn_name));

    // Build parameter list (skip first local which is return place)
    // For handler op bodies with multiple state fields, skip the state field
    // locals (2..1+state_count) — they are loaded from the state pointer, not passed as args.
    let mut params: Vec<(String, String)> = Vec.new();
    let mut arg_idx: usize = 0;
    let mut p: usize = 1; // Start at 1 to skip return place
    let param_end: usize = 1usize + (body.param_count as usize);
    while p < param_end && p < body.locals.len() {
        let local = &body.locals[p];
        let local_id = mir_def.MirLocalId.new(p as u32);
        // Skip handler state field locals — they're accessed via GEP into state ptr
        if ctx.is_handler_state_field(local_id) {
            p += 1;
            continue;
        }
        // Handler op state local: arg type is ptr (state pointer from wrapper)
        let ty = if ctx.is_handler_state_ptr(local_id) {
            common::make_string("ptr")
        } else {
            codegen_size::type_to_llvm_with_ctx_id(ctx, local.ty)
        };
        let mut arg_name = common::make_string("%arg");
        let idx_str = codegen_types::format_u64(arg_idx as u64);
        arg_name.push_str(idx_str.as_str());
        params.push((ty, arg_name));
        arg_idx += 1;
        p += 1;
    }

    // Get return type (local _0)
    // Normalize {} (empty struct / unit) to void for LLVM function signatures
    let ret_ty_raw = if body.locals.len() > 0 {
        codegen_size::type_to_llvm_with_ctx_id(ctx, body.locals[0].ty)
    } else {
        common::make_string("void")
    };
    let ret_ty = if is_empty_struct_type(ret_ty_raw.as_str()) {
        common::make_string("void")
    } else {
        ret_ty_raw
    };

    // Store function signature for generic call fixup at call sites
    let mut sig_param_types: Vec<String> = Vec.new();
    for sp in 0usize..params.len() {
        sig_param_types.push(clone_string(&params[sp].0));
    }
    ctx.register_fn_signature(body.def_id.index, sig_param_types, clone_string(&ret_ty));

    // Emit function header
    ctx.emit_fn_header(fn_name, &params, ret_ty.as_str());

    // Emit entry label
    ctx.write("entry:\n");

    // Run escape analysis to determine allocation tiers
    let escape_result = mir_escape::analyze_escapes(body);

    // Emit allocas with escape-aware allocation decisions
    codegen_stmt::emit_allocas_with_escapes(ctx, body, &escape_result);

    // Store arguments into allocas
    codegen_stmt::emit_arg_stores(ctx, body);

    // For closure bodies with captures, load captured values from env struct
    if body.capture_locals.len() > 0 {
        emit_capture_loads(ctx, body);
    }

    // Jump to first basic block if there are any
    if body.basic_blocks.len() > 0 {
        let first_label = ctx.block_label_cg(mir_def.BasicBlockId.new(0));
        ctx.indent();
        ctx.emit_br_cg(&first_label);
        ctx.dedent();
    } else {
        ctx.indent();
        ctx.emit_unreachable();
        ctx.dedent();
    }

    // Emit all basic blocks
    for block_idx in 0usize..body.basic_blocks.len() {
        let block_id = mir_def.BasicBlockId.new(block_idx as u32);
        codegen_term::emit_basic_block(ctx, block_id, &body.basic_blocks[block_idx]);
    }

    ctx.emit_fn_footer();
    ctx.end_function();

    // Extract and return the function IR
    let result = clone_string(&ctx.output);
    ctx.output = String.new();
    result
}

/// Emits loads for captured variables from the env struct pointer at closure body start.
///
/// Closure body layout:
///   Local 0: return value
///   Local 1: env_ptr (first parameter, ptr type)
///   Locals 2..1+num_user_params: explicit closure parameters
///   Locals (1+param_count)..(1+param_count+capture_count): capture locals
///
/// The env struct has the same layout as the capture operands in the
/// AggregateKind.Closure aggregate that constructed this closure.
fn emit_capture_loads(
    ctx: &mut codegen_ctx.CodegenCtx,
    body: &mir_body.MirBody,
) {
    // Build env struct LLVM type from capture types
    let mut env_llvm = common::make_string("{ ");
    for ti in 0usize..body.capture_tys.len() {
        if ti > 0 {
            env_llvm.push_str(", ");
        }
        let cap_ty_llvm = codegen_size::type_to_llvm_with_ctx_id(ctx, body.capture_tys[ti]);
        env_llvm.push_str(cap_ty_llvm.as_str());
    }
    env_llvm.push_str(" }");

    // Load env_ptr from local 1's alloca
    let env_load = ctx.fresh_temp_cg();
    let local1_name = ctx.local_cg(mir_def.MirLocalId.new(1));
    ctx.write("    ");
    ctx.write_cgname(&env_load);
    ctx.write(" = load ptr, ptr ");
    ctx.write_cgname(&local1_name);
    ctx.write("\n");

    // For each capture, GEP into env struct and load value into the capture local's alloca
    let mut ci: usize = 0;
    while ci < body.capture_locals.len() && ci < body.capture_tys.len() {
        let cap_ty_llvm = codegen_size::type_to_llvm_with_ctx_id(ctx, body.capture_tys[ci]);
        let local_idx = body.capture_locals[ci];

        // GEP to get pointer to this capture in the env struct
        let field_ptr = ctx.fresh_temp_cg();
        ctx.write("    ");
        ctx.write_cgname(&field_ptr);
        ctx.write(" = getelementptr ");
        ctx.write_string(&env_llvm);
        ctx.write(", ptr ");
        ctx.write_cgname(&env_load);
        ctx.write(", i32 0, i32 ");
        ctx.write(codegen_types::format_u64(ci as u64).as_str());
        ctx.write("\n");

        // Load the captured value
        let cap_val = ctx.fresh_temp_cg();
        ctx.write("    ");
        ctx.write_cgname(&cap_val);
        ctx.write(" = load ");
        ctx.write_string(&cap_ty_llvm);
        ctx.write(", ptr ");
        ctx.write_cgname(&field_ptr);
        ctx.write("\n");

        // Store into the capture local's alloca
        let cap_local = ctx.local_cg(mir_def.MirLocalId.new(local_idx));
        ctx.write("    ");
        ctx.write("store ");
        ctx.write_string(&cap_ty_llvm);
        ctx.write(" ");
        ctx.write_cgname(&cap_val);
        ctx.write(", ptr ");
        ctx.write_cgname(&cap_local);
        ctx.write("\n");

        ci += 1;
    }
}

// ============================================================
// ADT Registry Population
// ============================================================

/// Populates the ADT registry from HIR items.
/// Uses a two-pass approach: first register all ADTs with placeholder field types,
/// then rebuild layouts using the now-populated registry for correct nested ADT types.
pub fn populate_adt_registry(
    ctx: &mut codegen_ctx.CodegenCtx,
    items: &Vec<hir_lower_ctx.ItemEntry>,
) {
    // Pass 1: Register all ADTs with basic (possibly ptr) field types.
    // This ensures all ADT def_ids are known before resolving nested types.
    for i in 0usize..items.len() {
        let entry = &items[i];
        match &entry.item.kind {
            &hir_item.ItemKind.Struct(ref struct_def) => {
                let layout = build_struct_layout_basic(entry.def_id.index, struct_def);
                ctx.register_struct(layout);
            }
            &hir_item.ItemKind.Enum(ref enum_def) => {
                let layout = build_enum_layout_with_ctx(ctx, entry.def_id.index, enum_def);
                ctx.register_enum(layout);
            }
            &hir_item.ItemKind.Fn(_) => {}
            &hir_item.ItemKind.TypeAlias(_) => {}
            &hir_item.ItemKind.Const(_) => {}
            &hir_item.ItemKind.Static(_) => {}
            &hir_item.ItemKind.Trait(_) => {}
            &hir_item.ItemKind.Effect(_) => {}
            &hir_item.ItemKind.Handler(ref handler_def) => {
                let layout = build_handler_enum_layout(ctx, entry.def_id.index, handler_def);
                ctx.register_enum(layout);
            }
            &hir_item.ItemKind.Module(_) => {}
            &hir_item.ItemKind.Impl(_) => {}
            &hir_item.ItemKind.Macro(_) => {}
            &hir_item.ItemKind.Foreign(_) => {}
        }
    }

    // Pass 2+: Rebuild struct and enum layouts using context-aware type resolution.
    // Each pass resolves one more level of nesting. Since lookup_struct/lookup_enum and
    // adt_llvm_type scan from the end, new entries override old ones.
    //
    // Within each pass, items are processed in def_id order. When a struct S appears
    // before enum E in the items list, S uses E's value from the PREVIOUS pass. This
    // means S is always one pass behind E. To ensure all types converge:
    // - Run passes until no layout changes (fixpoint), then one extra pass so that
    //   structs pick up the final enum values from the convergence pass.
    // - Maximum 12 passes as a safety bound (handles nesting depth up to ~6).
    let mut pass: u32 = 0;
    let mut stable_count: u32 = 0;
    while pass < 12 && stable_count < 2 {
        let mut changed: bool = false;
        for j in 0usize..items.len() {
            let entry = &items[j];
            match &entry.item.kind {
                &hir_item.ItemKind.Struct(ref struct_def) => {
                    let layout = build_struct_layout_with_ctx(ctx, entry.def_id.index, struct_def);
                    // Check if this layout differs from the last registered one
                    let old_type = ctx.adt_llvm_type(entry.def_id.index);
                    if !string_eq_str(old_type.as_str(), layout.llvm_type.as_str()) {
                        changed = true;
                    }
                    ctx.register_struct(layout);
                }
                &hir_item.ItemKind.Enum(ref enum_def) => {
                    let layout = build_enum_layout_with_ctx(ctx, entry.def_id.index, enum_def);
                    let old_type = ctx.adt_llvm_type(entry.def_id.index);
                    if !string_eq_str(old_type.as_str(), layout.llvm_type.as_str()) {
                        changed = true;
                    }
                    ctx.register_enum(layout);
                }
                _ => {}
            }
        }
        if changed {
            stable_count = 0;
        } else {
            stable_count += 1;
        }
        pass += 1;
    }
}

/// Registers synthetic StructLayouts for builtin ADT types (Vec, String, HashMap, Box).
/// These types are not in the HIR items list but need to be in the ADT registry so that
/// user-defined structs containing these types resolve to the correct LLVM layout
/// (e.g., `{ ptr, i64, i64 }` instead of `ptr`).
pub fn register_builtin_adts(
    ctx: &mut codegen_ctx.CodegenCtx,
    builtin_vec_def: &Option<hir_def.DefId>,
    builtin_string_def: &Option<hir_def.DefId>,
    builtin_hashmap_def: &Option<hir_def.DefId>,
    builtin_box_def: &Option<hir_def.DefId>,
    builtin_option_def: &Option<hir_def.DefId>,
    builtin_result_def: &Option<hir_def.DefId>,
) {
    // Vec<T> = { ptr, i64, i64 } (data pointer, length, capacity)
    match builtin_vec_def {
        &Option.Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "{ ptr, i64, i64 }");
            ctx.register_struct(layout);
        }
        &Option.None => {}
    }
    // String = { ptr, i64, i64 } (same as Vec<u8>)
    match builtin_string_def {
        &Option.Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "{ ptr, i64, i64 }");
            ctx.register_struct(layout);
        }
        &Option.None => {}
    }
    // HashMap<K,V> = { ptr, i64, i64 } (runtime representation)
    match builtin_hashmap_def {
        &Option.Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "{ ptr, i64, i64 }");
            ctx.register_struct(layout);
        }
        &Option.None => {}
    }
    // Box<T> = ptr (single heap pointer)
    match builtin_box_def {
        &Option.Some(ref def_id) => {
            let layout = make_builtin_struct_layout(def_id.index, "ptr");
            ctx.register_struct(layout);
        }
        &Option.None => {}
    }
    // Option<T> = { i32, [1 x i64] } — discriminant i32, generic payload
    // Variant 0 = None (no payload), Variant 1 = Some(T) (one field)
    match builtin_option_def {
        &Option.Some(ref def_id) => {
            let layout = make_builtin_enum_layout(def_id.index, 2, true);
            ctx.register_enum(layout);
        }
        &Option.None => {}
    }
    // Result<T, E> = { i32, [1 x i64] } — discriminant i32, generic payload
    // Variant 0 = Ok(T) (one field), Variant 1 = Err(E) (one field)
    match builtin_result_def {
        &Option.Some(ref def_id) => {
            let layout = make_builtin_enum_layout(def_id.index, 2, false);
            ctx.register_enum(layout);
        }
        &Option.None => {}
    }
}

/// Creates a synthetic StructLayout for a builtin type with the given LLVM type string.
fn make_builtin_struct_layout(def_id: u32, llvm_type_str: &str) -> codegen_ctx.StructLayout {
    codegen_ctx.StructLayout {
        def_id: def_id,
        fields: Vec.new(),
        llvm_type: common::make_string(llvm_type_str),
    }
}

/// Creates a synthetic EnumLayout for a builtin enum (Option or Result).
/// Generic enums use i64 as the payload slot size (sufficient for pointers and i64 values).
/// `num_variants` is the number of variants (2 for Option, 2 for Result).
/// `first_is_unit` indicates whether variant 0 has no payload (true for Option.None).
fn make_builtin_enum_layout(def_id: u32, num_variants: u32, first_is_unit: bool) -> codegen_ctx.EnumLayout {
    let mut variants: Vec<codegen_ctx.VariantLayout> = Vec.new();
    for vi in 0u32..num_variants {
        let fields: Vec<codegen_ctx.AdtFieldInfo> = Vec.new();
        let payload_ty = if first_is_unit && vi == 0 {
            common::make_string("{}")
        } else {
            common::make_string("{ i64 }")
        };
        variants.push(codegen_ctx.VariantLayout {
            variant_idx: vi,
            fields: fields,
            payload_llvm_type: payload_ty,
        });
    }
    codegen_ctx.EnumLayout {
        def_id: def_id,
        discriminant_type: common::make_string("i32"),
        variants: variants,
        llvm_type: common::make_string("{ i32, [1 x i64] }"),
        max_payload_size: 8,
    }
}

/// Rebuilds ADT layouts using context-aware type resolution.
/// Call this after registering builtin ADTs and before code generation
/// to ensure all struct fields containing Vec/String/HashMap resolve to correct sizes.
pub fn rebuild_adt_layouts(
    ctx: &mut codegen_ctx.CodegenCtx,
    items: &Vec<hir_lower_ctx.ItemEntry>,
) {
    for pass in 0u32..4 {
        for j in 0usize..items.len() {
            let entry = &items[j];
            match &entry.item.kind {
                &hir_item.ItemKind.Struct(ref struct_def) => {
                    let layout = build_struct_layout_with_ctx(ctx, entry.def_id.index, struct_def);
                    ctx.register_struct(layout);
                }
                &hir_item.ItemKind.Enum(ref enum_def) => {
                    let layout = build_enum_layout_with_ctx(ctx, entry.def_id.index, enum_def);
                    ctx.register_enum(layout);
                }
                _ => {}
            }
        }
    }
}

/// Builds a StructLayout using basic type resolution (no ADT registry lookups).
/// Used in pass 1 to get all ADTs registered before resolving nested types.
fn build_struct_layout_basic(def_id: u32, struct_def: &hir_item.StructDef) -> codegen_ctx.StructLayout {
    let mut fields: Vec<codegen_ctx.AdtFieldInfo> = Vec.new();
    let mut llvm_type = common::make_string("{ ");

    match &struct_def.body {
        &hir_item.StructBody.Record(ref struct_fields) => {
            for fi in 0usize..struct_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let field_ty_hir = type_intern::ty_id_to_type(struct_fields[fi].ty);
                let field_ty = codegen_types::type_to_llvm(&field_ty_hir);
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx.AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option.Some(struct_fields[fi].ty),
                });
            }
        }
        &hir_item.StructBody.Tuple(ref tuple_fields) => {
            for fi in 0usize..tuple_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let tuple_field_hir = type_intern::ty_id_to_type(type_intern.TyId.new(tuple_fields[fi].index));
                let field_ty = codegen_types::type_to_llvm(&tuple_field_hir);
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx.AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option.Some(type_intern.TyId.new(tuple_fields[fi].index)),
                });
            }
        }
        &hir_item.StructBody.Unit => {
            // Unit struct: empty
        }
    }

    llvm_type.push_str(" }");

    // Handle edge case: empty struct
    if fields.len() == 0 {
        llvm_type = common::make_string("{}");
    }

    codegen_ctx.StructLayout {
        def_id: def_id,
        fields: fields,
        llvm_type: llvm_type,
    }
}

/// Builds an EnumLayout for an effect handler definition.
/// Handler structs are laid out like enums: { i32_discriminant, [N x i64]_payload }
/// where N is computed from the actual byte sizes of state fields (ceil(total_bytes / 8)),
/// not simply the number of fields. This ensures aggregate types like String (24 bytes)
/// get enough payload slots.
fn build_handler_enum_layout(ctx: &mut codegen_ctx.CodegenCtx, def_id: u32, handler_def: &hir_item.HandlerDef) -> codegen_ctx.EnumLayout {
    let state_count = handler_def.state.len();

    // Build variant payload fields using actual LLVM types
    let mut fields: Vec<codegen_ctx.AdtFieldInfo> = Vec.new();
    let mut payload_type = common::make_string("{ ");
    let mut total_state_bytes: u64 = 0;
    for si in 0usize..state_count {
        let field_ty_id = handler_def.state[si].ty;
        let field_llvm_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, field_ty_id);
        let field_size = codegen_size::llvm_type_size(field_llvm_ty.as_str());
        total_state_bytes += field_size;
        if si > 0 {
            payload_type.push_str(", ");
        }
        payload_type.push_str(field_llvm_ty.as_str());
        fields.push(codegen_ctx.AdtFieldInfo {
            llvm_type: field_llvm_ty,
            hir_type: Option.Some(field_ty_id),
        });
    }
    payload_type.push_str(" }");

    // Single variant (variant_idx = 0) holding all state fields
    let mut variants: Vec<codegen_ctx.VariantLayout> = Vec.new();
    variants.push(codegen_ctx.VariantLayout {
        variant_idx: 0,
        fields: fields,
        payload_llvm_type: if state_count > 0 { payload_type } else { common::make_string("{}") },
    });

    // Build LLVM type: { i32, [N x i64] } for stateful, { i32 } for stateless
    // N = ceil(total_state_bytes / 8) so aggregate types get enough slots
    let mut llvm_type = common::make_string("{ i32");
    let max_payload_size: u64 = if state_count > 0 {
        let num_i64_slots = (total_state_bytes + 7) / 8;
        llvm_type.push_str(", [");
        llvm_type.push_str(codegen_types::format_u64(num_i64_slots).as_str());
        llvm_type.push_str(" x i64]");
        num_i64_slots * 8
    } else {
        0
    };
    llvm_type.push_str(" }");

    // Register total state byte size for PushHandler shadow alloca sizing
    ctx.register_handler_state_byte_size(def_id, total_state_bytes as u32);

    codegen_ctx.EnumLayout {
        def_id: def_id,
        discriminant_type: common::make_string("i32"),
        variants: variants,
        llvm_type: llvm_type,
        max_payload_size: max_payload_size,
    }
}

/// Builds a StructLayout using context-aware type resolution.
/// ADT fields resolve to their actual struct/enum types from the registry.
fn build_struct_layout_with_ctx(
    ctx: &mut codegen_ctx.CodegenCtx,
    def_id: u32,
    struct_def: &hir_item.StructDef,
) -> codegen_ctx.StructLayout {
    let mut fields: Vec<codegen_ctx.AdtFieldInfo> = Vec.new();
    let mut llvm_type = common::make_string("{ ");

    match &struct_def.body {
        &hir_item.StructBody.Record(ref struct_fields) => {
            for fi in 0usize..struct_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, struct_fields[fi].ty);
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx.AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option.Some(struct_fields[fi].ty),
                });
            }
        }
        &hir_item.StructBody.Tuple(ref tuple_fields) => {
            for fi in 0usize..tuple_fields.len() {
                if fi > 0 {
                    llvm_type.push_str(", ");
                }
                let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, type_intern.TyId.new(tuple_fields[fi].index));
                llvm_type.push_str(field_ty.as_str());
                // Store HIR type for indexing element size calculation
                fields.push(codegen_ctx.AdtFieldInfo {
                    llvm_type: field_ty,
                    hir_type: Option.Some(type_intern.TyId.new(tuple_fields[fi].index)),
                });
            }
        }
        &hir_item.StructBody.Unit => {
            // Unit struct: empty
        }
    }

    llvm_type.push_str(" }");

    if fields.len() == 0 {
        llvm_type = common::make_string("{}");
    }

    codegen_ctx.StructLayout {
        def_id: def_id,
        fields: fields,
        llvm_type: llvm_type,
    }
}

/// Builds an EnumLayout using context-aware type resolution.
/// ADT fields in enum payloads resolve to their actual struct/enum types from the registry.
fn build_enum_layout_with_ctx(
    ctx: &mut codegen_ctx.CodegenCtx,
    def_id: u32,
    enum_def: &hir_item.EnumDef,
) -> codegen_ctx.EnumLayout {
    let mut variants: Vec<codegen_ctx.VariantLayout> = Vec.new();
    let mut max_payload_size: u64 = 0;
    let mut max_alignment: u64 = 1;
    let mut has_payload: bool = false;

    for vi in 0usize..enum_def.variants.len() {
        let variant = &enum_def.variants[vi];
        let mut fields: Vec<codegen_ctx.AdtFieldInfo> = Vec.new();
        let mut payload_type = common::make_string("{}");

        match &variant.kind {
            &hir_item.VariantKind.Unit => {
                // No payload
            }
            &hir_item.VariantKind.Tuple(ref tuple_fields) => {
                let mut pt = common::make_string("{ ");
                for fi in 0usize..tuple_fields.len() {
                    if fi > 0 {
                        pt.push_str(", ");
                    }
                    let tuple_ty_id = type_intern.TyId.new(tuple_fields[fi].index);
                    let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, tuple_ty_id);
                    pt.push_str(field_ty.as_str());
                    fields.push(codegen_ctx.AdtFieldInfo {
                        llvm_type: field_ty,
                        hir_type: Option.Some(type_intern.TyId.new(tuple_fields[fi].index)),
                    });
                }
                pt.push_str(" }");
                if tuple_fields.len() > 0 {
                    has_payload = true;
                    payload_type = pt;
                }
            }
            &hir_item.VariantKind.Record(ref record_fields) => {
                let mut pt = common::make_string("{ ");
                for fi in 0usize..record_fields.len() {
                    if fi > 0 {
                        pt.push_str(", ");
                    }
                    let field_ty = codegen_size::type_to_llvm_with_ctx_id(ctx, record_fields[fi].ty);
                    pt.push_str(field_ty.as_str());
                    fields.push(codegen_ctx.AdtFieldInfo {
                        llvm_type: field_ty,
                        hir_type: Option.Some(record_fields[fi].ty),
                    });
                }
                pt.push_str(" }");
                if record_fields.len() > 0 {
                    has_payload = true;
                    payload_type = pt;
                }
            }
        }

        // Use proper struct size with padding (not naive sum of field sizes)
        let variant_size = codegen_size::llvm_type_size(payload_type.as_str());
        let variant_align = codegen_size::llvm_type_alignment(payload_type.as_str());
        if variant_size > max_payload_size {
            max_payload_size = variant_size;
        }
        if variant_align > max_alignment {
            max_alignment = variant_align;
        }

        variants.push(codegen_ctx.VariantLayout {
            variant_idx: variant.discriminant,
            fields: fields,
            payload_llvm_type: payload_type,
        });

    }

    // Always use i32 for discriminant (matching reference compiler)
    let discriminant_type = common::make_string("i32");

    // Build enum LLVM type with alignment-aware payload array.
    // The payload array element type is chosen to satisfy the maximum alignment
    // requirement across all variant payloads (matching reference compiler behavior).
    let mut llvm_type = common::make_string("{ i32");
    if has_payload && max_payload_size > 0 {
        if max_alignment >= 8 {
            let num_elements = (max_payload_size + 7) / 8;
            llvm_type.push_str(", [");
            let count_str = codegen_types::format_u64(num_elements);
            llvm_type.push_str(count_str.as_str());
            llvm_type.push_str(" x i64]");
            max_payload_size = num_elements * 8;
        } else if max_alignment >= 4 {
            let num_elements = (max_payload_size + 3) / 4;
            llvm_type.push_str(", [");
            let count_str = codegen_types::format_u64(num_elements);
            llvm_type.push_str(count_str.as_str());
            llvm_type.push_str(" x i32]");
            max_payload_size = num_elements * 4;
        } else if max_alignment >= 2 {
            let num_elements = (max_payload_size + 1) / 2;
            llvm_type.push_str(", [");
            let count_str = codegen_types::format_u64(num_elements);
            llvm_type.push_str(count_str.as_str());
            llvm_type.push_str(" x i16]");
            max_payload_size = num_elements * 2;
        } else {
            llvm_type.push_str(", [");
            let size_str = codegen_types::format_u64(max_payload_size);
            llvm_type.push_str(size_str.as_str());
            llvm_type.push_str(" x i8]");
        }
    }
    llvm_type.push_str(" }");

    codegen_ctx.EnumLayout {
        def_id: def_id,
        discriminant_type: discriminant_type,
        variants: variants,
        llvm_type: llvm_type,
        max_payload_size: max_payload_size,
    }
}

// ============================================================
// Simple Function Generator
// ============================================================

/// Generates a simple function that returns a constant.
pub fn generate_constant_function(name: &str, value: i64) -> String {
    let mut output = String.new();
    output.push_str("define i64 @");
    output.push_str(name);
    output.push_str("() {\n");
    output.push_str("entry:\n");
    output.push_str("    ret i64 ");
    let val_str = codegen_types::format_i64(value);
    output.push_str(val_str.as_str());
    output.push_str("\n}\n");
    output
}

// ============================================================
// Module Preamble
// ============================================================

/// Generates the standard module preamble.
pub fn module_preamble(module_name: &str) -> String {
    let mut output = String.new();
    output.push_str("; ModuleID = '");
    output.push_str(module_name);
    output.push_str("'\n");
    output.push_str("source_filename = \"");
    output.push_str(module_name);
    output.push_str(".blood\"\n");
    output.push_str("target datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128\"\n");
    output.push_str("target triple = \"x86_64-unknown-linux-gnu\"\n\n");
    output
}

/// Generates standard intrinsic declarations.
pub fn intrinsic_declarations() -> String {
    let mut output = String.new();
    output.push_str("\n; Intrinsic declarations\n");
    output.push_str("declare void @llvm.memcpy.p0.p0.i64(ptr, ptr, i64, i1)\n");
    output.push_str("declare void @llvm.memset.p0.i64(ptr, i8, i64, i1)\n");
    output.push_str("declare void @llvm.trap()\n");
    output.push_str("declare void @llvm.debugtrap()\n");
    output.push_str("declare ptr @llvm.stacksave()\n");
    output.push_str("declare void @llvm.stackrestore(ptr)\n");

    // C library declarations
    output.push_str("\n; C library declarations\n");
    output.push_str("declare i32 @puts(ptr)\n");

    // Box runtime declarations
    output.push_str("\n; Box runtime declarations\n");
    output.push_str("declare ptr @box_new(ptr, i64)\n");
    output.push_str("declare ptr @box_as_ref(ptr)\n");

    // Effect handler evidence API declarations (from libblood_runtime.a)
    output.push_str("\n; Effect handler evidence API declarations\n");
    output.push_str("declare ptr @blood_evidence_create()\n");
    output.push_str("declare ptr @blood_evidence_current()\n");
    output.push_str("declare void @blood_evidence_set_current(ptr)\n");
    output.push_str("declare void @blood_evidence_push_with_state(ptr, i64, ptr)\n");
    output.push_str("declare void @blood_evidence_set_inline(i64)\n");
    output.push_str("declare void @blood_evidence_clear_inline()\n");
    output.push_str("declare i64 @blood_evidence_pop(ptr)\n");
    output.push_str("declare void @blood_evidence_register(ptr, i64, ptr, i64)\n");
    output.push_str("declare i64 @blood_perform(i64, i32, ptr, i64, i64)\n");
    output.push_str("declare i64 @blood_continuation_create_multishot(ptr, ptr)\n");
    output.push_str("declare i64 @blood_continuation_resume(i64, i64)\n");
    output.push_str("\n; Identity continuation for tail-resumptive performs\n");
    output.push_str("define internal i64 @__blood_identity_continuation(i64 %0, ptr %1) {\n");
    output.push_str("entry:\n");
    output.push_str("  ret i64 %0\n");
    output.push_str("}\n");

    // Builtin constructor stubs (used as function pointers for match dispatch, not called directly)
    output.push_str("\n; Builtin constructor stubs\n");
    output.push_str("define internal void @option_none_ctor() { ret void }\n");
    output.push_str("define internal void @option_some_ctor(ptr %0) { ret void }\n");
    output.push_str("declare void @string_new(ptr)\n");
    output.push_str("declare void @vec_new(i64, ptr)\n");

    // Format string conversion runtime declarations
    // These return { ptr, i64 } fat pointers (&str).
    output.push_str("\n; Format string conversion runtime declarations\n");
    output.push_str("declare { ptr, i64 } @int_to_string(i32)\n");
    output.push_str("declare { ptr, i64 } @bool_to_string(i1)\n");
    output.push_str("declare { ptr, i64 } @float_to_string(double)\n");
    output.push_str("declare { ptr, i64 } @char_to_string(i32)\n");

    // Builtin method runtime declarations
    // These are runtime functions called by builtin method resolution.
    // Signatures match blood-rust's codegen/context/mod.rs.
    output.push_str("\n; String method runtime declarations\n");
    output.push_str("declare i64 @string_len(ptr)\n");
    output.push_str("declare void @string_push(ptr, i32)\n");
    output.push_str("declare void @string_push_str(ptr, ptr)\n");
    output.push_str("declare { ptr, i64 } @string_as_str(ptr)\n");
    output.push_str("declare { ptr, i64 } @string_as_bytes(ptr)\n");

    output.push_str("\n; str method runtime declarations\n");
    output.push_str("declare { ptr, i64 } @str_as_bytes(ptr)\n");

    output.push_str("\n; Vec method runtime declarations\n");
    output.push_str("declare i64 @vec_len(ptr)\n");
    output.push_str("declare void @vec_push(ptr, ptr, i64)\n");
    output.push_str("declare i32 @vec_pop(ptr, i64, ptr)\n");
    output.push_str("declare void @vec_clear(ptr)\n");
    output.push_str("declare void @vec_with_capacity(i64, i64, ptr)\n");
    output.push_str("declare i32 @vec_is_empty(ptr)\n");
    output.push_str("declare i64 @vec_capacity(ptr)\n");
    output.push_str("declare i32 @vec_get(ptr, i64, i64, ptr)\n");
    output.push_str("declare ptr @vec_get_ptr(ptr, i64, i64)\n");
    output.push_str("declare i32 @vec_contains(ptr, ptr, i64)\n");
    output.push_str("declare void @vec_reverse(ptr, i64)\n");
    output.push_str("declare void @vec_first(ptr, i64, ptr)\n");
    output.push_str("declare void @vec_last(ptr, i64, ptr)\n");
    output.push_str("declare void @vec_free(ptr, i64)\n");

    output.push_str("\n; Option method runtime declarations\n");
    output.push_str("declare i32 @option_is_some(ptr)\n");
    output.push_str("declare i32 @option_is_none(ptr)\n");
    output.push_str("declare void @option_unwrap(ptr, i64, ptr)\n");
    output.push_str("declare void @option_as_ref(ptr, i64, ptr)\n");

    output.push_str("\n; Slice method runtime declarations\n");
    output.push_str("declare i64 @slice_len(ptr)\n");

    // Region memory management runtime wrappers
    // The runtime uses blood_region_* prefix; we provide region_* wrappers for codegen
    output.push_str("\n; Region memory management\n");
    output.push_str("declare i64 @blood_region_create(i64, i64)\n");
    output.push_str("declare void @blood_region_destroy(i64)\n");
    output.push_str("declare void @blood_region_reset(i64)\n");
    output.push_str("declare void @blood_region_activate(i64)\n");
    output.push_str("declare void @blood_region_deactivate()\n");
    output.push_str("declare i64 @blood_region_alloc(i64, i64, i64)\n");
    output.push_str("declare i32 @blood_region_exit_scope(i64)\n");
    output.push_str("declare i64 @blood_region_used(i64)\n");
    output.push_str("declare void @blood_region_trim(i64)\n");
    output.push_str("declare i64 @blood_region_committed(i64)\n");
    output.push_str("declare i64 @blood_region_alloc_count(i64)\n");
    output.push_str("declare i64 @blood_system_alloc_live_bytes()\n");
    output.push_str("define internal i64 @region_create(i64 %0, i64 %1) { %r = call i64 @blood_region_create(i64 %0, i64 %1) ret i64 %r }\n");
    output.push_str("define internal void @region_destroy(i64 %0) { call void @blood_region_destroy(i64 %0) ret void }\n");
    output.push_str("define internal void @region_reset(i64 %0) { call void @blood_region_reset(i64 %0) ret void }\n");
    output.push_str("define internal void @region_activate(i64 %0) { call void @blood_region_activate(i64 %0) ret void }\n");
    output.push_str("define internal void @region_deactivate() { call void @blood_region_deactivate() ret void }\n");
    output.push_str("define internal i64 @region_alloc(i64 %0, i64 %1, i64 %2) { %r = call i64 @blood_region_alloc(i64 %0, i64 %1, i64 %2) ret i64 %r }\n");
    output.push_str("define internal i32 @region_exit_scope(i64 %0) { %r = call i32 @blood_region_exit_scope(i64 %0) ret i32 %r }\n");
    output.push_str("define internal i64 @region_used(i64 %0) { %r = call i64 @blood_region_used(i64 %0) ret i64 %r }\n");
    output.push_str("define internal void @region_trim(i64 %0) { call void @blood_region_trim(i64 %0) ret void }\n");
    output.push_str("define internal i64 @region_committed(i64 %0) { %r = call i64 @blood_region_committed(i64 %0) ret i64 %r }\n");
    output.push_str("define internal i64 @region_alloc_count(i64 %0) { %r = call i64 @blood_region_alloc_count(i64 %0) ret i64 %r }\n");
    output.push_str("define internal i64 @system_alloc_live_bytes() { %r = call i64 @blood_system_alloc_live_bytes() ret i64 %r }\n");
    output.push_str("declare i64 @blood_realloc_diag_count()\n");
    output.push_str("declare i64 @blood_realloc_diag_wasted()\n");
    output.push_str("declare i64 @blood_realloc_diag_inplace()\n");
    output.push_str("declare i64 @blood_realloc_diag_inplace_bytes()\n");
    output.push_str("declare i64 @blood_realloc_diag_offset_delta()\n");
    output.push_str("declare void @blood_realloc_stats_reset()\n");
    output.push_str("declare void @blood_print_alloc_hist()\n");
    output.push_str("declare void @blood_alloc_hist_reset()\n");
    output.push_str("define internal i64 @realloc_diag_count() { %r = call i64 @blood_realloc_diag_count() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_wasted() { %r = call i64 @blood_realloc_diag_wasted() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_inplace() { %r = call i64 @blood_realloc_diag_inplace() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_inplace_bytes() { %r = call i64 @blood_realloc_diag_inplace_bytes() ret i64 %r }\n");
    output.push_str("define internal i64 @realloc_diag_offset_delta() { %r = call i64 @blood_realloc_diag_offset_delta() ret i64 %r }\n");
    output.push_str("define internal void @realloc_stats_reset() { call void @blood_realloc_stats_reset() ret void }\n");
    output.push_str("define internal void @print_alloc_hist() { call void @blood_print_alloc_hist() ret void }\n");
    output.push_str("define internal void @alloc_hist_reset() { call void @blood_alloc_hist_reset() ret void }\n");

    // Memory management - generational references
    output.push_str("\n; Memory management - generational references\n");
    output.push_str("declare i64 @blood_alloc_or_abort(i64, ptr)\n");
    output.push_str("declare void @blood_free(i64, i64)\n");
    output.push_str("declare i32 @blood_register_allocation(i64, i64)\n");
    output.push_str("declare void @blood_unregister_allocation(i64)\n");
    output.push_str("declare i32 @blood_validate_generation(i64, i32)\n");
    output.push_str("declare i32 @blood_get_generation(i64)\n");
    output.push_str("declare void @blood_increment_generation(ptr)\n");
    output.push_str("declare void @blood_stale_reference_panic(i32, i32)\n");

    // Persistent allocation (reference counting)
    output.push_str("\n; Persistent allocation (reference counting)\n");
    output.push_str("declare ptr @blood_persistent_alloc(i64, i64, i32, ptr)\n");
    output.push_str("declare void @blood_persistent_decrement(i64)\n");

    // Blood-name → runtime-name wrappers
    // Blood registers builtins with user-friendly names (e.g., "print"),
    // but the runtime exports them under different names (e.g., "print_str").
    // These wrappers bridge the gap. Uses named temps to avoid SSA numbering issues.
    output.push_str("\n; Blood builtin name wrappers\n");

    // print/println/eprint/eprintln → *_str runtime variants (for &str args)
    output.push_str("declare void @print_str({ ptr, i64 })\n");
    output.push_str("declare void @println_str({ ptr, i64 })\n");
    output.push_str("declare void @eprint_str({ ptr, i64 })\n");
    output.push_str("declare void @eprintln_str({ ptr, i64 })\n");
    output.push_str("define internal void @print({ ptr, i64 } %s) {\n  call void @print_str({ ptr, i64 } %s)\n  ret void\n}\n");
    output.push_str("define internal void @println({ ptr, i64 } %s) {\n  call void @println_str({ ptr, i64 } %s)\n  ret void\n}\n");
    output.push_str("define internal void @eprint({ ptr, i64 } %s) {\n  call void @eprint_str({ ptr, i64 } %s)\n  ret void\n}\n");
    output.push_str("define internal void @eprintln({ ptr, i64 } %s) {\n  call void @eprintln_str({ ptr, i64 } %s)\n  ret void\n}\n");

    // assert → blood_assert (Blood bool/i1 → runtime i32 conversion)
    output.push_str("declare void @blood_assert(i32)\n");
    output.push_str("declare void @blood_assert_eq_int(i32, i32)\n");
    output.push_str("declare void @blood_assert_eq_bool(i1, i1)\n");
    output.push_str("define internal void @assert(i1 %cond) {\n  %ext = zext i1 %cond to i32\n  call void @blood_assert(i32 %ext)\n  ret void\n}\n");
    output.push_str("define internal void @assert_eq_int(i32 %a, i32 %b) {\n  call void @blood_assert_eq_int(i32 %a, i32 %b)\n  ret void\n}\n");
    output.push_str("define internal void @assert_eq_bool(i1 %a, i1 %b) {\n  call void @blood_assert_eq_bool(i1 %a, i1 %b)\n  ret void\n}\n");

    // unreachable/todo → panic with message string constants
    // Note: @panic is declared by the runtime function codegen path, not here.
    output.push_str("@.str.unreachable = private unnamed_addr constant [26 x i8] c\"unreachable code reached!\\00\"\n");
    output.push_str("@.str.todo = private unnamed_addr constant [21 x i8] c\"not yet implemented!\\00\"\n");
    output.push_str("define internal void @unreachable() noreturn {\n  call void @panic({ ptr, i64 } { ptr @.str.unreachable, i64 25 })\n  unreachable\n}\n");
    output.push_str("define internal void @todo() noreturn {\n  call void @panic({ ptr, i64 } { ptr @.str.todo, i64 20 })\n  unreachable\n}\n");

    // process_exit → libc exit
    output.push_str("declare void @exit(i32) noreturn\n");
    output.push_str("define internal void @process_exit(i32 %code) noreturn {\n  call void @exit(i32 %code)\n  unreachable\n}\n");

    // Low-level memory builtins → blood runtime (all i64 addresses)
    output.push_str("declare i64 @blood_alloc_simple(i64)\n");
    output.push_str("declare i64 @blood_realloc(i64, i64)\n");
    output.push_str("declare void @blood_free_simple(i64)\n");
    output.push_str("declare i64 @blood_memcpy(i64, i64, i64)\n");
    output.push_str("define internal i64 @alloc(i64 %sz) {\n  %r = call i64 @blood_alloc_simple(i64 %sz)\n  ret i64 %r\n}\n");
    output.push_str("define internal i64 @realloc(i64 %p, i64 %sz) {\n  %r = call i64 @blood_realloc(i64 %p, i64 %sz)\n  ret i64 %r\n}\n");
    output.push_str("define internal void @free(i64 %p) {\n  call void @blood_free_simple(i64 %p)\n  ret void\n}\n");
    output.push_str("define internal i64 @memcpy(i64 %d, i64 %s, i64 %n) {\n  %r = call i64 @blood_memcpy(i64 %d, i64 %s, i64 %n)\n  ret i64 %r\n}\n");

    // str_concat → blood_str_concat
    output.push_str("declare { ptr, i64 } @blood_str_concat({ ptr, i64 }, { ptr, i64 })\n");
    output.push_str("define internal { ptr, i64 } @str_concat({ ptr, i64 } %a, { ptr, i64 } %b) {\n  %r = call { ptr, i64 } @blood_str_concat({ ptr, i64 } %a, { ptr, i64 } %b)\n  ret { ptr, i64 } %r\n}\n");

    // Builtins whose Blood types (Option<T>, String) don't match runtime ABI.
    // The runtime uses concrete types, not opaque ptrs.
    output.push_str("\n; Parsing / conversion / IO runtime declarations\n");
    output.push_str("declare double @parse_f64({ ptr, i64 })\n");
    output.push_str("declare i64 @parse_i64_radix({ ptr, i64 }, i32)\n");
    output.push_str("declare i32 @char_from_u32(i32)\n");
    output.push_str("declare { ptr, i64 } @read_line()\n");

    // Math library wrappers (Blood name → libm name where they differ)
    output.push_str("\n; Math library wrappers\n");
    output.push_str("declare double @fabs(double)\n");
    output.push_str("declare float @fabsf(float)\n");
    output.push_str("declare float @sqrtf(float)\n");
    output.push_str("define internal double @abs_f64(double %x) {\n  %r = call double @fabs(double %x)\n  ret double %r\n}\n");
    output.push_str("define internal float @abs_f32(float %x) {\n  %r = call float @fabsf(float %x)\n  ret float %r\n}\n");
    output.push_str("define internal float @sqrt_f32(float %x) {\n  %r = call float @sqrtf(float %x)\n  ret float %r\n}\n");

    // Thread builtins → blood_thread_spawn / blood_thread_join runtime wrappers
    output.push_str("\n; Thread runtime declarations\n");
    output.push_str("declare i64 @blood_thread_spawn(i64, i64)\n");
    output.push_str("declare i64 @blood_thread_join(i64)\n");
    output.push_str("define internal i64 @thread_spawn(i64 %f, i64 %a) {\n  %r = call i64 @blood_thread_spawn(i64 %f, i64 %a)\n  ret i64 %r\n}\n");
    output.push_str("define internal i64 @thread_join(i64 %h) {\n  %r = call i64 @blood_thread_join(i64 %h)\n  ret i64 %r\n}\n");

    output
}

// ============================================================
// External Function Declarations
// ============================================================

/// Generates an external function declaration.
pub fn extern_function(name: &str, params: &Vec<String>, ret_ty: &str) -> String {
    let mut output = String.new();
    output.push_str("declare ");
    output.push_str(ret_ty);
    output.push_str(" @");
    output.push_str(name);
    output.push_str("(");
    for i in 0usize..params.len() {
        if i > 0 {
            output.push_str(", ");
        }
        output.push_str(params[i].as_str());
    }
    output.push_str(")\n");
    output
}

// ============================================================
// String Helpers
// ============================================================

/// Checks if an LLVM type string is "{}" (empty struct / unit type).
fn is_empty_struct_type(ty: &str) -> bool {
    let bytes = ty.as_bytes();
    if bytes.len() == 2 {
        bytes[0] == 123 && bytes[1] == 125
    } else {
        false
    }
}

/// Clones a String.
fn clone_string(s: &String) -> String {
    let mut result = String.new();
    result.push_str(s.as_str());
    result
}

/// Compares two &str for equality.
fn string_eq_str(a: &str, b: &str) -> bool {
    let a_bytes = a.as_bytes();
    let b_bytes = b.as_bytes();
    if a_bytes.len() != b_bytes.len() {
        return false;
    }
    for i in 0usize..a_bytes.len() {
        if a_bytes[i] != b_bytes[i] {
            return false;
        }
    }
    true
}

/// Appends a u32 as decimal digits to a string.
fn append_u32(s: &mut String, n: u32) {
    if n == 0 {
        s.push('0');
        return;
    }
    let mut val = n;
    // Stack-based digit buffer
    let mut digits: [u8; 10] = [0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8, 0u8];
    let mut count: usize = 0;
    while val > 0 {
        digits[count] = ((val % 10) as u8) + 48u8; // '0' = 48
        val /= 10;
        count += 1;
    }
    // Reverse order
    while count > 0 {
        count -= 1;
        s.push(digits[count] as char);
    }
}

// ============================================================
// Integration Tests (compile-time verification)
// ============================================================

/// Generates a minimal test module to verify codegen works.
pub fn generate_test_module() -> String {
    let mut output = String.new();

    // Module header
    output.push_str("; Test module for Blood codegen\n");
    output.push_str("source_filename = \"test.blood\"\n\n");

    // Simple function that returns 42
    output.push_str("define i64 @test_return() {\n");
    output.push_str("entry:\n");
    output.push_str("    ret i64 42\n");
    output.push_str("}\n\n");

    // Function with parameters
    output.push_str("define i64 @test_add(i64 %a, i64 %b) {\n");
    output.push_str("entry:\n");
    output.push_str("    %result = add i64 %a, %b\n");
    output.push_str("    ret i64 %result\n");
    output.push_str("}\n\n");

    // Function with control flow
    output.push_str("define i64 @test_if(i64 %cond) {\n");
    output.push_str("entry:\n");
    output.push_str("    %cmp = icmp ne i64 %cond, 0\n");
    output.push_str("    br i1 %cmp, label %then, label %else\n");
    output.push_str("then:\n");
    output.push_str("    br label %merge\n");
    output.push_str("else:\n");
    output.push_str("    br label %merge\n");
    output.push_str("merge:\n");
    output.push_str("    %result = phi i64 [ 1, %then ], [ 0, %else ]\n");
    output.push_str("    ret i64 %result\n");
    output.push_str("}\n");

    output
}
